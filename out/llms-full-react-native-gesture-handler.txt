# React NativeGesture Handler

### Declarative API exposing platform native touch and gesture system to React Native.

### Learn how it works

Tap and drag the circles to explore the gestures.

### Why Gesture Handler?

#### native gesture recognizers

With Gesture Handler touch stream handling happens on the UI thread and uses APIs native to each platform.

#### native components

Gesture Handler library ships with a set of components that aim to provide best possible interations such as SwipeableRow or Drawer.

#### 120 FPS

Gesture Handler integrates tightly with Reanimated to allow you to build smooth gesture based experiences up to 120 fps.

Learn more about the features in the newest article about Gesture Handler

### We are Software Mansion

React Native Core Contributors and experts in dealing with all kinds of React Native issues. No matter if you need help with gestures, animations or React Native development we can help.

## Installation

### Requirements

`react-native-gesture-handler` supports the three latest minor releases of `react-native`.

| version | `react-native` version |
| ------- | ---------------------- |
| 2.24.0+ | 0.75.0+                |
| 2.21.0+ | 0.74.0+                |
| 2.18.0+ | 0.73.0+                |
| 2.16.0+ | 0.68.0+                |
| 2.14.0+ | 0.67.0+                |
| 2.10.0+ | 0.64.0+                |
| 2.0.0+  | 0.63.0+                |

In order to fully utilize the touch events you also need to use `react-native-reanimated` 2.3.0 or newer.

Setting up `react-native-gesture-handler` is pretty straightforward:

#### 1. Start with installing the package from npm:

- EXPO
- NPM
- YARN

```
npx expo install react-native-gesture-handler
```

```
npm install react-native-gesture-handler
```

```
yarn add react-native-gesture-handler
```

#### 2. Wrap your app with `GestureHandlerRootView` component

```
import { GestureHandlerRootView } from 'react-native-gesture-handler';

export default function App() {
  return (
    <GestureHandlerRootView>
      <ActualApp />
    </GestureHandlerRootView>
  );
}
```

If you don't provide anything to the `styles` prop, it will default to `flex: 1`. If you want to customize the styling of the root view, don't forget to also include `flex: 1` in the custom style, otherwise your app won't render anything. Keep `GestureHandlerRootView` as close to the actual root of the app as possible. It's the entry point for all gestures and all gesture relations. The gestures won't be recognized outside of the root view, and relations only work between gestures mounted under the same root view.

If you're unsure if one of your dependencies already renders `GestureHandlerRootView` on its own, don't worry and add one at the root anyway. In case of nested root views, Gesture Handler will only use the top-most one and ignore the nested ones.

tip

If you're using gesture handler in your component library, you may want to wrap your library's code in the `GestureHandlerRootView` component. This will avoid extra configuration for the user.

#### 3. Platform specific setup

##### Expo development build

When using an Expo development build, run prebuild to update the native code in the ios and android directories.

```
npx expo prebuild
```

##### Android

Setting up Gesture Handler on Android doesn't require any more steps. Keep in mind that if you want to use gestures in Modals you need to wrap Modal's content with `GestureHandlerRootView`:

```
import { Modal } from 'react-native';
import { GestureHandlerRootView } from 'react-native-gesture-handler';

export function CustomModal({ children, ...rest }) {
  return (
    <Modal {...rest}>
      <GestureHandlerRootView>
        {children}
      </GestureHandlerRootView>
    </Modal>
  );
}
```

###### Kotlin

Gesture Handler on Android is implemented in Kotlin. If you need to set a specific Kotlin version to be used by the library, set the `kotlinVersion` ext property in `android/build.gradle` file and RNGH will use that version:

```
buildscript {
    ext {
        kotlinVersion = "1.6.21"
    }
}
```

##### iOS

While developing for iOS, make sure to install pods first before running the app:

```
cd ios && pod install && cd ..
```

##### Web

There is no additional configuration required for the web, however, since the Gesture Handler 2.10.0 the new web implementation is enabled by default. We recommend you to check if the gestures in your app are working as expected since their behavior should now resemble the native platforms. If you don't want to use the new implementation, you can still revert back to the legacy one by enabling it at the beginning of your `index.js` file:

```
import { enableLegacyWebImplementation } from 'react-native-gesture-handler';

enableLegacyWebImplementation(true);
```

Nonetheless, it's recommended to adapt to the new implementation, as the legacy one will be dropped in the next major release of Gesture Handler.

##### With wix/react-native-navigation

If you are using a native navigation library like wix/react-native-navigation you need to make sure that every screen is wrapped with `GestureHandlerRootView` (you can do this using `gestureHandlerRootHOC` function). This can be done for example at the stage when you register your screens. Here's an example:

```
import { gestureHandlerRootHOC } from 'react-native-gesture-handler';
import { Navigation } from 'react-native-navigation';
import FirstTabScreen from './FirstTabScreen';
import SecondTabScreen from './SecondTabScreen';
import PushedScreen from './PushedScreen';
// register all screens of the app (including internal ones)
export function registerScreens() {
  Navigation.registerComponent(
    'example.FirstTabScreen',
    () => gestureHandlerRootHOC(FirstTabScreen),
    () => FirstTabScreen
  );
  Navigation.registerComponent(
    'example.SecondTabScreen',
    () => gestureHandlerRootHOC(SecondTabScreen),
    () => SecondTabScreen
  );
  Navigation.registerComponent(
    'example.PushedScreen',
    () => gestureHandlerRootHOC(PushedScreen),
    () => PushedScreen
  );
}
```

You can check out this example project to see this kind of set up in action.

Remember that you need to wrap each screen that you use in your app with `GestureHandlerRootView` (you can do this using `gestureHandlerRootHOC` function) as with native navigation libraries each screen maps to a separate root view. It will not be enough to wrap the main screen only.

## Rotation gesture

A continuous gesture that can recognize a rotation gesture and track its movement.

The gesture activates when fingers are placed on the screen and change position in a proper way.

Gesture callback can be used for continuous tracking of the rotation gesture. It provides information about the gesture such as the amount rotated, the focal point of the rotation (anchor), and its instantaneous velocity.

`Rotation Gesture`

### Example

```
import { StyleSheet } from 'react-native';
import { Gesture, GestureDetector } from 'react-native-gesture-handler';
import Animated, {
  useSharedValue,
  useAnimatedStyle,
} from 'react-native-reanimated';

export default function App() {
  const rotation = useSharedValue(1);
  const savedRotation = useSharedValue(1);

  const rotationGesture = Gesture.Rotation()
    .onUpdate((e) => {
      rotation.value = savedRotation.value + e.rotation;
    })
    .onEnd(() => {
      savedRotation.value = rotation.value;
    });

  const animatedStyle = useAnimatedStyle(() => ({
    transform: [{ rotateZ: `${(rotation.value / Math.PI) * 180}deg` }],
  }));

  return (
    <GestureDetector gesture={rotationGesture}>
      <Animated.View style={[styles.box, animatedStyle]} />
    </GestureDetector>
  );
}

const styles = StyleSheet.create({
  box: {
    height: 120,
    width: 120,
    backgroundColor: '#b58df1',
    borderRadius: 20,
    marginBottom: 30,
  },
});
```

### Config

#### Properties common to all gestures:

#### `enabled(value: boolean)`

Indicates whether the given handler should be analyzing stream of touch events or not. When set to `false` we can be sure that the handler's state will **never** become `ACTIVE`. If the value gets updated while the handler already started recognizing a gesture, then the handler's state it will immediately change to `FAILED` or `CANCELLED` (depending on its current state). Default value is `true`.

#### `shouldCancelWhenOutside(value: boolean)`

When `true` the handler will cancel or fail recognition (depending on its current state) whenever the finger leaves the area of the connected view. Default value of this property is different depending on the handler type. Most handlers' `shouldCancelWhenOutside` property defaults to `false` except for the `LongPressGesture` and `TapGesture` which default to `true`.

#### `hitSlop(settings)`

This parameter enables control over what part of the connected view area can be used to begin recognizing the gesture. When a negative number is provided the bounds of the view will reduce the area by the given number of points in each of the sides evenly.

Instead you can pass an object to specify how each boundary side should be reduced by providing different number of points for `left`, `right`, `top` or `bottom` sides. You can alternatively provide `horizontal` or `vertical` instead of specifying directly `left`, `right` or `top` and `bottom`. Finally, the object can also take `width` and `height` attributes. When `width` is set it is only allow to specify one of the sides `right` or `left`. Similarly when `height` is provided only `top` or `bottom` can be set. Specifying `width` or `height` is useful if we only want the gesture to activate on the edge of the view. In which case for example we can set `left: 0` and `width: 20` which would make it possible for the gesture to be recognize when started no more than 20 points from the left edge.

**IMPORTANT:** Note that this parameter is primarily designed to reduce the area where gesture can activate. Hence it is only supported for all the values (except `width` and `height`) to be non positive (0 or lower). Although on Android it is supported for the values to also be positive and therefore allow to expand beyond view bounds but not further than the parent view bounds. To achieve this effect on both platforms you can use React Native's View hitSlop property.

#### `withRef(ref)`

Sets a ref to the gesture object, allowing for interoperability with the old API.

#### `withTestId(testID)`

Sets a `testID` property for gesture object, allowing for querying for it in tests.

#### `cancelsTouchesInView(value)` (**iOS only**)

Accepts a boolean value. When `true`, the gesture will cancel touches for native UI components (`UIButton`, `UISwitch`, etc) it's attached to when it becomes `ACTIVE`. Default value is `true`.

#### `runOnJS(value: boolean)`

When `react-native-reanimated` is installed, the callbacks passed to the gestures are automatically workletized and run on the UI thread when called. This option allows for changing this behavior: when `true`, all the callbacks will be run on the JS thread instead of the UI thread, regardless of whether they are worklets or not. Defaults to `false`.

#### `simultaneousWithExternalGesture(otherGesture1, otherGesture2, ...)`

Adds a gesture that should be recognized simultaneously with this one.

**IMPORTANT:** Note that this method only marks the relation between gestures, without composing them. `GestureDetector` will not recognize the `otherGestures` and it needs to be added to another detector in order to be recognized.

#### `requireExternalGestureToFail(otherGesture1, otherGesture2, ...)`

Adds a relation requiring another gesture to fail, before this one can activate.

#### `blocksExternalGesture(otherGesture1, otherGesture2, ...)`

Adds a relation that makes other gestures wait with activation until this gesture fails (or doesn't start at all).

**IMPORTANT:** Note that this method only marks the relation between gestures, without composing them.`GestureDetector` will not recognize the `otherGestures` and it needs to be added to another detector in order to be recognized.

#### `activeCursor(value)` (Web only)

This parameter allows to specify which cursor should be used when gesture activates. Supports all CSS cursor values (e.g. `"grab"`, `"zoom-in"`). Default value is set to `"auto"`.

#### Properties common to all continuous gestures:

#### `manualActivation(value: boolean)`

When `true` the handler will not activate by itself even if its activation criteria are met. Instead you can manipulate its state using state manager.

### Callbacks

#### Callbacks common to all gestures:

#### `onBegin(callback)`

Set the callback that is being called when given gesture handler starts receiving touches. At the moment of this callback the handler is not yet in an active state and we don't know yet if it will recognize the gesture at all.

#### `onStart(callback)`

Set the callback that is being called when the gesture is recognized by the handler and it transitions to the active state.

#### `onEnd(callback)`

Set the callback that is being called when the gesture that was recognized by the handler finishes. It will be called only if the handler was previously in the active state.

#### `onFinalize(callback)`

Set the callback that is being called when the handler finalizes handling gesture - the gesture was recognized and has finished or it failed to recognize.

#### `onTouchesDown(callback)`

Set the `onTouchesDown` callback which is called every time a finger is placed on the screen.

#### `onTouchesMove(callback)`

Set the `onTouchesMove` callback which is called every time a finger is moved on the screen.

#### `onTouchesUp(callback)`

Set the `onTouchesUp` callback which is called every time a finger is lifted from the screen.

#### `onTouchesCancelled(callback)`

Set the `onTouchesCancelled` callback which is called every time a finger stops being tracked, for example when the gesture finishes.

#### Callbacks common to all continuous gestures:

#### `onUpdate(callback)`

Set the callback that is being called every time the gesture receives an update while it's active.

#### `onChange(callback)`

Set the callback that is being called every time the gesture receives an update while it's active. This callback will receive information about change in value in relation to the last received event.

### Event data

#### Event attributes specific to `RotationGesture`:

#### `rotation`

Amount rotated, expressed in radians, from the gesture's focal point (anchor).

#### `velocity`

Instantaneous velocity, expressed in point units per second, of the gesture.

#### `anchorX`

X coordinate, expressed in points, of the gesture's central focal point (anchor).

#### `anchorY`

Y coordinate, expressed in points, of the gesture's central focal point (anchor).

#### Event attributes common to all gestures:

#### `state`

Current state of the handler. Expressed as one of the constants exported under `State` object by the library.

#### `numberOfPointers`

Represents the number of pointers (fingers) currently placed on the screen.

#### `pointerType`

Indicates the type of pointer device in use. This value is represented by the `PointerType` enum, which includes the following fields:

- `TOUCH` - represents finger
- `STYLUS` - represents stylus or digital pen
- `MOUSE` - represents computer mouse
- `KEY` - represents keyboard
- `OTHER` - represents unknown device type that is not relevant

## Pinch gesture

A continuous gesture that recognizes pinch gesture. It allows for tracking the distance between two fingers and use that information to scale or zoom your content. The gesture activates when fingers are placed on the screen and change their position. Gesture callback can be used for continuous tracking of the pinch gesture. It provides information about velocity, anchor (focal) point of gesture and scale.

The distance between the fingers is reported as a scale factor. At the beginning of the gesture, the scale factor is 1.0. As the distance between the two fingers increases, the scale factor increases proportionally. Similarly, the scale factor decreases as the distance between the fingers decreases. Pinch gestures are used most commonly to change the size of objects or content onscreen. For example, map views use pinch gestures to change the zoom level of the map.

`Pinch Gesture`

### Example

```
import { StyleSheet } from 'react-native';
import { Gesture, GestureDetector } from 'react-native-gesture-handler';
import Animated, {
  useSharedValue,
  useAnimatedStyle,
} from 'react-native-reanimated';

export default function App() {
  const scale = useSharedValue(1);
  const savedScale = useSharedValue(1);

  const pinchGesture = Gesture.Pinch()
    .onUpdate((e) => {
      scale.value = savedScale.value * e.scale;
    })
    .onEnd(() => {
      savedScale.value = scale.value;
    });

  const animatedStyle = useAnimatedStyle(() => ({
    transform: [{ scale: scale.value }],
  }));

  return (
    <GestureDetector gesture={pinchGesture}>
      <Animated.View style={[styles.box, animatedStyle]} />
    </GestureDetector>
  );
}

const styles = StyleSheet.create({
  box: {
    height: 120,
    width: 120,
    backgroundColor: '#b58df1',
    borderRadius: 20,
    marginBottom: 30,
  },
});
```

### Config

#### Properties common to all gestures:

#### `enabled(value: boolean)`

Indicates whether the given handler should be analyzing stream of touch events or not. When set to `false` we can be sure that the handler's state will **never** become `ACTIVE`. If the value gets updated while the handler already started recognizing a gesture, then the handler's state it will immediately change to `FAILED` or `CANCELLED` (depending on its current state). Default value is `true`.

#### `shouldCancelWhenOutside(value: boolean)`

When `true` the handler will cancel or fail recognition (depending on its current state) whenever the finger leaves the area of the connected view. Default value of this property is different depending on the handler type. Most handlers' `shouldCancelWhenOutside` property defaults to `false` except for the `LongPressGesture` and `TapGesture` which default to `true`.

#### `hitSlop(settings)`

This parameter enables control over what part of the connected view area can be used to begin recognizing the gesture. When a negative number is provided the bounds of the view will reduce the area by the given number of points in each of the sides evenly.

Instead you can pass an object to specify how each boundary side should be reduced by providing different number of points for `left`, `right`, `top` or `bottom` sides. You can alternatively provide `horizontal` or `vertical` instead of specifying directly `left`, `right` or `top` and `bottom`. Finally, the object can also take `width` and `height` attributes. When `width` is set it is only allow to specify one of the sides `right` or `left`. Similarly when `height` is provided only `top` or `bottom` can be set. Specifying `width` or `height` is useful if we only want the gesture to activate on the edge of the view. In which case for example we can set `left: 0` and `width: 20` which would make it possible for the gesture to be recognize when started no more than 20 points from the left edge.

**IMPORTANT:** Note that this parameter is primarily designed to reduce the area where gesture can activate. Hence it is only supported for all the values (except `width` and `height`) to be non positive (0 or lower). Although on Android it is supported for the values to also be positive and therefore allow to expand beyond view bounds but not further than the parent view bounds. To achieve this effect on both platforms you can use React Native's View hitSlop property.

#### `withRef(ref)`

Sets a ref to the gesture object, allowing for interoperability with the old API.

#### `withTestId(testID)`

Sets a `testID` property for gesture object, allowing for querying for it in tests.

#### `cancelsTouchesInView(value)` (**iOS only**)

Accepts a boolean value. When `true`, the gesture will cancel touches for native UI components (`UIButton`, `UISwitch`, etc) it's attached to when it becomes `ACTIVE`. Default value is `true`.

#### `runOnJS(value: boolean)`

When `react-native-reanimated` is installed, the callbacks passed to the gestures are automatically workletized and run on the UI thread when called. This option allows for changing this behavior: when `true`, all the callbacks will be run on the JS thread instead of the UI thread, regardless of whether they are worklets or not. Defaults to `false`.

#### `simultaneousWithExternalGesture(otherGesture1, otherGesture2, ...)`

Adds a gesture that should be recognized simultaneously with this one.

**IMPORTANT:** Note that this method only marks the relation between gestures, without composing them. `GestureDetector` will not recognize the `otherGestures` and it needs to be added to another detector in order to be recognized.

#### `requireExternalGestureToFail(otherGesture1, otherGesture2, ...)`

Adds a relation requiring another gesture to fail, before this one can activate.

#### `blocksExternalGesture(otherGesture1, otherGesture2, ...)`

Adds a relation that makes other gestures wait with activation until this gesture fails (or doesn't start at all).

**IMPORTANT:** Note that this method only marks the relation between gestures, without composing them.`GestureDetector` will not recognize the `otherGestures` and it needs to be added to another detector in order to be recognized.

#### `activeCursor(value)` (Web only)

This parameter allows to specify which cursor should be used when gesture activates. Supports all CSS cursor values (e.g. `"grab"`, `"zoom-in"`). Default value is set to `"auto"`.

#### Properties common to all continuous gestures:

#### `manualActivation(value: boolean)`

When `true` the handler will not activate by itself even if its activation criteria are met. Instead you can manipulate its state using state manager.

### Callbacks

#### Callbacks common to all gestures:

#### `onBegin(callback)`

Set the callback that is being called when given gesture handler starts receiving touches. At the moment of this callback the handler is not yet in an active state and we don't know yet if it will recognize the gesture at all.

#### `onStart(callback)`

Set the callback that is being called when the gesture is recognized by the handler and it transitions to the active state.

#### `onEnd(callback)`

Set the callback that is being called when the gesture that was recognized by the handler finishes. It will be called only if the handler was previously in the active state.

#### `onFinalize(callback)`

Set the callback that is being called when the handler finalizes handling gesture - the gesture was recognized and has finished or it failed to recognize.

#### `onTouchesDown(callback)`

Set the `onTouchesDown` callback which is called every time a finger is placed on the screen.

#### `onTouchesMove(callback)`

Set the `onTouchesMove` callback which is called every time a finger is moved on the screen.

#### `onTouchesUp(callback)`

Set the `onTouchesUp` callback which is called every time a finger is lifted from the screen.

#### `onTouchesCancelled(callback)`

Set the `onTouchesCancelled` callback which is called every time a finger stops being tracked, for example when the gesture finishes.

#### Callbacks common to all continuous gestures:

#### `onUpdate(callback)`

Set the callback that is being called every time the gesture receives an update while it's active.

#### `onChange(callback)`

Set the callback that is being called every time the gesture receives an update while it's active. This callback will receive information about change in value in relation to the last received event.

### Event data

#### Event attributes specific to `PinchGesture`:

#### `scale`

The scale factor relative to the points of the two touches in screen coordinates.

#### `velocity`

Velocity of the pan gesture the current moment. The value is expressed in scale factor per second.

#### `focalX`

Position expressed in points along X axis of center anchor point of gesture

#### `focalY`

Position expressed in points along Y axis of center anchor point of gesture

#### Event attributes common to all gestures:

#### `state`

Current state of the handler. Expressed as one of the constants exported under `State` object by the library.

#### `numberOfPointers`

Represents the number of pointers (fingers) currently placed on the screen.

#### `pointerType`

Indicates the type of pointer device in use. This value is represented by the `PointerType` enum, which includes the following fields:

- `TOUCH` - represents finger
- `STYLUS` - represents stylus or digital pen
- `MOUSE` - represents computer mouse
- `KEY` - represents keyboard
- `OTHER` - represents unknown device type that is not relevant

A continuous gesture that recognizes force of a touch. It allows for tracking pressure of touch on some iOS devices. The gesture activates when pressure of touch if greater or equal than `minForce`. It fails if pressure is greater than `maxForce` Gesture callback can be used for continuous tracking of the touch pressure. It provides information for one finger (the first one).

At the beginning of the gesture, the pressure factor is 0.0. As the pressure increases, the pressure factor increases proportionally. The maximum pressure is 1.0.

There's no implementation provided on Android and it simply renders children without any wrappers. Since this behaviour is only provided on some iOS devices, this gesture should not be used for defining any crucial behaviors. Use it only as an additional improvement and make all features to be accessed without this gesture as well.

## Reference

```
import { GestureDetector, Gesture } from 'react-native-gesture-handler';

function App() {
  const forceTouch = Gesture.ForceTouch();

  return (
    <GestureDetector gesture={forceTouch}>
      <View />
    </GestureDetector>
  );
}
```

### Config

#### Properties specific to `ForceTouchGesture`:

#### `minForce(value: number)`

A minimal pressure that is required before gesture can activate. Should be a value from range `[0.0, 1.0]`. Default is `0.2`.

#### `maxForce(value: number)`

A maximal pressure that could be applied for gesture. If the pressure is greater, gesture fails. Should be a value from range `[0.0, 1.0]`.

#### `feedbackOnActivation(value: boolean)`

Value defining if haptic feedback has to be performed on activation.

#### Properties common to all gestures:

#### `enabled(value: boolean)`

Indicates whether the given handler should be analyzing stream of touch events or not. When set to `false` we can be sure that the handler's state will **never** become `ACTIVE`. If the value gets updated while the handler already started recognizing a gesture, then the handler's state it will immediately change to `FAILED` or `CANCELLED` (depending on its current state). Default value is `true`.

#### `shouldCancelWhenOutside(value: boolean)`

When `true` the handler will cancel or fail recognition (depending on its current state) whenever the finger leaves the area of the connected view. Default value of this property is different depending on the handler type. Most handlers' `shouldCancelWhenOutside` property defaults to `false` except for the `LongPressGesture` and `TapGesture` which default to `true`.

#### `hitSlop(settings)`

This parameter enables control over what part of the connected view area can be used to begin recognizing the gesture. When a negative number is provided the bounds of the view will reduce the area by the given number of points in each of the sides evenly.

Instead you can pass an object to specify how each boundary side should be reduced by providing different number of points for `left`, `right`, `top` or `bottom` sides. You can alternatively provide `horizontal` or `vertical` instead of specifying directly `left`, `right` or `top` and `bottom`. Finally, the object can also take `width` and `height` attributes. When `width` is set it is only allow to specify one of the sides `right` or `left`. Similarly when `height` is provided only `top` or `bottom` can be set. Specifying `width` or `height` is useful if we only want the gesture to activate on the edge of the view. In which case for example we can set `left: 0` and `width: 20` which would make it possible for the gesture to be recognize when started no more than 20 points from the left edge.

**IMPORTANT:** Note that this parameter is primarily designed to reduce the area where gesture can activate. Hence it is only supported for all the values (except `width` and `height`) to be non positive (0 or lower). Although on Android it is supported for the values to also be positive and therefore allow to expand beyond view bounds but not further than the parent view bounds. To achieve this effect on both platforms you can use React Native's View hitSlop property.

#### `withRef(ref)`

Sets a ref to the gesture object, allowing for interoperability with the old API.

#### `withTestId(testID)`

Sets a `testID` property for gesture object, allowing for querying for it in tests.

#### `cancelsTouchesInView(value)` (**iOS only**)

Accepts a boolean value. When `true`, the gesture will cancel touches for native UI components (`UIButton`, `UISwitch`, etc) it's attached to when it becomes `ACTIVE`. Default value is `true`.

#### `runOnJS(value: boolean)`

When `react-native-reanimated` is installed, the callbacks passed to the gestures are automatically workletized and run on the UI thread when called. This option allows for changing this behavior: when `true`, all the callbacks will be run on the JS thread instead of the UI thread, regardless of whether they are worklets or not. Defaults to `false`.

#### `simultaneousWithExternalGesture(otherGesture1, otherGesture2, ...)`

Adds a gesture that should be recognized simultaneously with this one.

**IMPORTANT:** Note that this method only marks the relation between gestures, without composing them. `GestureDetector` will not recognize the `otherGestures` and it needs to be added to another detector in order to be recognized.

#### `requireExternalGestureToFail(otherGesture1, otherGesture2, ...)`

Adds a relation requiring another gesture to fail, before this one can activate.

#### `blocksExternalGesture(otherGesture1, otherGesture2, ...)`

Adds a relation that makes other gestures wait with activation until this gesture fails (or doesn't start at all).

**IMPORTANT:** Note that this method only marks the relation between gestures, without composing them.`GestureDetector` will not recognize the `otherGestures` and it needs to be added to another detector in order to be recognized.

#### `activeCursor(value)` (Web only)

This parameter allows to specify which cursor should be used when gesture activates. Supports all CSS cursor values (e.g. `"grab"`, `"zoom-in"`). Default value is set to `"auto"`.

#### Properties common to all continuous gestures:

#### `manualActivation(value: boolean)`

When `true` the handler will not activate by itself even if its activation criteria are met. Instead you can manipulate its state using state manager.

### Callbacks

#### Callbacks common to all gestures:

#### `onBegin(callback)`

Set the callback that is being called when given gesture handler starts receiving touches. At the moment of this callback the handler is not yet in an active state and we don't know yet if it will recognize the gesture at all.

#### `onStart(callback)`

Set the callback that is being called when the gesture is recognized by the handler and it transitions to the active state.

#### `onEnd(callback)`

Set the callback that is being called when the gesture that was recognized by the handler finishes. It will be called only if the handler was previously in the active state.

#### `onFinalize(callback)`

Set the callback that is being called when the handler finalizes handling gesture - the gesture was recognized and has finished or it failed to recognize.

#### `onTouchesDown(callback)`

Set the `onTouchesDown` callback which is called every time a finger is placed on the screen.

#### `onTouchesMove(callback)`

Set the `onTouchesMove` callback which is called every time a finger is moved on the screen.

#### `onTouchesUp(callback)`

Set the `onTouchesUp` callback which is called every time a finger is lifted from the screen.

#### `onTouchesCancelled(callback)`

Set the `onTouchesCancelled` callback which is called every time a finger stops being tracked, for example when the gesture finishes.

#### Callbacks common to all continuous gestures:

#### `onUpdate(callback)`

Set the callback that is being called every time the gesture receives an update while it's active.

#### `onChange(callback)`

Set the callback that is being called every time the gesture receives an update while it's active. This callback will receive information about change in value in relation to the last received event.

### Event data

#### Event attributes specific to `ForceTouchGesture`:

#### `force`

The pressure of a touch.

#### Event attributes common to all gestures:

#### `state`

Current state of the handler. Expressed as one of the constants exported under `State` object by the library.

#### `numberOfPointers`

Represents the number of pointers (fingers) currently placed on the screen.

#### `pointerType`

Indicates the type of pointer device in use. This value is represented by the `PointerType` enum, which includes the following fields:

- `TOUCH` - represents finger
- `STYLUS` - represents stylus or digital pen
- `MOUSE` - represents computer mouse
- `KEY` - represents keyboard
- `OTHER` - represents unknown device type that is not relevant

## Buttons

Gesture handler library provides native components that can act as buttons. These can be treated as a replacement to `TouchableHighlight` or `TouchableOpacity` from RN core. Gesture handler's buttons recognize touches in native which makes the recognition process deterministic, allows for rendering ripples on Android in highly performant way (`TouchableNativeFeedback` requires that touch event does a roundtrip to JS before we can update ripple effect, which makes ripples lag a bit on older phones), and provides native and platform default interaction for buttons that are placed in a scrollable container (in which case the interaction is slightly delayed to prevent button from highlighting when you fling).

Currently Gesture handler library exposes three components that render native touchable elements under the hood:

-
-
-

On top of that all the buttons are wrapped with `NativeViewGestureHandler` and therefore allow for all the common gesture handler properties and `NativeViewGestureHandler`'s extra properties to be applied to them.

**IMPORTANT**: In order to make buttons accessible, you have to wrap your children in a `View` with `accessible` and `accessibilityRole="button"` props. Example:

```
// Not accessible:
const NotAccessibleButton = () => (
  <RectButton onPress={this._onPress}>
    <Text>Foo</Text>
  </RectButton>
);
// Accessible:
const AccessibleButton = () => (
  <RectButton onPress={this._onPress}>
    <View accessible accessibilityRole="button">
      <Text>Bar</Text>
    </View>
  </RectButton>
);
```

It is applicable for both iOS and Android platform. On iOS, you won't be able to even select the button, on Android you won't be able to click it in accessibility mode.

### `BaseButton`

Can be used as a base class if you'd like to implement some custom interaction for when the button is pressed.

Below is a list of properties specific to `BaseButton` component:

#### `onActiveStateChange`

function that gets triggered when button changes from inactive to active and vice versa. It passes active state as a boolean variable as a first parameter for that method.

#### `onPress`

function that gets triggered when the button gets pressed (analogous to `onPress` in `TouchableHighlight` from RN core).

#### `onLongPress`

function that gets triggered when the button gets pressed for at least `delayLongPress` milliseconds.

#### `rippleColor` (**Android only**)

defines color of native ripple animation used since API level 21.

#### `exclusive`

defines if more than one button could be pressed simultaneously. By default set `true`.

#### `delayLongPress`

defines the delay, in milliseconds, after which the `onLongPress` callback gets called. By default set to 600.

### `RectButton`

This type of button component should be used when you deal with rectangular elements or blocks of content that can be pressed, for example table rows or buttons with text and icons. This component provides a platform specific interaction, rendering a rectangular ripple on Android or highlighting the background on iOS and on older versions of Android. In addition to the props of `BaseButton`, it accepts the following:

Below is a list of properties specific to `RectButton` component:

#### `underlayColor`

this is the background color that will be dimmed when button is in active state.

#### `activeOpacity` (**iOS only**)

opacity applied to the underlay when button is in active state.

### `BorderlessButton`

This type of button component should be used with simple icon-only or text-only buttons. The interaction will be different depending on platform: on Android a borderless ripple will be rendered (it means that the ripple will animate into a circle that can span outside of the view bounds), whereas on iOS the button will be dimmed (similar to how `TouchableOpacity` works). In addition to the props of `BaseButton`, it accepts the following:

Below is a list of properties specific to `BorderlessButton` component:

#### `borderless` (**Android only**)

set this to `false` if you want the ripple animation to render only within view bounds.

#### `activeOpacity` (**iOS only**)

opacity applied to the button when it is in an active state.

### Design patterns

Components listed here were not designed to behave and look in the same way on both platforms but rather to be used for handling similar behaviour on iOS and Android taking into consideration their's design concepts.

If you wish to get specific information about platforms design patterns, visit official Apple docs and Material.io guideline, which widely describe how to implement coherent design.

This library allows to use native components with native feedback in adequate situations.

If you do not wish to implement custom design approach, `RectButton` and `BorderlessButton` seem to be absolutely enough and there's no need to use anything else. In all the remaining cases you can always rely on `BaseButton` which is a superclass for the other button classes and can be used as a generic `Touchable` replacement that can be customized to your needs.

Below we list some of the common usecases for button components to be used along with the type of button that should be used according to the platform specific design guidelines.

#### Lists and action buttons

If you have a list with clickable items or have an action button that need to display as a separate UI block (vs being inlined in a text) you should use `RectButton`. It changes opacity on click and additionally supports a ripple effect on Android.

To determine emphasis of button it's vital to use fill color or leave it transparent especially on Android. For medium emphasis you may consider outlined buttons which are used for lower impact than fill buttons.

#### Icon or text only buttons

Use `BorderlessButton` for simple icon-only or text-only buttons. The interaction will be different depending on platform: on Android a borderless ripple will be rendered, whereas on iOS the button will be dimmed. It should be used if you wish to handle non-crucial actions and supportive behaviour.

#### `PureNativeButton`

Use a `PureNativeButton` for accessing the native Component used for build more complex buttons listed above. It's normally is not recommended to use, but it might be useful if we want to wrap it using Animated or Reanimated.

```
import {
  createNativeWrapper,
  PureNativeButton,
} from 'react-native-gesture-handler';
import Animated from 'react-native-reanimated';
const { event, Value, createAnimatedComponent } = Animated;

const AnimatedRawButton = createNativeWrapper(
  createAnimatedComponent(PureNativeButton),
  {
    shouldCancelWhenOutside: false,
    shouldActivateOnStart: false,
  }
);

export default class App extends React.Component {
  constructor(props) {
    super(props);
    const state = new Value();
    this._onGestureEvent = event([
      {
        nativeEvent: { state },
      },
    ]);
  }

  render() {
    return <AnimatedRawButton onHandlerStateChange={this._onGestureEvent} />;
  }
}
```

## Pan gesture

A continuous gesture that can recognize a panning (dragging) gesture and track its movement.

The gesture activates when a finger is placed on the screen and moved some initial distance.

Configurations such as a minimum initial distance, specific vertical or horizontal pan detection and number of fingers required for activation (allowing for multifinger swipes) may be specified.

Gesture callback can be used for continuous tracking of the pan gesture. It provides information about the gesture such as its XY translation from the starting point as well as its instantaneous velocity.

`Pan Gesture`

### Example

```
import { StyleSheet } from 'react-native';
import { Gesture, GestureDetector } from 'react-native-gesture-handler';
import Animated, {
  useSharedValue,
  withTiming,
  useAnimatedStyle,
} from 'react-native-reanimated';

const END_POSITION = 200;

export default function App() {
  const onLeft = useSharedValue(true);
  const position = useSharedValue(0);

  const panGesture = Gesture.Pan()
    .onUpdate((e) => {
      if (onLeft.value) {
        position.value = e.translationX;
      } else {
        position.value = END_POSITION + e.translationX;
      }
    })
    .onEnd((e) => {
      if (position.value > END_POSITION / 2) {
        position.value = withTiming(END_POSITION, { duration: 100 });
        onLeft.value = false;
      } else {
        position.value = withTiming(0, { duration: 100 });
        onLeft.value = true;
      }
    });

  const animatedStyle = useAnimatedStyle(() => ({
    transform: [{ translateX: position.value }],
  }));

  return (
    <GestureDetector gesture={panGesture}>
      <Animated.View style={[styles.box, animatedStyle]} />
    </GestureDetector>
  );
}

const styles = StyleSheet.create({
  box: {
    height: 120,
    width: 120,
    backgroundColor: '#b58df1',
    borderRadius: 20,
    marginBottom: 30,
  },
});
```

### Multi touch pan handling

If your app relies on multi touch pan handling this section provides some information how the default behavior differs between the platform and how (if necessary) it can be unified.

The difference in multi touch pan handling lies in the way how translation properties during the event are being calculated. On iOS the default behavior when more than one finger is placed on the screen is to treat this situation as if only one pointer was placed in the center of mass (average position of all the pointers). This applies also to many platform native components that handle touch even if not primarily interested in multi touch interactions like for example UIScrollView component.

On Android, the default behavior for native components like scroll view, pager views or drawers is different and hence gesture defaults to that when it comes to pan handling. The difference is that instead of treating the center of mass of all the fingers placed as a leading pointer it takes the latest placed finger as such. This behavior can be changed on Android using `averageTouches` flag.

Note that on both Android and iOS when the additional finger is placed on the screen that translation prop is not affected even though the position of the pointer being tracked might have changed. Therefore it is safe to rely on translation most of the time as it only reflects the movement that happens regardless of how many fingers are placed on the screen and if that number changes over time. If you wish to track the "center of mass" virtual pointer and account for its changes when the number of finger changes you can use relative or absolute position provided in the event (`x` and `y` or `absoluteX` and `absoluteY`).

### Config

#### Properties specific to `PanGesture`:

#### `minDistance(value: number)`

Minimum distance the finger (or multiple finger) need to travel before the gesture activates. Expressed in points.

#### `minPointers(value: number)`

A number of fingers that is required to be placed before gesture can activate. Should be a higher or equal to 0 integer.

#### `maxPointers(value: number)`

When the given number of fingers is placed on the screen and gesture hasn't yet activated it will fail recognizing the gesture. Should be a higher or equal to 0 integer.

#### `activateAfterLongPress(duration: number)`

Duration in milliseconds of the `LongPress` gesture before `Pan` is allowed to activate. If the finger is moved during that period, the gesture will fail. Should be a higher or equal to 0 integer. Default value is 0, meaning no `LongPress` is required to activate the `Pan`.

#### `activeOffsetX(value: number | number[])`

Range along X axis (in points) where fingers travels without activation of gesture. Moving outside of this range implies activation of gesture. Range can be given as an array or a single number. If range is set as an array, first value must be lower or equal to 0, a the second one higher or equal to 0. If only one number `p` is given a range of `(-inf, p)` will be used if `p` is higher or equal to 0 and `(-p, inf)` otherwise.

#### `activeOffsetY(value: number | number[])`

Range along Y axis (in points) where fingers travels without activation of gesture. Moving outside of this range implies activation of gesture. Range can be given as an array or a single number. If range is set as an array, first value must be lower or equal to 0, a the second one higher or equal to 0. If only one number `p` is given a range of `(-inf, p)` will be used if `p` is higher or equal to 0 and `(-p, inf)` otherwise.

#### `failOffsetY(value: number | number[])`

When the finger moves outside this range (in points) along Y axis and gesture hasn't yet activated it will fail recognizing the gesture. Range can be given as an array or a single number. If range is set as an array, first value must be lower or equal to 0, a the second one higher or equal to 0. If only one number `p` is given a range of `(-inf, p)` will be used if `p` is higher or equal to 0 and `(-p, inf)` otherwise.

#### `failOffsetX(value: number | number[])`

When the finger moves outside this range (in points) along X axis and gesture hasn't yet activated it will fail recognizing the gesture. Range can be given as an array or a single number. If range is set as an array, first value must be lower or equal to 0, a the second one higher or equal to 0. If only one number `p` is given a range of `(-inf, p)` will be used if `p` is higher or equal to 0 and `(-p, inf)` otherwise.

#### `averageTouches(value: boolean)` (Android only)

Android, by default, will calculate translation values based on the position of the leading pointer (the first one that was placed on the screen). This modifier allows that behavior to be changed to the one that is default on iOS - the averaged position of all active pointers will be used to calculate the translation values.

#### `enableTrackpadTwoFingerGesture(value: boolean)` (iOS only)

Enables two-finger gestures on supported devices, for example iPads with trackpads. If not enabled the gesture will require click + drag, with enableTrackpadTwoFingerGesture swiping with two fingers will also trigger the gesture.

#### `mouseButton(value: MouseButton)` (Web & Android only)

Allows users to choose which mouse button should handler respond to. The enum `MouseButton` consists of the following predefined fields:

- `LEFT`
- `RIGHT`
- `MIDDLE`
- `BUTTON_4`
- `BUTTON_5`
- `ALL`

Arguments can be combined using `|` operator, e.g. `mouseButton(MouseButton.LEFT | MouseButton.RIGHT)`. Default value is set to `MouseButton.LEFT`.

#### Properties common to all gestures:

#### `enabled(value: boolean)`

Indicates whether the given handler should be analyzing stream of touch events or not. When set to `false` we can be sure that the handler's state will **never** become `ACTIVE`. If the value gets updated while the handler already started recognizing a gesture, then the handler's state it will immediately change to `FAILED` or `CANCELLED` (depending on its current state). Default value is `true`.

#### `shouldCancelWhenOutside(value: boolean)`

When `true` the handler will cancel or fail recognition (depending on its current state) whenever the finger leaves the area of the connected view. Default value of this property is different depending on the handler type. Most handlers' `shouldCancelWhenOutside` property defaults to `false` except for the `LongPressGesture` and `TapGesture` which default to `true`.

#### `hitSlop(settings)`

This parameter enables control over what part of the connected view area can be used to begin recognizing the gesture. When a negative number is provided the bounds of the view will reduce the area by the given number of points in each of the sides evenly.

Instead you can pass an object to specify how each boundary side should be reduced by providing different number of points for `left`, `right`, `top` or `bottom` sides. You can alternatively provide `horizontal` or `vertical` instead of specifying directly `left`, `right` or `top` and `bottom`. Finally, the object can also take `width` and `height` attributes. When `width` is set it is only allow to specify one of the sides `right` or `left`. Similarly when `height` is provided only `top` or `bottom` can be set. Specifying `width` or `height` is useful if we only want the gesture to activate on the edge of the view. In which case for example we can set `left: 0` and `width: 20` which would make it possible for the gesture to be recognize when started no more than 20 points from the left edge.

**IMPORTANT:** Note that this parameter is primarily designed to reduce the area where gesture can activate. Hence it is only supported for all the values (except `width` and `height`) to be non positive (0 or lower). Although on Android it is supported for the values to also be positive and therefore allow to expand beyond view bounds but not further than the parent view bounds. To achieve this effect on both platforms you can use React Native's View hitSlop property.

#### `withRef(ref)`

Sets a ref to the gesture object, allowing for interoperability with the old API.

#### `withTestId(testID)`

Sets a `testID` property for gesture object, allowing for querying for it in tests.

#### `cancelsTouchesInView(value)` (**iOS only**)

Accepts a boolean value. When `true`, the gesture will cancel touches for native UI components (`UIButton`, `UISwitch`, etc) it's attached to when it becomes `ACTIVE`. Default value is `true`.

#### `runOnJS(value: boolean)`

When `react-native-reanimated` is installed, the callbacks passed to the gestures are automatically workletized and run on the UI thread when called. This option allows for changing this behavior: when `true`, all the callbacks will be run on the JS thread instead of the UI thread, regardless of whether they are worklets or not. Defaults to `false`.

#### `simultaneousWithExternalGesture(otherGesture1, otherGesture2, ...)`

Adds a gesture that should be recognized simultaneously with this one.

**IMPORTANT:** Note that this method only marks the relation between gestures, without composing them. `GestureDetector` will not recognize the `otherGestures` and it needs to be added to another detector in order to be recognized.

#### `requireExternalGestureToFail(otherGesture1, otherGesture2, ...)`

Adds a relation requiring another gesture to fail, before this one can activate.

#### `blocksExternalGesture(otherGesture1, otherGesture2, ...)`

Adds a relation that makes other gestures wait with activation until this gesture fails (or doesn't start at all).

**IMPORTANT:** Note that this method only marks the relation between gestures, without composing them.`GestureDetector` will not recognize the `otherGestures` and it needs to be added to another detector in order to be recognized.

#### `activeCursor(value)` (Web only)

This parameter allows to specify which cursor should be used when gesture activates. Supports all CSS cursor values (e.g. `"grab"`, `"zoom-in"`). Default value is set to `"auto"`.

#### Properties common to all continuous gestures:

#### `manualActivation(value: boolean)`

When `true` the handler will not activate by itself even if its activation criteria are met. Instead you can manipulate its state using state manager.

### Callbacks

#### Callbacks common to all gestures:

#### `onBegin(callback)`

Set the callback that is being called when given gesture handler starts receiving touches. At the moment of this callback the handler is not yet in an active state and we don't know yet if it will recognize the gesture at all.

#### `onStart(callback)`

Set the callback that is being called when the gesture is recognized by the handler and it transitions to the active state.

#### `onEnd(callback)`

Set the callback that is being called when the gesture that was recognized by the handler finishes. It will be called only if the handler was previously in the active state.

#### `onFinalize(callback)`

Set the callback that is being called when the handler finalizes handling gesture - the gesture was recognized and has finished or it failed to recognize.

#### `onTouchesDown(callback)`

Set the `onTouchesDown` callback which is called every time a finger is placed on the screen.

#### `onTouchesMove(callback)`

Set the `onTouchesMove` callback which is called every time a finger is moved on the screen.

#### `onTouchesUp(callback)`

Set the `onTouchesUp` callback which is called every time a finger is lifted from the screen.

#### `onTouchesCancelled(callback)`

Set the `onTouchesCancelled` callback which is called every time a finger stops being tracked, for example when the gesture finishes.

#### Callbacks common to all continuous gestures:

#### `onUpdate(callback)`

Set the callback that is being called every time the gesture receives an update while it's active.

#### `onChange(callback)`

Set the callback that is being called every time the gesture receives an update while it's active. This callback will receive information about change in value in relation to the last received event.

### Event data

#### Event attributes specific to `PanGesture`:

#### `translationX`

Translation of the pan gesture along X axis accumulated over the time of the gesture. The value is expressed in the point units.

#### `translationY`

Translation of the pan gesture along Y axis accumulated over the time of the gesture. The value is expressed in the point units.

#### `velocityX`

Velocity of the pan gesture along the X axis in the current moment. The value is expressed in point units per second.

#### `velocityY`

Velocity of the pan gesture along the Y axis in the current moment. The value is expressed in point units per second.

#### `x`

X coordinate of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the view attached to the `GestureDetector`. Expressed in point units.

#### `y`

Y coordinate of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the view attached to the `GestureDetector`. Expressed in point units.

#### `absoluteX`

X coordinate of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the window. The value is expressed in point units. It is recommended to use it instead of `x` in cases when the original view can be transformed as an effect of the gesture.

#### `absoluteY`

Y coordinate of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the window. The value is expressed in point units. It is recommended to use it instead of `y` in cases when the original view can be transformed as an effect of the gesture.

#### `stylusData`

Object that contains additional information about `stylus`. It consists of the following fields:

- `tiltX` - angle in degrees between the Y-Z plane of the stylus and the screen.
- `tiltY` - angle in degrees between the X-Z plane of the stylus and the screen.
- `altitudeAngle` - angle between stylus axis and the X-Y plane of a device screen.
- `azimuthAngle` - angle between the Y-Z plane and the plane containing both the stylus axis and the Y axis.
- `pressure` - indicates the normalized pressure of the stylus.

#### Event attributes common to all gestures:

#### `state`

Current state of the handler. Expressed as one of the constants exported under `State` object by the library.

#### `numberOfPointers`

Represents the number of pointers (fingers) currently placed on the screen.

#### `pointerType`

Indicates the type of pointer device in use. This value is represented by the `PointerType` enum, which includes the following fields:

- `TOUCH` - represents finger
- `STYLUS` - represents stylus or digital pen
- `MOUSE` - represents computer mouse
- `KEY` - represents keyboard
- `OTHER` - represents unknown device type that is not relevant

## Buttons

Gesture handler library provides native components that can act as buttons. These can be treated as a replacement to `TouchableHighlight` or `TouchableOpacity` from RN core. Gesture handler's buttons recognize touches in native which makes the recognition process deterministic, allows for rendering ripples on Android in highly performant way (`TouchableNativeFeedback` requires that touch event does a roundtrip to JS before we can update ripple effect, which makes ripples lag a bit on older phones), and provides native and platform default interaction for buttons that are placed in a scrollable container (in which case the interaction is slightly delayed to prevent button from highlighting when you fling).

Currently Gesture handler library exposes three components that render native touchable elements under the hood:

-
-
-

On top of that all the buttons are wrapped with `NativeViewGestureHandler` and therefore allow for all the common gesture handler properties and `NativeViewGestureHandler`'s extra properties to be applied to them.

**IMPORTANT**: In order to make buttons accessible, you have to wrap your children in a `View` with `accessible` and `accessibilityRole="button"` props. Example:

```
// Not accessible:
const NotAccessibleButton = () => (
  <RectButton onPress={this._onPress}>
    <Text>Foo</Text>
  </RectButton>
);
// Accessible:
const AccessibleButton = () => (
  <RectButton onPress={this._onPress}>
    <View accessible accessibilityRole="button">
      <Text>Bar</Text>
    </View>
  </RectButton>
);
```

It is applicable for both iOS and Android platform. On iOS, you won't be able to even select the button, on Android you won't be able to click it in accessibility mode.

### `BaseButton`

Can be used as a base class if you'd like to implement some custom interaction for when the button is pressed.

Below is a list of properties specific to `BaseButton` component:

#### `onActiveStateChange`

function that gets triggered when button changes from inactive to active and vice versa. It passes active state as a boolean variable as a first parameter for that method.

#### `onPress`

function that gets triggered when the button gets pressed (analogous to `onPress` in `TouchableHighlight` from RN core).

#### `onLongPress`

function that gets triggered when the button gets pressed for at least `delayLongPress` milliseconds.

#### `rippleColor` (**Android only**)

defines color of native ripple animation used since API level 21.

#### `exclusive`

defines if more than one button could be pressed simultaneously. By default set `true`.

#### `delayLongPress`

defines the delay, in milliseconds, after which the `onLongPress` callback gets called. By default set to 600.

### `RectButton`

This type of button component should be used when you deal with rectangular elements or blocks of content that can be pressed, for example table rows or buttons with text and icons. This component provides a platform specific interaction, rendering a rectangular ripple on Android or highlighting the background on iOS and on older versions of Android. In addition to the props of `BaseButton`, it accepts the following:

Below is a list of properties specific to `RectButton` component:

#### `underlayColor`

this is the background color that will be dimmed when button is in active state.

#### `activeOpacity` (**iOS only**)

opacity applied to the underlay when button is in active state.

### `BorderlessButton`

This type of button component should be used with simple icon-only or text-only buttons. The interaction will be different depending on platform: on Android a borderless ripple will be rendered (it means that the ripple will animate into a circle that can span outside of the view bounds), whereas on iOS the button will be dimmed (similar to how `TouchableOpacity` works). In addition to the props of `BaseButton`, it accepts the following:

Below is a list of properties specific to `BorderlessButton` component:

#### `borderless` (**Android only**)

set this to `false` if you want the ripple animation to render only within view bounds.

#### `activeOpacity` (**iOS only**)

opacity applied to the button when it is in an active state.

### Design patterns

Components listed here were not designed to behave and look in the same way on both platforms but rather to be used for handling similar behaviour on iOS and Android taking into consideration their's design concepts.

If you wish to get specific information about platforms design patterns, visit official Apple docs and Material.io guideline, which widely describe how to implement coherent design.

This library allows to use native components with native feedback in adequate situations.

If you do not wish to implement custom design approach, `RectButton` and `BorderlessButton` seem to be absolutely enough and there's no need to use anything else. In all the remaining cases you can always rely on `BaseButton` which is a superclass for the other button classes and can be used as a generic `Touchable` replacement that can be customized to your needs.

Below we list some of the common usecases for button components to be used along with the type of button that should be used according to the platform specific design guidelines.

#### Lists and action buttons

If you have a list with clickable items or have an action button that need to display as a separate UI block (vs being inlined in a text) you should use `RectButton`. It changes opacity on click and additionally supports a ripple effect on Android.

To determine emphasis of button it's vital to use fill color or leave it transparent especially on Android. For medium emphasis you may consider outlined buttons which are used for lower impact than fill buttons.

#### Icon or text only buttons

Use `BorderlessButton` for simple icon-only or text-only buttons. The interaction will be different depending on platform: on Android a borderless ripple will be rendered, whereas on iOS the button will be dimmed. It should be used if you wish to handle non-crucial actions and supportive behaviour.

#### `PureNativeButton`

Use a `PureNativeButton` for accessing the native Component used for build more complex buttons listed above. It's normally is not recommended to use, but it might be useful if we want to wrap it using Animated or Reanimated.

```
import {
  createNativeWrapper,
  PureNativeButton,
} from 'react-native-gesture-handler';
import Animated from 'react-native-reanimated';
const { event, Value, createAnimatedComponent } = Animated;

const AnimatedRawButton = createNativeWrapper(
  createAnimatedComponent(PureNativeButton),
  {
    shouldCancelWhenOutside: false,
    shouldActivateOnStart: false,
  }
);

export default class App extends React.Component {
  constructor(props) {
    super(props);
    const state = new Value();
    this._onGestureEvent = event([
      {
        nativeEvent: { state },
      },
    ]);
  }

  render() {
    return <AnimatedRawButton onHandlerStateChange={this._onGestureEvent} />;
  }
}
```

## Gesture states & events

Every gesture can be treated as "state machine". At any given time, each handler instance has an assigned state that can change when new touch events occur or can be forced to change by the touch system in certain circumstances.

A gesture can be in one of the six possible states:

- ##### UNDETERMINED

  This is the initial state of each gesture recognizer and it goes into this state after it's done recognizing a gesture.

- ##### FAILED

  A gesture recognizer received some touches but for some reason didn't recognize them. For example, if a finger travels more distance than a defined `maxDist` property allows, then the gesture won't become active but will fail instead. Afterwards, it's state will be reset to `UNDETERMINED`.

- ##### BEGAN

  Gesture recognizer has started receiving touch stream but hasn't yet received enough data to either fail or activate.

- ##### CANCELLED

  The gesture recognizer has received a signal (possibly new touches or a command from the touch system controller) resulting in the cancellation of a continuous gesture. The gesture's state will become `CANCELLED` until it is finally reset to the initial state, `UNDETERMINED`.

- ##### ACTIVE

  Recognizer has recognized a gesture. It will become and stay in the `ACTIVE` state until the gesture finishes (e.g. when user lifts the finger) or gets cancelled by the touch system. Under normal circumstances the state will then turn into `END`. In the case that a gesture is cancelled by the touch system, its state would then become `CANCELLED`.

- ##### END

  The gesture recognizer has received touches signalling the end of a gesture. Its state will become `END` until it is reset to `UNDETERMINED`.

### State flows

The most typical flow of state is when a gesture picks up on an initial touch event, then recognizes it, then acknowledges its ending and resets itself back to the initial state.

The flow looks as follows:

### Events

There are three types of events in RNGH2: `StateChangeEvent`, `GestureEvent` and `PointerEvent`. The `StateChangeEvent` is send every time a gesture moves to a different state, while `GestureEvent` is send every time a gesture is updated. The first two carry a gesture-specific data and a `state` property, indicating the current state of the gesture. `StateChangeEvent` also carries a `oldState` property indicating the previous state of the gesture. `PointerEvent` carries information about raw touch events, like touching the screen or moving the finger. These events are handled internally before they are passed along to the correct callbacks:

#### `onBegin`

Is called when a gesture transitions to the `BEGAN` state.

#### `onStart`

Is called when a gesture transitions to the `ACTIVE` state.

#### `onEnd`

Is called when a gesture transitions from the `ACTIVE` state to the `END`, `FAILED`, or `CANCELLED` state. If the gesture transitions to the `END` state, the `success` argument is set to `true` otherwise it is set to `false`.

#### `onFinalize`

Is called when a gesture transitions to the `END`, `FAILED`, or `CANCELLED` state. If the gesture transitions to the `END` state, the `success` argument is set to `true` otherwise it is set to `false`. If the gesture transitions from the `ACTIVE` state, it will be called after `onEnd`.

#### `onUpdate`

Is called every time a gesture is updated while it is in the `ACTIVE` state.

#### `onPointerDown`

Is called when new pointers are placed on the screen. It may carry information about more than one pointer because the events are batched.

#### `onPointerMove`

Is called when pointers are moved on the screen. It may carry information about more than one pointer because the events are batched.

#### `onPointerUp`

Is called when pointers are lifted from the screen. It may carry information about more than one pointer because the events are batched.

#### `onPointerCancelled`

Is called when there will be no more information about this pointer. It may be called because the gesture has ended or was interrupted. It may carry information about more than one pointer because the events are batched.

## Handler State

As described in "About Gesture Handlers", gesture handlers can be treated as "state machines". At any given time, each handler instance has an assigned state that can change when new touch events occur or can be forced to change by the touch system in certain circumstances.

A gesture handler can be in one of the six possible states:

-

-

- -
  -
  -
  -
  -
  -

Each state has its own description below.

### Accessing state

We can monitor a handler's state changes by using the `onHandlerStateChange` callback and the destructured `nativeEvent` argument passed to it. This can be done by comparing the `nativeEvent`'s `state` attribute to one of the constants exported under the `State` object (see example below).

```
import { State, LongPressGestureHandler } from 'react-native-gesture-handler';

class Demo extends Component {
  _handleStateChange = ({ nativeEvent }) => {
    if (nativeEvent.state === State.ACTIVE) {
      Alert.alert('Longpress');
    }
  };
  render() {
    return (
      <LongPressGestureHandler onHandlerStateChange={this._handleStateChange}>
        <Text style={styles.buttonText}>Longpress me</Text>
      </LongPressGestureHandler>
    );
  }
}
```

### State flows

The most typical flow of state is when a gesture handler picks up on an initial touch event then recognizes it then acknowledges its ending then resets itself back to the initial state.

The flow looks as follows (longer arrows represent that there are possibly more touch events received before the state changes):

`UNDETERMINED` -> `BEGAN` ---- ------> `ACTIVE` ---- ------> `END` -> `UNDETERMINED`

Another possible flow is when a handler receives touches that cause a recognition failure:

`UNDETERMINED` -> `BEGAN` ---- ------> `FAILED` -> `UNDETERMINED`

At last, when a handler does properly recognize the gesture but then is interrupted by the touch system. In that case, the gesture recognition is canceled and the flow looks as follows:

`UNDETERMINED` -> `BEGAN` ---- ------> `ACTIVE` ---- ------> `CANCELLED` -> `UNDETERMINED`

### States

The section below describes all possible handler states:

#### UNDETERMINED

This is the initial state of each handler and it goes into this state after it's done recognizing a gesture.

#### FAILED

A handler received some touches but for some reason didn't recognize them. For example, if a finger travels more distance than a defined `maxDist` property allows, then the handler won't become active but will fail instead. Afterwards, it's state will be reset to `UNDETERMINED`.

#### BEGAN

Handler has started receiving touch stream but hasn't yet received enough data to either fail or activate.

#### CANCELLED

The gesture recognizer has received a signal (possibly new touches or a command from the touch system controller) resulting in the cancellation of a continuous gesture. The gesture's state will become `CANCELLED` until it is finally reset to the initial state, `UNDETERMINED`.

#### ACTIVE

Handler has recognized a gesture. It will become and stay in the `ACTIVE` state until the gesture finishes (e.g. when user lifts the finger) or gets cancelled by the touch system. Under normal circumstances the state will then turn into `END`. In the case that a gesture is cancelled by the touch system, its state would then become `CANCELLED`. Learn about discrete and continuous handlers here to understand how long a handler can be kept in the `ACTIVE` state.

#### END

The gesture recognizer has received touches signalling the end of a gesture. Its state will become `END` until it is reset to `UNDETERMINED`.

Version: 2.x

## Gesture handlers (legacy)

###

###

###

###

###

###

###

###

###

###

###

###

## Testing with Jest

### Mocking native modules

In order to load mocks provided by RNGH add following to your jest config in `package.json`:

```
"setupFiles": ["./node_modules/react-native-gesture-handler/jestSetup.js"]
```

Example:

```
"jest": {
  "preset": "react-native",
  "setupFiles": ["./node_modules/react-native-gesture-handler/jestSetup.js"]
}
```

### Testing Gestures' and Gesture handlers' callbacks

RNGH provides an API for triggering selected handlers:

-
-

### fireGestureHandler(gestureOrHandler, eventList)

Simulates one event stream (i.e. event sequence starting with `BEGIN` state and ending with one of `END`/`FAIL`/`CANCEL` states), calling appropriate callbacks associated with given gesture handler.

#### Arguments

##### `gestureOrHandler`

Represents either:

1. Gesture handler component found by Jest queries (e.g. `getByTestId`)
2. Gesture found by `getByGestureTestId()`

##### `eventList`

Event data passed to appropriate callback. RNGH fills event list if required data is missing using these rules:

1. `oldState` is filled using state of the previous event. `BEGIN` events use `UNDETERMINED` value as previous event.
2. Events after first `ACTIVE` state can omit `state` field.
3. Handler specific data is filled (e.g. `numberOfTouches`, `x` fields) with defaults.
4. Missing `BEGIN` and `END` events are added with data copied from first and last passed event, respectively.
5. If first event don't have `state` field, the `ACTIVE` state is assumed.

Some examples:

```
const oldStateFilled = [
  { state: State.BEGAN },
  { state: State.ACTIVE },
  { state: State.END },
]; // three events with specified state are fired.

const implicitActiveState = [
  { state: State.BEGAN },
  { state: State.ACTIVE },
  { x: 5 },
  { state: State.END },
]; // 4 events, including two ACTIVE events (second one has overridden additional data).

const implicitBegin = [
  { x: 1, y: 11 },
  { x: 2, y: 12, state: State.FAILED },
]; // 3 events, including implicit BEGAN, one ACTIVE, and one FAILED event with additional data.

const implicitBeginAndEnd = [
  { x: 5, y: 15 },
  { x: 6, y: 16 },
  { x: 7, y: 17 },
]; // 5 events, including 3 ACTIVE events and implicit BEGAN and END events. BEGAN uses first event's additional data, END uses last event's additional data.

const allImplicits = []; // 3 events, one BEGIN, one ACTIVE, one END with defaults.
```

#### Example

Extracted from RNGH tests, check `Events.test.tsx` for full implementation.

```
it('sends events with additional data to handlers', () => {
  const panHandlers = mockedEventHandlers();
  render(<SingleHandler handlers={panHandlers} treatStartAsUpdate />);
  fireGestureHandler<PanGesture>(getByGestureTestId('pan'), [
    { state: State.BEGAN, translationX: 0 },
    { state: State.ACTIVE, translationX: 10 },
    { translationX: 20 },
    { translationX: 20 },
    { state: State.END, translationX: 30 },
  ]);

  expect(panHandlers.active).toHaveBeenCalledTimes(3);
  expect(panHandlers.active).toHaveBeenLastCalledWith(
    expect.objectContaining({ translationX: 20 })
  );
});
```

### getByGestureTestId(testID)

Returns opaque data type associated with gesture. Gesture is found via `testID` attribute in rendered components (see `withTestID` method).

#### Arguments

##### `testID`

String identifying gesture.

#### Notes

`testID` must be unique among components rendered in test.

#### Example

See above example for `fireGestureHandler`.

## About Gesture Handlers

warning

The old API will be removed in the future version of Gesture Handler. Please migrate to gestures API instead. Check out our upgrading guide for more information.

Gesture handlers are the core building blocks of this library. We use this term to describe elements of the native touch system that the library allows us to instantiate and control from Javascript using React's Component interface.

Each handler type is capable of recognizing one type of gesture (pan, pinch, etc.) and provides gesture-specific information via events (translation, scale, etc.).

Handlers analyze touch stream synchronously in the UI thread. This allows for uninterrupted interactions even when the Javascript thread is blocked.

Each handler works as an isolated state machine. It takes touch stream as an input and based on it, it can flip between states. When a gesture starts, based on the position where the finger was placed, a set of handlers that may be interested in recognizing the gesture is selected. All the touch events (touch down, move, up, or when other fingers are placed or lifted) are delivered to all of the handlers selected initially. When one gesture becomes active, it cancels all the other gestures (read more about how to influence this process in "Cross handler interactions" section).

Gesture handler components do not instantiate a native view in the view hierarchy. Instead, they are kept in library's own registry and are only connected to native views. When using any of the gesture handler components, it is important for it to have a native view rendered as a child. Since handler components don't have corresponding views in the hierarchy, the events registered with them are actually hooked into the underlying view.

#### Available gesture handlers

Currently, the library provides the following list of gestures. Their parameters and attributes they provide to gesture events are documented under each gesture page:

-
-
-
-
-
-
-

#### Discrete vs continuous

We distinguish between two types of gestures: discrete and continuous.

Continuous gesture handlers can be active for a long period of time and will generate a stream of gesture events until the gesture is over. An example of a continuous handler is `PanGestureHandler` that once activated, will start providing updates about translation and other properties.

On the other hand, discrete gesture handlers once activated will not stay in the active state but will end immediately. `LongPressGestureHandler` is a discrete handler, as it only detects if the finger is placed for a sufficiently long period of time, it does not track finger movements (as that's the responsibility of `PanGestureHandler`).

Keep in mind that `onGestureEvent` is only generated in continuous gesture handlers and shouldn't be used in the `TapGestureHandler` and other discrete handlers.

#### Nesting handlers

Handler components can be nested. In any case it is recommended that the innermost handler renders a native view component. There are some limitations that apply when using `useNativeDriver` flag. An example of nested handlers:

```
class Multitap extends Component {
  render() {
    return (
      <LongPressGestureHandler
        onHandlerStateChange={this._onLongpress}
        minDurationMs={800}>
        <TapGestureHandler
          onHandlerStateChange={this._onSingleTap}
          waitFor={this.doubleTapRef}>
          <TapGestureHandler
            ref={this.doubleTapRef}
            onHandlerStateChange={this._onDoubleTap}
            numberOfTaps={2}>
            <View style={styles.box} />
          </TapGestureHandler>
        </TapGestureHandler>
      </LongPressGestureHandler>
    );
  }
}
```

#### Using native components

Gesture handler library exposes a set of components normally available in React Native that are wrapped in `NativeViewGestureHandler`. Here is a list of exposed components:

- `ScrollView`
- `FlatList`
- `Switch`
- `TextInput`
- `DrawerLayoutAndroid` (**Android only**)

If you want to use other handlers or buttons nested in a `ScrollView`, use the `waitFor` property to define interaction between a handler and `ScrollView`

#### Events with `useNativeDriver`

Because handlers do not instantiate native views but instead hook up to their child views, directly nesting two gesture handlers using `Animated.event` is not currently supported. To workaround this limitation we recommend placing an `<Animated.View>` component in between the handlers.

Instead of doing:

```
const PanAndRotate = () => (
  <PanGestureHandler onGestureEvent={Animated.event({ ... }, { useNativeDriver: true })}>
    <RotationGestureHandler onGestureEvent={Animated.event({ ... }, { useNativeDriver: true })}>
      <Animated.View style={animatedStyles}/>
    </RotationGestureHandler>
  </PanGestureHandler>
);
```

Place an `<Animated.View>` in between the handlers:

```
const PanAndRotate = () => (
  <PanGestureHandler onGestureEvent={Animated.event({ ... }, { useNativeDriver: true })}>
    <Animated.View>
      <RotationGestureHandler onGestureEvent={Animated.event({ ... }, { useNativeDriver: true })}>
        <Animated.View style={animatedStyles}/>
      </RotationGestureHandler>
    </Animated.View>
  </PanGestureHandler>
);
```

Another consequence of handlers depending on their native child components is that when using a `useNativeDriver` flag with an `Animated.event`, the child component must be wrapped by an `Animated.API` e.g. `<Animated.View>` instead of just a `<View>`:

```
class Draggable extends Component {
  render() {
    return (
      <PanGestureHandler onGestureEvent={Animated.event({ ... }, { useNativeDriver: true })}>
        <Animated.View style={animatedStyles} /> {/* <-- NEEDS TO BE Animated.View */}
      </PanGestureHandler>
    );
  }
};
```

While we recommend using our own `ReanimatedSwipeable` component, creating your own version of swipeable gives you more control over its behavior. Common issue here is that after creating your own swipeable component, scroll does not work. In that case, try adding `touchAction` set to `"pan-y"`, like this:

```
<GestureDetector gesture={...} ... touchAction="pan-y">
  ...
</GestureDetector>
```

## Cross handler interactions

warning

The old API will be removed in the future version of Gesture Handler. Please migrate to gestures API instead. Check out our upgrading guide for more information.

Gesture handlers can "communicate" with each other to support complex gestures and control how they \*\* in certain scenarios.

There are two means of achieving that described in the sections below. In each case, it is necessary to provide a reference of one handler as a property to the other. Gesture handler relies on ref objects created using `React.createRef()` and introduced in React 16.3.

### Simultaneous recognition

By default, only one gesture handler is allowed to be in the `ACTIVE` state. So when a gesture handler recognizes a gesture it cancels all other handlers in the `BEGAN` state and prevents any new handlers from receiving a stream of touch events as long as it remains `ACTIVE`.

This behavior can be altered using the `simultaneousHandlers` property (available for all types of handlers). This property accepts a ref or an array of refs to other handlers. Handlers connected in this way will be allowed to remain in the `ACTIVE` state at the same time.

#### Use cases

Simultaneous recognition needs to be used when implementing a photo preview component that supports zooming (scaling) the photo, rotating and panning it while zoomed in. In this case we would use a `PinchGestureHandler`, `RotationGestureHandler` and `PanGestureHandler` that would have to simultaneously recognize gestures.

#### Example

See the "Scale, rotate & tilt" example from the GestureHandler Example App or view it directly on your phone by visiting our expo demo.

```
class PinchableBox extends React.Component {
  // ...take a look on full implementation in an Example app
  render() {
    const imagePinch = React.createRef();
    const imageRotation = React.createRef();
    return (
      <RotationGestureHandler
        ref={imageRotation}
        simultaneousHandlers={imagePinch}
        onGestureEvent={this._onRotateGestureEvent}
        onHandlerStateChange={this._onRotateHandlerStateChange}>
        <Animated.View>
          <PinchGestureHandler
            ref={imagePinch}
            simultaneousHandlers={imageRotation}
            onGestureEvent={this._onPinchGestureEvent}
            onHandlerStateChange={this._onPinchHandlerStateChange}>
            <Animated.View style={styles.container} collapsable={false}>
              <Animated.Image
                style={[
                  styles.pinchableImage,
                  {
                    /* events-related transformations */
                  },
                ]}
              />
            </Animated.View>
          </PinchGestureHandler>
        </Animated.View>
      </RotationGestureHandler>
    );
  }
}
```

### Awaiting other handlers

#### Use cases

A good example where awaiting is necessary is when we want to have single and double tap handlers registered for one view (a button). In such a case we need to make single tap handler await a double tap. Otherwise if we try to perform a double tap the single tap handler will fire just after we hit the button for the first time, consequently cancelling the double tap handler.

#### Example

See the "Multitap" example from GestureHandler Example App or view it directly on your phone by visiting our expo demo.

```
const doubleTap = React.createRef();
const PressBox = () => (
  <TapGestureHandler
    onHandlerStateChange={({ nativeEvent }) =>
      nativeEvent.state === State.ACTIVE && Alert.alert('Single tap!')
    }
    waitFor={doubleTap}>
    <TapGestureHandler
      ref={doubleTap}
      onHandlerStateChange={({ nativeEvent }) =>
        nativeEvent.state === State.ACTIVE && Alert.alert("You're so fast")
      }
      numberOfTaps={2}>
      <View style={styles.box} />
    </TapGestureHandler>
  </TapGestureHandler>
);
```

## Fling gesture

A discrete gesture that activates when the movement is sufficiently long and fast. Gesture gets ACTIVE when movement is sufficiently long and it does not take too much time. When gesture gets activated it will turn into END state when finger is released. The gesture will fail to recognize if the finger is lifted before being activated.

`Fling Gesture`

### Example

```
import { StyleSheet } from 'react-native';
import {
  Gesture,
  GestureDetector,
  Directions,
} from 'react-native-gesture-handler';
import Animated, {
  useSharedValue,
  useAnimatedStyle,
  withTiming,
} from 'react-native-reanimated';

export default function App() {
  const position = useSharedValue(0);
  const flingGesture = Gesture.Fling()
    .direction(Directions.RIGHT)
    .onStart((e) => {
      position.value = withTiming(position.value + 10, { duration: 100 });
    });

  const animatedStyle = useAnimatedStyle(() => ({
    transform: [{ translateX: position.value }],
  }));

  return (
    <GestureDetector gesture={flingGesture}>
      <Animated.View style={[styles.box, animatedStyle]} />
    </GestureDetector>
  );
}

const styles = StyleSheet.create({
  box: {
    height: 120,
    width: 120,
    backgroundColor: '#b58df1',
    borderRadius: 20,
    marginBottom: 30,
  },
});
```

### Config

#### Properties specific to `FlingGesture`:

#### `direction(value: Directions)`

Expressed allowed direction of movement. Expected values are exported as constants in the `Directions` object. It's possible to pass one or many directions in one parameter:

```
import { Directions } from 'react-native-gesture-handler';
fling.direction(Directions.RIGHT | Directions.LEFT);
```

or

```
fling.direction(Directions.DOWN);
```

#### `numberOfPointers(value: number)`

Determine exact number of points required to handle the fling gesture.

#### `mouseButton(value: MouseButton)` (Web & Android only)

Allows users to choose which mouse button should handler respond to. The enum `MouseButton` consists of the following predefined fields:

- `LEFT`
- `RIGHT`
- `MIDDLE`
- `BUTTON_4`
- `BUTTON_5`
- `ALL`

Arguments can be combined using `|` operator, e.g. `mouseButton(MouseButton.LEFT | MouseButton.RIGHT)`. Default value is set to `MouseButton.LEFT`.

#### Properties common to all gestures:

#### `enabled(value: boolean)`

Indicates whether the given handler should be analyzing stream of touch events or not. When set to `false` we can be sure that the handler's state will **never** become `ACTIVE`. If the value gets updated while the handler already started recognizing a gesture, then the handler's state it will immediately change to `FAILED` or `CANCELLED` (depending on its current state). Default value is `true`.

#### `shouldCancelWhenOutside(value: boolean)`

When `true` the handler will cancel or fail recognition (depending on its current state) whenever the finger leaves the area of the connected view. Default value of this property is different depending on the handler type. Most handlers' `shouldCancelWhenOutside` property defaults to `false` except for the `LongPressGesture` and `TapGesture` which default to `true`.

#### `hitSlop(settings)`

This parameter enables control over what part of the connected view area can be used to begin recognizing the gesture. When a negative number is provided the bounds of the view will reduce the area by the given number of points in each of the sides evenly.

Instead you can pass an object to specify how each boundary side should be reduced by providing different number of points for `left`, `right`, `top` or `bottom` sides. You can alternatively provide `horizontal` or `vertical` instead of specifying directly `left`, `right` or `top` and `bottom`. Finally, the object can also take `width` and `height` attributes. When `width` is set it is only allow to specify one of the sides `right` or `left`. Similarly when `height` is provided only `top` or `bottom` can be set. Specifying `width` or `height` is useful if we only want the gesture to activate on the edge of the view. In which case for example we can set `left: 0` and `width: 20` which would make it possible for the gesture to be recognize when started no more than 20 points from the left edge.

**IMPORTANT:** Note that this parameter is primarily designed to reduce the area where gesture can activate. Hence it is only supported for all the values (except `width` and `height`) to be non positive (0 or lower). Although on Android it is supported for the values to also be positive and therefore allow to expand beyond view bounds but not further than the parent view bounds. To achieve this effect on both platforms you can use React Native's View hitSlop property.

#### `withRef(ref)`

Sets a ref to the gesture object, allowing for interoperability with the old API.

#### `withTestId(testID)`

Sets a `testID` property for gesture object, allowing for querying for it in tests.

#### `cancelsTouchesInView(value)` (**iOS only**)

Accepts a boolean value. When `true`, the gesture will cancel touches for native UI components (`UIButton`, `UISwitch`, etc) it's attached to when it becomes `ACTIVE`. Default value is `true`.

#### `runOnJS(value: boolean)`

When `react-native-reanimated` is installed, the callbacks passed to the gestures are automatically workletized and run on the UI thread when called. This option allows for changing this behavior: when `true`, all the callbacks will be run on the JS thread instead of the UI thread, regardless of whether they are worklets or not. Defaults to `false`.

#### `simultaneousWithExternalGesture(otherGesture1, otherGesture2, ...)`

Adds a gesture that should be recognized simultaneously with this one.

**IMPORTANT:** Note that this method only marks the relation between gestures, without composing them. `GestureDetector` will not recognize the `otherGestures` and it needs to be added to another detector in order to be recognized.

#### `requireExternalGestureToFail(otherGesture1, otherGesture2, ...)`

Adds a relation requiring another gesture to fail, before this one can activate.

#### `blocksExternalGesture(otherGesture1, otherGesture2, ...)`

Adds a relation that makes other gestures wait with activation until this gesture fails (or doesn't start at all).

**IMPORTANT:** Note that this method only marks the relation between gestures, without composing them.`GestureDetector` will not recognize the `otherGestures` and it needs to be added to another detector in order to be recognized.

#### `activeCursor(value)` (Web only)

This parameter allows to specify which cursor should be used when gesture activates. Supports all CSS cursor values (e.g. `"grab"`, `"zoom-in"`). Default value is set to `"auto"`.

### Callbacks

#### Callbacks common to all gestures:

#### `onBegin(callback)`

Set the callback that is being called when given gesture handler starts receiving touches. At the moment of this callback the handler is not yet in an active state and we don't know yet if it will recognize the gesture at all.

#### `onStart(callback)`

Set the callback that is being called when the gesture is recognized by the handler and it transitions to the active state.

#### `onEnd(callback)`

Set the callback that is being called when the gesture that was recognized by the handler finishes. It will be called only if the handler was previously in the active state.

#### `onFinalize(callback)`

Set the callback that is being called when the handler finalizes handling gesture - the gesture was recognized and has finished or it failed to recognize.

#### `onTouchesDown(callback)`

Set the `onTouchesDown` callback which is called every time a finger is placed on the screen.

#### `onTouchesMove(callback)`

Set the `onTouchesMove` callback which is called every time a finger is moved on the screen.

#### `onTouchesUp(callback)`

Set the `onTouchesUp` callback which is called every time a finger is lifted from the screen.

#### `onTouchesCancelled(callback)`

Set the `onTouchesCancelled` callback which is called every time a finger stops being tracked, for example when the gesture finishes.

### Event data

#### Event attributes specific to `FlingGesture`:

#### `x`

X coordinate of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the view attached to the `GestureDetector`. Expressed in point units.

#### `y`

Y coordinate of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the view attached to the `GestureDetector`. Expressed in point units.

#### `absoluteX`

X coordinate of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the window. The value is expressed in point units. It is recommended to use it instead of `x` in cases when the original view can be transformed as an effect of the gesture.

#### `absoluteY`

Y coordinate of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the window. The value is expressed in point units. It is recommended to use it instead of `y` in cases when the original view can be transformed as an effect of the gesture.

#### Event attributes common to all gestures:

#### `state`

Current state of the handler. Expressed as one of the constants exported under `State` object by the library.

#### `numberOfPointers`

Represents the number of pointers (fingers) currently placed on the screen.

#### `pointerType`

Indicates the type of pointer device in use. This value is represented by the `PointerType` enum, which includes the following fields:

- `TOUCH` - represents finger
- `STYLUS` - represents stylus or digital pen
- `MOUSE` - represents computer mouse
- `KEY` - represents keyboard
- `OTHER` - represents unknown device type that is not relevant

## Common handler properties

warning

The old API will be removed in the future version of Gesture Handler. Please migrate to gestures API instead. Check out our upgrading guide for more information.

This page covers the common set of properties all gesture handler components expose.

#### Units

All handler component properties and event attributes that represent onscreen dimensions are expressed in screen density independent units we refer to as "points". These are the units commonly used in React Native ecosystem (e.g. in the layout system). They do not map directly to physical pixels but instead to iOS's points and to dp units on Android.

### Properties

This section describes properties that can be used with all gesture handler components:

#### `enabled`

Accepts a boolean value. Indicates whether the given handler should be analyzing stream of touch events or not. When set to `false` we can be sure that the handler's state will **never** become `ACTIVE`. If the value gets updated while the handler already started recognizing a gesture, then the handler's state it will immediately change to `FAILED` or `CANCELLED` (depending on its current state). Default value is `true`.

#### `shouldCancelWhenOutside`

Accepts a boolean value. When `true` the handler will cancel or fail recognition (depending on its current state) whenever the finger leaves the area of the connected view. Default value of this property is different depending on the handler type. Most handlers' `shouldCancelWhenOutside` property defaults to `false` except for the `LongPressGestureHandler` and `TapGestureHandler` which default to `true`.

#### `cancelsTouchesInView` (**iOS only**)

Accepts a boolean value. When `true`, the handler will cancel touches for native UI components (`UIButton`, `UISwitch`, etc) it's attached to when it becomes `ACTIVE`. Default value is `true`.

#### `simultaneousHandlers`

Accepts a react ref object or an array of refs to other handler components (refs should be created using `React.createRef()`). When set, the handler will be allowed to activate even if one or more of the handlers provided by their refs are in an `ACTIVE` state. It will also prevent the provided handlers from cancelling the current handler when they activate. Read more in the cross handler interaction section.

#### `waitFor`

Accepts a react ref object or an array of refs to other handler components (refs should be created using `React.createRef()`). When set the handler will not activate as long as the handlers provided by their refs are in the `BEGAN` state. Read more in the cross handler interaction section.

#### `hitSlop`

This parameter enables control over what part of the connected view area can be used to begin recognizing the gesture. When a negative number is provided the bounds of the view will reduce the area by the given number of points in each of the sides evenly.

Instead you can pass an object to specify how each boundary side should be reduced by providing different number of points for `left`, `right`, `top` or `bottom` sides. You can alternatively provide `horizontal` or `vertical` instead of specifying directly `left`, `right` or `top` and `bottom`. Finally, the object can also take `width` and `height` attributes. When `width` is set it is only allow to specify one of the sides `right` or `left`. Similarly when `height` is provided only `top` or `bottom` can be set. Specifying `width` or `height` is useful if we only want the gesture to activate on the edge of the view. In which case for example we can set `left: 0` and `width: 20` which would make it possible for the gesture to be recognize when started no more than 20 points from the left edge.

**IMPORTANT:** Note that this parameter is primarily designed to reduce the area where gesture can activate. Hence it is only supported for all the values (except `width` and `height`) to be non positive (0 or lower). Although on Android it is supported for the values to also be positive and therefore allow to expand beyond view bounds but not further than the parent view bounds. To achieve this effect on both platforms you can use React Native's View hitSlop property.

#### `userSelect` (Web only)

This parameter allows to specify which `userSelect` property should be applied to underlying view. Possible values are `"none" | "auto" | "text"`. Default value is set to `"none"`.

#### `activeCursor` (Web only)

This parameter allows to specify which cursor should be used when gesture activates. Supports all CSS cursor values (e.g. `"grab"`, `"zoom-in"`). Default value is set to `"auto"`.

#### `onGestureEvent`

Takes a callback that is going to be triggered for each subsequent touch event while the handler is in an ACTIVE state. Event payload depends on the particular handler type. Common set of event data attributes is documented below and handler specific attributes are documented on the corresponding handler pages. E.g. event payload for `PinchGestureHandler` contains `scale` attribute that represents how the distance between fingers changed since when the gesture started.

Instead of a callback `Animated.event` object can be used. Also Animated events with `useNativeDriver` flag enabled **are fully supported**.

#### `onHandlerStateChange`

Takes a callback that is going to be triggered when state of the given handler changes.

The event payload contains the same payload as in case of `onGestureEvent` including handler specific event attributes some handlers may provide.

In addition `onHandlerStateChange` event payload contains `oldState` attribute which represents the state of the handler right before the change.

Instead of a callback `Animated.event` object can be used. Also Animated events with `useNativeDriver` flag enabled **are fully supported**.

### Event data

This section describes the attributes of event object being provided to `onGestureEvent` and `onHandlerStateChange` callbacks:

#### `state`

Current state of the handler. Expressed as one of the constants exported under `State` object by the library. Refer to the section about handler state to learn more about how to use it.

#### `numberOfPointers`

Represents the number of pointers (fingers) currently placed on the screen.

## Hover gesture

A continuous gesture that can recognize hovering above the view it's attached to. The hover effect may be activated by moving a mouse or a stylus over the view.

On iOS additional visual effects may be configured.

`Hover Gesture`

### Reference

```
import { GestureDetector, Gesture } from 'react-native-gesture-handler';

function App() {
  const hover = Gesture.Hover();

  return (
    <GestureDetector gesture={hover}>
      <View />
    </GestureDetector>
  );
}
```

### Remarks

- Don't rely on `Hover` gesture to continue after the mouse button is clicked or the stylus touches the screen. If you want to handle both cases, compose it with `Pan` gesture.

### Config

#### Properties specific to `HoverGesture`:

#### `effect(effect: HoverEffect)` (iOS only)

```
import { HoverEffect } from 'react-native-gesture-handler';
```

Visual effect applied to the view while the view is hovered. The possible values are:

- `HoverEffect.None`
- `HoverEffect.Lift`
- `HoverEffect.Highlight`

Defaults to `HoverEffect.None`

#### Properties common to all gestures:

#### `enabled(value: boolean)`

Indicates whether the given handler should be analyzing stream of touch events or not. When set to `false` we can be sure that the handler's state will **never** become `ACTIVE`. If the value gets updated while the handler already started recognizing a gesture, then the handler's state it will immediately change to `FAILED` or `CANCELLED` (depending on its current state). Default value is `true`.

#### `shouldCancelWhenOutside(value: boolean)`

When `true` the handler will cancel or fail recognition (depending on its current state) whenever the finger leaves the area of the connected view. Default value of this property is different depending on the handler type. Most handlers' `shouldCancelWhenOutside` property defaults to `false` except for the `LongPressGesture` and `TapGesture` which default to `true`.

#### `hitSlop(settings)`

This parameter enables control over what part of the connected view area can be used to begin recognizing the gesture. When a negative number is provided the bounds of the view will reduce the area by the given number of points in each of the sides evenly.

Instead you can pass an object to specify how each boundary side should be reduced by providing different number of points for `left`, `right`, `top` or `bottom` sides. You can alternatively provide `horizontal` or `vertical` instead of specifying directly `left`, `right` or `top` and `bottom`. Finally, the object can also take `width` and `height` attributes. When `width` is set it is only allow to specify one of the sides `right` or `left`. Similarly when `height` is provided only `top` or `bottom` can be set. Specifying `width` or `height` is useful if we only want the gesture to activate on the edge of the view. In which case for example we can set `left: 0` and `width: 20` which would make it possible for the gesture to be recognize when started no more than 20 points from the left edge.

**IMPORTANT:** Note that this parameter is primarily designed to reduce the area where gesture can activate. Hence it is only supported for all the values (except `width` and `height`) to be non positive (0 or lower). Although on Android it is supported for the values to also be positive and therefore allow to expand beyond view bounds but not further than the parent view bounds. To achieve this effect on both platforms you can use React Native's View hitSlop property.

#### `withRef(ref)`

Sets a ref to the gesture object, allowing for interoperability with the old API.

#### `withTestId(testID)`

Sets a `testID` property for gesture object, allowing for querying for it in tests.

#### `cancelsTouchesInView(value)` (**iOS only**)

Accepts a boolean value. When `true`, the gesture will cancel touches for native UI components (`UIButton`, `UISwitch`, etc) it's attached to when it becomes `ACTIVE`. Default value is `true`.

#### `runOnJS(value: boolean)`

When `react-native-reanimated` is installed, the callbacks passed to the gestures are automatically workletized and run on the UI thread when called. This option allows for changing this behavior: when `true`, all the callbacks will be run on the JS thread instead of the UI thread, regardless of whether they are worklets or not. Defaults to `false`.

#### `simultaneousWithExternalGesture(otherGesture1, otherGesture2, ...)`

Adds a gesture that should be recognized simultaneously with this one.

**IMPORTANT:** Note that this method only marks the relation between gestures, without composing them. `GestureDetector` will not recognize the `otherGestures` and it needs to be added to another detector in order to be recognized.

#### `requireExternalGestureToFail(otherGesture1, otherGesture2, ...)`

Adds a relation requiring another gesture to fail, before this one can activate.

#### `blocksExternalGesture(otherGesture1, otherGesture2, ...)`

Adds a relation that makes other gestures wait with activation until this gesture fails (or doesn't start at all).

**IMPORTANT:** Note that this method only marks the relation between gestures, without composing them.`GestureDetector` will not recognize the `otherGestures` and it needs to be added to another detector in order to be recognized.

#### `activeCursor(value)` (Web only)

This parameter allows to specify which cursor should be used when gesture activates. Supports all CSS cursor values (e.g. `"grab"`, `"zoom-in"`). Default value is set to `"auto"`.

### Callbacks

#### Callbacks common to all gestures:

#### `onBegin(callback)`

Set the callback that is being called when given gesture handler starts receiving touches. At the moment of this callback the handler is not yet in an active state and we don't know yet if it will recognize the gesture at all.

#### `onStart(callback)`

Set the callback that is being called when the gesture is recognized by the handler and it transitions to the active state.

#### `onEnd(callback)`

Set the callback that is being called when the gesture that was recognized by the handler finishes. It will be called only if the handler was previously in the active state.

#### `onFinalize(callback)`

Set the callback that is being called when the handler finalizes handling gesture - the gesture was recognized and has finished or it failed to recognize.

#### `onTouchesDown(callback)`

Set the `onTouchesDown` callback which is called every time a finger is placed on the screen.

#### `onTouchesMove(callback)`

Set the `onTouchesMove` callback which is called every time a finger is moved on the screen.

#### `onTouchesUp(callback)`

Set the `onTouchesUp` callback which is called every time a finger is lifted from the screen.

#### `onTouchesCancelled(callback)`

Set the `onTouchesCancelled` callback which is called every time a finger stops being tracked, for example when the gesture finishes.

#### Callbacks common to all continuous gestures:

#### `onUpdate(callback)`

Set the callback that is being called every time the gesture receives an update while it's active.

#### `onChange(callback)`

Set the callback that is being called every time the gesture receives an update while it's active. This callback will receive information about change in value in relation to the last received event.

### Event data

#### Event attributes specific to `HoverGesture`:

#### `x`

X coordinate of the current position of the pointer relative to the view attached to the `GestureDetector`. Expressed in point units.

#### `y`

Y coordinate of the current position of the pointer relative to the view attached to the `GestureDetector`. Expressed in point units.

#### `absoluteX`

X coordinate of the current position of the pointer relative to the window. The value is expressed in point units. It is recommended to use it instead of `x` in cases when the original view can be transformed as an effect of the gesture.

#### `absoluteY`

Y coordinate of the current position of the pointer relative to the window. The value is expressed in point units. It is recommended to use it instead of `y` in cases when the original view can be transformed as an effect of the gesture.

#### `stylusData`

Object that contains additional information about `stylus`. It consists of the following fields:

- `tiltX` - angle in degrees between the Y-Z plane of the stylus and the screen.
- `tiltY` - angle in degrees between the X-Z plane of the stylus and the screen.
- `altitudeAngle` - angle between stylus axis and the X-Y plane of a device screen.
- `azimuthAngle` - angle between the Y-Z plane and the plane containing both the stylus axis and the Y axis.
- `pressure` - indicates the normalized pressure of the stylus.

#### Event attributes common to all gestures:

#### `state`

Current state of the handler. Expressed as one of the constants exported under `State` object by the library.

#### `numberOfPointers`

Represents the number of pointers (fingers) currently placed on the screen.

#### `pointerType`

Indicates the type of pointer device in use. This value is represented by the `PointerType` enum, which includes the following fields:

- `TOUCH` - represents finger
- `STYLUS` - represents stylus or digital pen
- `MOUSE` - represents computer mouse
- `KEY` - represents keyboard
- `OTHER` - represents unknown device type that is not relevant

## PanGestureHandler

warning

The old API will be removed in the future version of Gesture Handler. Please migrate to gestures API instead. Check out our upgrading guide for more information.

A continuous gesture handler that can recognize a panning (dragging) gesture and track its movement.

The handler activates when a finger is placed on the screen and moved some initial distance.

Configurations such as a minimum initial distance, specific vertical or horizontal pan detection and number of fingers required for activation (allowing for multifinger swipes) may be specified.

Gesture callback can be used for continuous tracking of the pan gesture. It provides information about the gesture such as its XY translation from the starting point as well as its instantaneous velocity.

The handler is implemented using UIPanGestureRecognizer on iOS and PanGestureHandler on Android.

### Custom activation criteria

The `PanGestureHandler` component exposes a number of properties that can be used to customize the criteria under which a handler will activate or fail when recognizing a gesture.

When more than one of such a property is set, `PanGestureHandler` expects all criteria to be met for successful recognition and at most one of the criteria to be overstepped to fail recognition. For example when both `minDeltaX` and `minDeltaY` are set to 20 we expect the finger to travel by 20 points in both the X and Y axis before the handler activates. Another example would be setting both `maxDeltaX` and `maxDeltaY` to 20 and `minDist` to 23. In such a case, if we move a finger along the X-axis by 20 points and along the Y-axis by 0 points, the handler will fail even though the finger is still within the bounds of translation along Y-axis.

### Multi touch pan handling

If your app relies on multi touch pan handling this section provides some information how the default behavior differs between the platform and how (if necessary) it can be unified.

The difference in multi touch pan handling lies in the way how translation properties during the event are being calculated. On iOS the default behavior when more than one finger is placed on the screen is to treat this situation as if only one pointer was placed in the center of mass (average position of all the pointers). This applies also to many platform native components that handle touch even if not primarily interested in multi touch interactions like for example UIScrollView component.

The default behavior for native components like scroll view, pager views or drawers is different and hence gesture handler defaults to that when it comes to pan handling. The difference is that instead of treating the center of mass of all the fingers placed as a leading pointer it takes the latest placed finger as such. This behavior can be changed on Android using `avgTouches` flag.

Note that on both Android and iOS when the additional finger is placed on the screen that translation prop is not affected even though the position of the pointer being tracked might have changed. Therefore it is safe to rely on translation most of the time as it only reflects the movement that happens regardless of how many fingers are placed on the screen and if that number changes over time. If you wish to track the "center of mass" virtual pointer and account for its changes when the number of finger changes you can use relative or absolute position provided in the event (`x` and `y` or `absoluteX` and `absoluteY`).

### Properties

See set of properties inherited from base handler class. Below is a list of properties specific to `PanGestureHandler` component:

#### `minDist`

Minimum distance the finger (or multiple finger) need to travel before the handler activates. Expressed in points.

#### `minPointers`

A number of fingers that is required to be placed before handler can activate. Should be a higher or equal to 0 integer.

#### `maxPointers`

When the given number of fingers is placed on the screen and handler hasn't yet activated it will fail recognizing the gesture. Should be a higher or equal to 0 integer.

#### `activeOffsetX`

Range along X axis (in points) where fingers travels without activation of handler. Moving outside of this range implies activation of handler. Range can be given as an array or a single number. If range is set as an array, first value must be lower or equal to 0, a the second one higher or equal to 0. If only one number `p` is given a range of `(-inf, p)` will be used if `p` is higher or equal to 0 and `(-p, inf)` otherwise.

#### `activeOffsetY`

Range along Y axis (in points) where fingers travels without activation of handler. Moving outside of this range implies activation of handler. Range can be given as an array or a single number. If range is set as an array, first value must be lower or equal to 0, a the second one higher or equal to 0. If only one number `p` is given a range of `(-inf, p)` will be used if `p` is higher or equal to 0 and `(-p, inf)` otherwise.

#### `failOffsetY`

When the finger moves outside this range (in points) along Y axis and handler hasn't yet activated it will fail recognizing the gesture. Range can be given as an array or a single number. If range is set as an array, first value must be lower or equal to 0, a the second one higher or equal to 0. If only one number `p` is given a range of `(-inf, p)` will be used if `p` is higher or equal to 0 and `(-p, inf)` otherwise.

#### `failOffsetX`

When the finger moves outside this range (in points) along X axis and handler hasn't yet activated it will fail recognizing the gesture. Range can be given as an array or a single number. If range is set as an array, first value must be lower or equal to 0, a the second one higher or equal to 0. If only one number `p` is given a range of `(-inf, p)` will be used if `p` is higher or equal to 0 and `(-p, inf)` otherwise.

#### `maxDeltaX`

> This method is deprecated but supported for backward compatibility. Instead of using `maxDeltaX={N}` you can do `failOffsetX={[-N, N]}`.

When the finger travels the given distance expressed in points along X axis and handler hasn't yet activated it will fail recognizing the gesture.

#### `maxDeltaY`

> This method is deprecated but supported for backward compatibility. Instead of using `maxDeltaY={N}` you can do `failOffsetY={[-N, N]}`.

When the finger travels the given distance expressed in points along Y axis and handler hasn't yet activated it will fail recognizing the gesture.

#### `minOffsetX`

> This method is deprecated but supported for backward compatibility. Instead of using `minOffsetX={N}` you can do `activeOffsetX={N}`.

Minimum distance along X (in points) axis the finger (or multiple finger) need to travel before the handler activates. If set to a lower or equal to 0 value we expect the finger to travel "left" by the given distance. When set to a higher or equal to 0 number the handler will activate on a movement to the "right". If you wish for the movement direction to be ignored use `minDeltaX` instead.

#### `minOffsetY`

> This method is deprecated but supported for backward compatibility. Instead of using `minOffsetY={N}` you can do `activeOffsetY={N}`.

Minimum distance along Y (in points) axis the finger (or multiple finger) need to travel before the handler activates. If set to a lower or equal to 0 value we expect the finger to travel "up" by the given distance. When set to a higher or equal to 0 number the handler will activate on a movement to the "bottom". If you wish for the movement direction to be ignored use `minDeltaY` instead.

#### `minDeltaX`

> This method is deprecated but supported for backward compatibility. Instead of using `minDeltaX={N}` you can do `activeOffsetX={[-N, N]}`.

Minimum distance along X (in points) axis the finger (or multiple finger) need to travel (left or right) before the handler activates. Unlike `minoffsetx` this parameter accepts only non-lower or equal to 0 numbers that represents the distance in point units. If you want for the handler to activate for the movement in one particular direction use `minOffsetX` instead.

#### `minDeltaY`

> This method is deprecated but supported for backward compatibility. Instead of using `minDeltaY={N}` you can do `activeOffsetY={[-N, N]}`.

Minimum distance along Y (in points) axis the finger (or multiple finger) need to travel (top or bottom) before the handler activates. Unlike `minOffsetY` this parameter accepts only non-lower or equal to 0 numbers that represents the distance in point units. If you want for the handler to activate for the movement in one particular direction use `minOffsetY` instead.

#### `avgTouches` (Android only)

Android, by default, will calculate translation values based on the position of the leading pointer (the first one that was placed on the screen). This prop allows that behavior to be changed to the one that is default on iOS - the averaged position of all active pointers will be used to calculate the translation values.

#### `enableTrackpadTwoFingerGesture` (iOS only)

Enables two-finger gestures on supported devices, for example iPads with trackpads. If not enabled the gesture will require click + drag, with enableTrackpadTwoFingerGesture swiping with two fingers will also trigger the gesture.

### Event data

See set of event attributes from base handler class. Below is a list of gesture event attributes specific to `PanGestureHandler`:

#### `translationX`

Translation of the pan gesture along X axis accumulated over the time of the gesture. The value is expressed in the point units.

#### `translationY`

Translation of the pan gesture along Y axis accumulated over the time of the gesture. The value is expressed in the point units.

#### `velocityX`

Velocity of the pan gesture along the X axis in the current moment. The value is expressed in point units per second.

#### `velocityY`

Velocity of the pan gesture along the Y axis in the current moment. The value is expressed in point units per second.

#### `x`

X coordinate of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the view attached to the handler. Expressed in point units.

#### `y`

Y coordinate of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the view attached to the handler. Expressed in point units.

#### `absoluteX`

X coordinate of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the window. The value is expressed in point units. It is recommended to use it instead of `x` in cases when the original view can be transformed as an effect of the gesture.

#### `absoluteY`

Y coordinate of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the window. The value is expressed in point units. It is recommended to use it instead of `y` in cases when the original view can be transformed as an effect of the gesture.

### Example

See the draggable example from Gesture Handler Example App.

```
import React, { Component } from 'react';
import { Animated, Dimensions } from 'react-native';
import {
  GestureHandlerRootView,
  PanGestureHandler,
} from 'react-native-gesture-handler';

const { width } = Dimensions.get('screen');
const circleRadius = 30;

class Circle extends Component {
  _touchX = new Animated.Value(width / 2 - circleRadius);

  _onPanGestureEvent = Animated.event([{ nativeEvent: { x: this._touchX } }], {
    useNativeDriver: true,
  });

  render() {
    return (
      <GestureHandlerRootView>
        <PanGestureHandler onGestureEvent={this._onPanGestureEvent}>
          <Animated.View
            style={{
              height: 150,
              justifyContent: 'center',
            }}>
            <Animated.View
              style={[
                {
                  backgroundColor: '#42a5f5',
                  borderRadius: circleRadius,
                  height: circleRadius * 2,
                  width: circleRadius * 2,
                },
                {
                  transform: [
                    {
                      translateX: Animated.add(
                        this._touchX,
                        new Animated.Value(-circleRadius)
                      ),
                    },
                  ],
                },
              ]}
            />
          </Animated.View>
        </PanGestureHandler>
      </GestureHandlerRootView>
    );
  }
}

export default function App() {
  return <Circle />;
}
```

## TapGestureHandler

warning

The old API will be removed in the future version of Gesture Handler. Please migrate to gestures API instead. Check out our upgrading guide for more information.

A discrete gesture handler that recognizes one or many taps.

Tap gestures detect one or more fingers briefly touching the screen. The fingers involved in these gestures must not move significantly from their initial touch positions. The required number of taps and allowed distance from initial position may be configured. For example, you might configure tap gesture recognizers to detect single taps, double taps, or triple taps.

In order for a handler to activate, specified gesture requirements such as minPointers, numberOfTaps, maxDist, maxDurationMs, and maxDelayMs (explained below) must be met. Immediately after the handler activates, it will END.

### Properties

See set of properties inherited from base handler class. Below is a list of properties specific to the `TapGestureHandler` component:

#### `minPointers`

Minimum number of pointers (fingers) required to be placed before the handler activates. Should be a positive integer. The default value is 1.

#### `maxDurationMs`

Maximum time, expressed in milliseconds, that defines how fast a finger must be released after a touch. The default value is 500.

#### `maxDelayMs`

Maximum time, expressed in milliseconds, that can pass before the next tap — if many taps are required. The default value is 500.

#### `numberOfTaps`

Number of tap gestures required to activate the handler. The default value is 1.

#### `maxDeltaX`

Maximum distance, expressed in points, that defines how far the finger is allowed to travel along the X axis during a tap gesture. If the finger travels further than the defined distance along the X axis and the handler hasn't yet activated, it will fail to recognize the gesture.

#### `maxDeltaY`

Maximum distance, expressed in points, that defines how far the finger is allowed to travel along the Y axis during a tap gesture. If the finger travels further than the defined distance along the Y axis and the handler hasn't yet activated, it will fail to recognize the gesture.

#### `maxDist`

Maximum distance, expressed in points, that defines how far the finger is allowed to travel during a tap gesture. If the finger travels further than the defined distance and the handler hasn't yet activated, it will fail to recognize the gesture.

### Event data

See set of event attributes from base handler class. Below is a list of gesture event attributes specific to the `TapGestureHandler` component:

#### `x`

X coordinate, expressed in points, of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the view attached to the handler.

#### `y`

Y coordinate, expressed in points, of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the view attached to the handler.

#### `absoluteX`

X coordinate, expressed in points, of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the window. It is recommended to use `absoluteX` instead of `x` in cases when the view attached to the handler can be transformed as an effect of the gesture.

#### `absoluteY`

Y coordinate, expressed in points, of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the window. It is recommended to use `absoluteY` instead of `y` in cases when the view attached to the handler can be transformed as an effect of the gesture.

### Example

See the multitap example from GestureHandler Example App.

```
export class PressBox extends Component {
  doubleTapRef = React.createRef();
  render() {
    return (
      <TapGestureHandler
        onHandlerStateChange={this._onSingleTap}
        waitFor={this.doubleTapRef}>
        <TapGestureHandler ref={this.doubleTapRef} numberOfTaps={2}>
          <View style={styles.box} />
        </TapGestureHandler>
      </TapGestureHandler>
    );
  }
}
```

## LongPressGestureHandler

warning

The old API will be removed in the future version of Gesture Handler. Please migrate to gestures API instead. Check out our upgrading guide for more information.

A discrete gesture handler that activates when the corresponding view is pressed for a sufficiently long time. This handler's state will turn into END immediately after the finger is released. The handler will fail to recognize a touch event if the finger is lifted before the minimum required time or if the finger is moved further than the allowable distance.

The handler is implemented using UILongPressGestureRecognizer on iOS and LongPressGestureHandler on Android.

### Properties

See set of properties inherited from base handler class. Below is a list of properties specific to the `LongPressGestureHandler` component:

#### `minDurationMs`

Minimum time, expressed in milliseconds, that a finger must remain pressed on the corresponding view. The default value is 500.

#### `maxDist`

Maximum distance, expressed in points, that defines how far the finger is allowed to travel during a long press gesture. If the finger travels further than the defined distance and the handler hasn't yet activated, it will fail to recognize the gesture. The default value is 10.

### Event data

See set of event attributes from base handler class. Below is a list of gesture event attributes specific to the `LongPressGestureHandler` component:

#### `x`

X coordinate, expressed in points, of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the view attached to the handler.

#### `y`

Y coordinate, expressed in points, of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the view attached to the handler.

#### `absoluteX`

X coordinate, expressed in points, of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the window. It is recommended to use `absoluteX` instead of `x` in cases when the view attached to the handler can be transformed as an effect of the gesture.

#### `absoluteY`

Y coordinate, expressed in points, of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the window. It is recommended to use `absoluteY` instead of `y` in cases when the view attached to the handler can be transformed as an effect of the gesture.

#### `duration`

Duration of the long press (time since the start of the event), expressed in milliseconds.

### Example

See the multitap example from GestureHandler Example App.

```
const LongPressButton = () => (
  <LongPressGestureHandler
    onHandlerStateChange={({ nativeEvent }) => {
      if (nativeEvent.state === State.ACTIVE) {
        Alert.alert("I'm being pressed for so long");
      }
    }}
    minDurationMs={800}>
    <View style={styles.box} />
  </LongPressGestureHandler>
);
```

##

## Migrating off RNGHEnabledRootView

### Update `MainActivity.java`

Update your `MainActivity.java` file (or wherever you create an instance of `ReactActivityDelegate`), so that it no longer overrides the method responsible for creating `ReactRootView` instance, or modify it so that it no longer uses `RNGestureHandlerEnabledRootView`. Do not forget to remove import for `RNGestureHandlerEnabledRootView`:

```
package com.swmansion.gesturehandler.react.example;

import com.facebook.react.ReactActivity;
- import com.swmansion.gesturehandler.react.RNGestureHandlerEnabledRootView;
public class MainActivity extends ReactActivity {

-  @Override
-  protected ReactActivityDelegate createReactActivityDelegate() {
-    return new ReactActivityDelegate(this, getMainComponentName()) {
-      @Override
-      protected ReactRootView createRootView() {
-       return new RNGestureHandlerEnabledRootView(MainActivity.this);
-      }
-    };
-  }
}
```

### Check if your app works correctly

Some libraries (for example React Navigation) already use `GestureHandlerRootView` as a wrapper to enable gesture interactions. In that case you don't have to add one yourself. If gestures in your app work as expected after removing `RNGestureHandlerEnabledRootView` you can skip the next step.

### Update your JS code

Instead of using `RNGestureHandlerEnabledRootView` wrap your entry point with `<GestureHandlerRootView>` or `gestureHandlerRootHOC`, for example:

```
export default function App() {
  return <GestureHandlerRootView style={{ flex: 1 }}>{/* content */}</GestureHandlerRootView>;
}
```

info

Note that `GestureHandlerRootView` acts like a normal `View`. So if you want it to fill the screen, you will need to pass `{ flex: 1 }` like you'll need to do with a normal View. By default, it'll take the size of the content nested inside.

## RotationGestureHandler

warning

The old API will be removed in the future version of Gesture Handler. Please migrate to gestures API instead. Check out our upgrading guide for more information.

A continuous gesture handler that can recognize a rotation gesture and track its movement.

The handler activates when fingers are placed on the screen and change position in a proper way.

Gesture callback can be used for continuous tracking of the rotation gesture. It provides information about the gesture such as the amount rotated, the focal point of the rotation (anchor), and its instantaneous velocity.

The handler is implemented using UIRotationGestureRecognizer on iOS and from scratch on Android.

### Properties

Properties provided to `RotationGestureHandler` do not extend common set of properties from base handler class.

### Event data

See set of event attributes from base handler class. Below is a list of gesture event attributes specific to `RotationGestureHandler`:

#### `rotation`

Amount rotated, expressed in radians, from the gesture's focal point (anchor).

#### `velocity`

Instantaneous velocity, expressed in point units per second, of the gesture.

#### `anchorX`

X coordinate, expressed in points, of the gesture's central focal point (anchor).

#### `anchorY`

Y coordinate, expressed in points, of the gesture's central focal point (anchor).

### Example

See the scale and rotation example from Gesture Handler Example App.

```
class RotableBox extends React.Component {
  _rotate = new Animated.Value(0);
  _rotateStr = this._rotate.interpolate({
    inputRange: [-100, 100],
    outputRange: ['-100rad', '100rad'],
  });
  _lastRotate = 0;
  _onRotateGestureEvent = Animated.event(
    [{ nativeEvent: { rotation: this._rotate } }],
    { useNativeDriver: USE_NATIVE_DRIVER }
  );
  _onRotateHandlerStateChange = (event) => {
    if (event.nativeEvent.oldState === State.ACTIVE) {
      this._lastRotate += event.nativeEvent.rotation;
      this._rotate.setOffset(this._lastRotate);
      this._rotate.setValue(0);
    }
  };
  render() {
    return (
      <RotationGestureHandler
        onGestureEvent={this._onRotateGestureEvent}
        onHandlerStateChange={this._onRotateHandlerStateChange}>
        <Animated.Image
          style={[
            styles.pinchableImage,
            {
              transform: [{ perspective: 200 }, { rotate: this._rotateStr }],
            },
          ]}
        />
      </RotationGestureHandler>
    );
  }
}
```

## FlingGestureHandler

warning

The old API will be removed in the future version of Gesture Handler. Please migrate to gestures API instead. Check out our upgrading guide for more information.

A discrete gesture handler that activates when the movement is sufficiently long and fast. Handler gets ACTIVE when movement is sufficiently long and it does not take too much time. When handler gets activated it will turn into END state when finger is released. The handler will fail to recognize if the finger is lifted before being activated. The handler is implemented using UISwipeGestureRecognizer on iOS and from scratch on Android.

### Properties

See set of properties inherited from base handler class. Below is a list of properties specific to `FlingGestureHandler` component:

#### `direction`

Expressed allowed direction of movement. It's possible to pass one or many directions in one parameter:

```
direction={Directions.RIGHT | Directions.LEFT}
```

or

```
direction={Directions.DOWN}
```

#### `numberOfPointers`

Determine exact number of points required to handle the fling gesture.

### Event data

See set of event attributes from base handler class. Below is a list of gesture event attributes specific to `FlingGestureHandler`:

#### `x`

X coordinate of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the view attached to the handler. Expressed in point units.

#### `y`

Y coordinate of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the view attached to the handler. Expressed in point units.

#### `absoluteX`

X coordinate of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the window. The value is expressed in point units. It is recommended to use it instead of `x` in cases when the original view can be transformed as an effect of the gesture.

#### `absoluteY`

Y coordinate of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the window. The value is expressed in point units. It is recommended to use it instead of `y` in cases when the original view can be transformed as an effect of the gesture.

### Example

See the fling example from Gesture Handler Example App.

```
const LongPressButton = () => (
  <FlingGestureHandler
    direction={Directions.RIGHT | Directions.LEFT}
    onHandlerStateChange={({ nativeEvent }) => {
      if (nativeEvent.state === State.ACTIVE) {
        Alert.alert("I'm flinged!");
      }
    }}>
    <View style={styles.box} />
  </FlingGestureHandler>
);
```

## Quick start

RNGH2 provides much simpler way to add gestures to your app. All you need to do is wrap the view that you want your gesture to work on with `GestureDetector`, define the gesture and pass it to detector. That's all!

To demonstrate how you would use the new API, let's make a simple app where you can drag a ball around. You will need to add `react-native-gesture-handler` (for gestures) and `react-native-reanimated` (for animations) modules.

Step 1

First let's define styles we will need to make the app:

```
import { StyleSheet } from 'react-native';

const styles = StyleSheet.create({
  ball: {
    width: 100,
    height: 100,
    borderRadius: 100,
    backgroundColor: 'blue',
    alignSelf: 'center',
  },
});
```

Step 2

Then we can start writing our `Ball` component:

```
import { GestureDetector } from 'react-native-gesture-handler';
import Animated from 'react-native-reanimated';

function Ball() {
  return (
    <GestureDetector>
      <Animated.View style={[styles.ball]} />
    </GestureDetector>
  );
}
```

Step 3

We also need to define

to keep track of the ball position and create animated styles in order to be able to position the ball on the screen:

```
import {
  useSharedValue,
  useAnimatedStyle,
  withSpring,
} from 'react-native-reanimated';

function Ball() {
  const isPressed = useSharedValue(false);
  const offset = useSharedValue({ x: 0, y: 0 });

  const animatedStyles = useAnimatedStyle(() => {
    return {
      transform: [
        { translateX: offset.value.x },
        { translateY: offset.value.y },
        { scale: withSpring(isPressed.value ? 1.2 : 1) },
      ],
      backgroundColor: isPressed.value ? 'yellow' : 'blue',
    };
  });

  // ...
}
```

Step 4

And add it to the ball's styles:

```
// ...
return (
  <GestureDetector>
    <Animated.View style={[styles.ball, animatedStyles]} />
  </GestureDetector>
);
// ...
```

Step 5

The only thing left is to define the pan gesture and assign it to the detector:

```
import { Gesture } from 'react-native-gesture-handler';

function Ball() {
  // ...
  const start = useSharedValue({ x: 0, y: 0 });
  const gesture = Gesture.Pan()
    .onBegin(() => {
      isPressed.value = true;
    })
    .onUpdate((e) => {
      offset.value = {
        x: e.translationX + start.value.x,
        y: e.translationY + start.value.y,
      };
    })
    .onEnd(() => {
      start.value = {
        x: offset.value.x,
        y: offset.value.y,
      };
    })
    .onFinalize(() => {
      isPressed.value = false;
    });
  // ...
}
```

```
// ...
return (
  <GestureDetector gesture={gesture}>
    <Animated.View style={[styles.ball, animatedStyles]} />
  </GestureDetector>
);
// ...
```

Note the `start` shared value. We need it to store the position of the ball at the moment we grab it to be able to correctly position it later, because we only have access to translation relative to the starting point of the gesture.

Now you can just add `Ball` component to some view in the app and see the results! (Or you can just check the code here and see it in action in the Example app.)

## Native gesture

A gesture that allows other touch handling components to work within RNGH's gesture system. This streamlines interactions between gestures and the native component, allowing it to form relations with other gestures.

When used, the native component should be the direct child of a `GestureDetector`.

### Example

This example renders a `ScrollView` with multiple colored rectangles, where each rectangle has a black section. Starting a touch on a black section will disable the `ScrollView` for the duration of the `Pan` gesture.

```
import { View, ScrollView } from 'react-native';
import { Gesture, GestureDetector } from 'react-native-gesture-handler';

const COLORS = ['red', 'green', 'blue', 'purple', 'orange', 'cyan'];

export default function App() {
  const native = Gesture.Native();

  return (
    <GestureDetector gesture={native}>
      <ScrollView style={{ flex: 1 }}>
        <ScrollableContent scrollGesture={native} />
      </ScrollView>
    </GestureDetector>
  );
}

function ScrollableContent({ scrollGesture }) {
  return (
    <View>
      {COLORS.map((color) => (
        <Rectangle key={color} color={color} scrollGesture={scrollGesture} />
      ))}
    </View>
  );
}

function Rectangle({ color, scrollGesture }) {
  const pan = Gesture.Pan().blocksExternalGesture(scrollGesture);

  return (
    <View
      key={color}
      style={{ width: '100%', height: 250, backgroundColor: color }}>
      <GestureDetector gesture={pan}>
        <View style={{ width: '100%', height: 50, backgroundColor: 'black' }} />
      </GestureDetector>
    </View>
  );
}
```

### Remarks

- `Native` gesture can be used as part of gesture composition and cross-component interactions just like any other gesture. You can use this to block a native component for the duration of the gesture or to make it work alongside a gesture.

danger

Do not use `Native` gesture with components exported by React Native Gesture Handler. Those come with a native gesture handler preapplied. Attaching a native gesture twice will likely result in the components not working as intended.

### Config

#### Properties specific to `NativeGesture`:

#### `shouldActivateOnStart(value: boolean)` (**Android only**)

When `true`, underlying handler will activate unconditionally when it receives any touches in `BEGAN` or `UNDETERMINED` state.

#### `disallowInterruption(value: boolean)`

When `true`, cancels all other gesture handlers when this `NativeViewGestureHandler` changes its state to `ACTIVE`.

#### Properties common to all gestures:

#### `enabled(value: boolean)`

Indicates whether the given handler should be analyzing stream of touch events or not. When set to `false` we can be sure that the handler's state will **never** become `ACTIVE`. If the value gets updated while the handler already started recognizing a gesture, then the handler's state it will immediately change to `FAILED` or `CANCELLED` (depending on its current state). Default value is `true`.

#### `shouldCancelWhenOutside(value: boolean)`

When `true` the handler will cancel or fail recognition (depending on its current state) whenever the finger leaves the area of the connected view. Default value of this property is different depending on the handler type. Most handlers' `shouldCancelWhenOutside` property defaults to `false` except for the `LongPressGesture` and `TapGesture` which default to `true`.

#### `hitSlop(settings)`

This parameter enables control over what part of the connected view area can be used to begin recognizing the gesture. When a negative number is provided the bounds of the view will reduce the area by the given number of points in each of the sides evenly.

Instead you can pass an object to specify how each boundary side should be reduced by providing different number of points for `left`, `right`, `top` or `bottom` sides. You can alternatively provide `horizontal` or `vertical` instead of specifying directly `left`, `right` or `top` and `bottom`. Finally, the object can also take `width` and `height` attributes. When `width` is set it is only allow to specify one of the sides `right` or `left`. Similarly when `height` is provided only `top` or `bottom` can be set. Specifying `width` or `height` is useful if we only want the gesture to activate on the edge of the view. In which case for example we can set `left: 0` and `width: 20` which would make it possible for the gesture to be recognize when started no more than 20 points from the left edge.

**IMPORTANT:** Note that this parameter is primarily designed to reduce the area where gesture can activate. Hence it is only supported for all the values (except `width` and `height`) to be non positive (0 or lower). Although on Android it is supported for the values to also be positive and therefore allow to expand beyond view bounds but not further than the parent view bounds. To achieve this effect on both platforms you can use React Native's View hitSlop property.

#### `withRef(ref)`

Sets a ref to the gesture object, allowing for interoperability with the old API.

#### `withTestId(testID)`

Sets a `testID` property for gesture object, allowing for querying for it in tests.

#### `cancelsTouchesInView(value)` (**iOS only**)

Accepts a boolean value. When `true`, the gesture will cancel touches for native UI components (`UIButton`, `UISwitch`, etc) it's attached to when it becomes `ACTIVE`. Default value is `true`.

#### `runOnJS(value: boolean)`

When `react-native-reanimated` is installed, the callbacks passed to the gestures are automatically workletized and run on the UI thread when called. This option allows for changing this behavior: when `true`, all the callbacks will be run on the JS thread instead of the UI thread, regardless of whether they are worklets or not. Defaults to `false`.

#### `simultaneousWithExternalGesture(otherGesture1, otherGesture2, ...)`

Adds a gesture that should be recognized simultaneously with this one.

**IMPORTANT:** Note that this method only marks the relation between gestures, without composing them. `GestureDetector` will not recognize the `otherGestures` and it needs to be added to another detector in order to be recognized.

#### `requireExternalGestureToFail(otherGesture1, otherGesture2, ...)`

Adds a relation requiring another gesture to fail, before this one can activate.

#### `blocksExternalGesture(otherGesture1, otherGesture2, ...)`

Adds a relation that makes other gestures wait with activation until this gesture fails (or doesn't start at all).

**IMPORTANT:** Note that this method only marks the relation between gestures, without composing them.`GestureDetector` will not recognize the `otherGestures` and it needs to be added to another detector in order to be recognized.

#### `activeCursor(value)` (Web only)

This parameter allows to specify which cursor should be used when gesture activates. Supports all CSS cursor values (e.g. `"grab"`, `"zoom-in"`). Default value is set to `"auto"`.

### Callbacks

#### Callbacks common to all gestures:

#### `onBegin(callback)`

Set the callback that is being called when given gesture handler starts receiving touches. At the moment of this callback the handler is not yet in an active state and we don't know yet if it will recognize the gesture at all.

#### `onStart(callback)`

Set the callback that is being called when the gesture is recognized by the handler and it transitions to the active state.

#### `onEnd(callback)`

Set the callback that is being called when the gesture that was recognized by the handler finishes. It will be called only if the handler was previously in the active state.

#### `onFinalize(callback)`

Set the callback that is being called when the handler finalizes handling gesture - the gesture was recognized and has finished or it failed to recognize.

#### `onTouchesDown(callback)`

Set the `onTouchesDown` callback which is called every time a finger is placed on the screen.

#### `onTouchesMove(callback)`

Set the `onTouchesMove` callback which is called every time a finger is moved on the screen.

#### `onTouchesUp(callback)`

Set the `onTouchesUp` callback which is called every time a finger is lifted from the screen.

#### `onTouchesCancelled(callback)`

Set the `onTouchesCancelled` callback which is called every time a finger stops being tracked, for example when the gesture finishes.

### Event data

#### Event attributes specific to `NativeGesture`:

#### `pointerInside`

True if gesture was performed inside of containing view, false otherwise.

#### Event attributes common to all gestures:

#### `state`

Current state of the handler. Expressed as one of the constants exported under `State` object by the library.

#### `numberOfPointers`

Represents the number of pointers (fingers) currently placed on the screen.

#### `pointerType`

Indicates the type of pointer device in use. This value is represented by the `PointerType` enum, which includes the following fields:

- `TOUCH` - represents finger
- `STYLUS` - represents stylus or digital pen
- `MOUSE` - represents computer mouse
- `KEY` - represents keyboard
- `OTHER` - represents unknown device type that is not relevant

## PinchGestureHandler

warning

The old API will be removed in the future version of Gesture Handler. Please migrate to gestures API instead. Check out our upgrading guide for more information.

A continuous gesture handler that recognizes pinch gesture. It allows for tracking the distance between two fingers and use that information to scale or zoom your content. The handler activates when fingers are placed on the screen and change their position. Gesture callback can be used for continuous tracking of the pinch gesture. It provides information about velocity, anchor (focal) point of gesture and scale.

The distance between the fingers is reported as a scale factor. At the beginning of the gesture, the scale factor is 1.0. As the distance between the two fingers increases, the scale factor increases proportionally. Similarly, the scale factor decreases as the distance between the fingers decreases. Pinch gestures are used most commonly to change the size of objects or content onscreen. For example, map views use pinch gestures to change the zoom level of the map.

The handler is implemented using UIPinchGestureRecognizer on iOS and from scratch on Android.

### Properties

Properties provided to `PinchGestureHandler` do not extend common set of properties from base handler class.

### Event data

See set of event attributes from base handler class. Below is a list of gesture event attributes specific to `PinchGestureHandler`:

#### `scale`

The scale factor relative to the points of the two touches in screen coordinates.

#### `velocity`

Velocity of the pan gesture the current moment. The value is expressed in scale factor per second.

#### `focalX`

Position expressed in points along X axis of center anchor point of gesture

#### `focalY`

Position expressed in points along Y axis of center anchor point of gesture

### Example

See the scale and rotation example from Gesture Handler Example App.

```
export class PinchableBox extends React.Component {
  _baseScale = new Animated.Value(1);
  _pinchScale = new Animated.Value(1);
  _scale = Animated.multiply(this._baseScale, this._pinchScale);
  _lastScale = 1;
  _onPinchGestureEvent = Animated.event(
    [{ nativeEvent: { scale: this._pinchScale } }],
    { useNativeDriver: USE_NATIVE_DRIVER }
  );

  _onPinchHandlerStateChange = (event) => {
    if (event.nativeEvent.oldState === State.ACTIVE) {
      this._lastScale *= event.nativeEvent.scale;
      this._baseScale.setValue(this._lastScale);
      this._pinchScale.setValue(1);
    }
  };

  render() {
    return (
      <PinchGestureHandler
        onGestureEvent={this._onPinchGestureEvent}
        onHandlerStateChange={this._onPinchHandlerStateChange}>
        <View style={styles.container} collapsable={false}>
          <Animated.Image
            style={[
              styles.pinchableImage,
              {
                transform: [{ perspective: 200 }, { scale: this._scale }],
              },
            ]}
          />
        </View>
      </PinchGestureHandler>
    );
  }
}
```

warning

The old API will be removed in the future version of Gesture Handler. Please migrate to gestures API instead. Check out our upgrading guide for more information.

A continuous gesture handler that recognizes force of a touch. It allows for tracking pressure of touch on some iOS devices. The handler activates when pressure of touch if greater or equal than `minForce`. It fails if pressure is greater than `maxForce` Gesture callback can be used for continuous tracking of the touch pressure. It provides information for one finger (the first one).

At the beginning of the gesture, the pressure factor is 0.0. As the pressure increases, the pressure factor increases proportionally. The maximum pressure is 1.0.

The handler is implemented using custom UIGestureRecognizer on iOS. There's no implementation provided on Android and it simply render children without any wrappers. Since this behaviour is only provided on some iOS devices, this handler should not be used for defining any crucial behaviors. Use it only as an additional improvement and make all features to be accessed without this handler as well.

## Properties

See set of properties inherited from base handler class. Below is a list of properties specific to `ForceTouchGestureHandler` component:

#### `minForce`

A minimal pressure that is required before handler can activate. Should be a value from range `[0.0, 1.0]`. Default is `0.2`.

#### `maxForce`

A maximal pressure that could be applied for handler. If the pressure is greater, handler fails. Should be a value from range `[0.0, 1.0]`.

#### `feedbackOnActivation`

Boolean value defining if haptic feedback has to be performed on activation.

### Event data

See set of event attributes from base handler class. Below is a list of gesture event attributes specific to `ForceTouchGestureHandler`:

#### `force`

The pressure of a touch.

### Static method

#### `forceTouchAvailable`

You may check if it's possible to use `ForceTouchGestureHandler` with `ForceTouchGestureHandler.forceTouchAvailable`

### Example

See the force touch handler example from Gesture Handler Example App.

```
<ForceTouchGestureHandler
  minForce={0}
  onGestureEvent={this._onGestureEvent}
  onHandlerStateChange={this._onHandlerStateChange}>
  <Animated.View
    style={[
      styles.box,
      { transform: [{ scale: Animated.add(1, this.force) }] },
    ]}
  />
</ForceTouchGestureHandler>
```

## Manual gesture

A plain gesture that has no specific activation criteria nor event data set. Its state has to be controlled manually using a state manager. It will not fail when all the pointers are lifted from the screen.

### Reference

```
import { GestureDetector, Gesture } from 'react-native-gesture-handler';

function App() {
  const manual = Gesture.Manual();

  return (
    <GestureDetector gesture={manual}>
      <Animated.View />
    </GestureDetector>
  );
}
```

### Config

#### Properties common to all gestures:

#### `enabled(value: boolean)`

Indicates whether the given handler should be analyzing stream of touch events or not. When set to `false` we can be sure that the handler's state will **never** become `ACTIVE`. If the value gets updated while the handler already started recognizing a gesture, then the handler's state it will immediately change to `FAILED` or `CANCELLED` (depending on its current state). Default value is `true`.

#### `shouldCancelWhenOutside(value: boolean)`

When `true` the handler will cancel or fail recognition (depending on its current state) whenever the finger leaves the area of the connected view. Default value of this property is different depending on the handler type. Most handlers' `shouldCancelWhenOutside` property defaults to `false` except for the `LongPressGesture` and `TapGesture` which default to `true`.

#### `hitSlop(settings)`

This parameter enables control over what part of the connected view area can be used to begin recognizing the gesture. When a negative number is provided the bounds of the view will reduce the area by the given number of points in each of the sides evenly.

Instead you can pass an object to specify how each boundary side should be reduced by providing different number of points for `left`, `right`, `top` or `bottom` sides. You can alternatively provide `horizontal` or `vertical` instead of specifying directly `left`, `right` or `top` and `bottom`. Finally, the object can also take `width` and `height` attributes. When `width` is set it is only allow to specify one of the sides `right` or `left`. Similarly when `height` is provided only `top` or `bottom` can be set. Specifying `width` or `height` is useful if we only want the gesture to activate on the edge of the view. In which case for example we can set `left: 0` and `width: 20` which would make it possible for the gesture to be recognize when started no more than 20 points from the left edge.

**IMPORTANT:** Note that this parameter is primarily designed to reduce the area where gesture can activate. Hence it is only supported for all the values (except `width` and `height`) to be non positive (0 or lower). Although on Android it is supported for the values to also be positive and therefore allow to expand beyond view bounds but not further than the parent view bounds. To achieve this effect on both platforms you can use React Native's View hitSlop property.

#### `withRef(ref)`

Sets a ref to the gesture object, allowing for interoperability with the old API.

#### `withTestId(testID)`

Sets a `testID` property for gesture object, allowing for querying for it in tests.

#### `cancelsTouchesInView(value)` (**iOS only**)

Accepts a boolean value. When `true`, the gesture will cancel touches for native UI components (`UIButton`, `UISwitch`, etc) it's attached to when it becomes `ACTIVE`. Default value is `true`.

#### `runOnJS(value: boolean)`

When `react-native-reanimated` is installed, the callbacks passed to the gestures are automatically workletized and run on the UI thread when called. This option allows for changing this behavior: when `true`, all the callbacks will be run on the JS thread instead of the UI thread, regardless of whether they are worklets or not. Defaults to `false`.

#### `simultaneousWithExternalGesture(otherGesture1, otherGesture2, ...)`

Adds a gesture that should be recognized simultaneously with this one.

**IMPORTANT:** Note that this method only marks the relation between gestures, without composing them. `GestureDetector` will not recognize the `otherGestures` and it needs to be added to another detector in order to be recognized.

#### `requireExternalGestureToFail(otherGesture1, otherGesture2, ...)`

Adds a relation requiring another gesture to fail, before this one can activate.

#### `blocksExternalGesture(otherGesture1, otherGesture2, ...)`

Adds a relation that makes other gestures wait with activation until this gesture fails (or doesn't start at all).

**IMPORTANT:** Note that this method only marks the relation between gestures, without composing them.`GestureDetector` will not recognize the `otherGestures` and it needs to be added to another detector in order to be recognized.

#### `activeCursor(value)` (Web only)

This parameter allows to specify which cursor should be used when gesture activates. Supports all CSS cursor values (e.g. `"grab"`, `"zoom-in"`). Default value is set to `"auto"`.

### Callbacks

#### Callbacks common to all gestures:

#### `onBegin(callback)`

Set the callback that is being called when given gesture handler starts receiving touches. At the moment of this callback the handler is not yet in an active state and we don't know yet if it will recognize the gesture at all.

#### `onStart(callback)`

Set the callback that is being called when the gesture is recognized by the handler and it transitions to the active state.

#### `onEnd(callback)`

Set the callback that is being called when the gesture that was recognized by the handler finishes. It will be called only if the handler was previously in the active state.

#### `onFinalize(callback)`

Set the callback that is being called when the handler finalizes handling gesture - the gesture was recognized and has finished or it failed to recognize.

#### `onTouchesDown(callback)`

Set the `onTouchesDown` callback which is called every time a finger is placed on the screen.

#### `onTouchesMove(callback)`

Set the `onTouchesMove` callback which is called every time a finger is moved on the screen.

#### `onTouchesUp(callback)`

Set the `onTouchesUp` callback which is called every time a finger is lifted from the screen.

#### `onTouchesCancelled(callback)`

Set the `onTouchesCancelled` callback which is called every time a finger stops being tracked, for example when the gesture finishes.

#### Callbacks common to all continuous gestures:

#### `onUpdate(callback)`

Set the callback that is being called every time the gesture receives an update while it's active.

#### `onChange(callback)`

Set the callback that is being called every time the gesture receives an update while it's active. This callback will receive information about change in value in relation to the last received event.

### Event data

#### Event attributes common to all gestures:

#### `state`

Current state of the handler. Expressed as one of the constants exported under `State` object by the library.

#### `numberOfPointers`

Represents the number of pointers (fingers) currently placed on the screen.

#### `pointerType`

Indicates the type of pointer device in use. This value is represented by the `PointerType` enum, which includes the following fields:

- `TOUCH` - represents finger
- `STYLUS` - represents stylus or digital pen
- `MOUSE` - represents computer mouse
- `KEY` - represents keyboard
- `OTHER` - represents unknown device type that is not relevant

## Make sure to migrate off the `RNGestureHandlerEnabledRootView` (Android only)

Gesture Handler 1 required you to override `createRootView` to return an instance of `RNGestureHandlerEnabledRootView`. This class has been the cause of many hard to debug and fix crashed and was deprecated in version 2.0, and subsequently removed in version 2.4. If you are still using it, check out migrating off RNGHEnabledRootView guide.

### Upgrading to the new API

The most important change brought by the Gesture Handler 2 is the new Gesture API, along with the `GestureDetector` component. It makes declaring gesture easier, as it handles much of the work under the hood and reduces the amount of necessary boilerplate code. Instead of a separate component for every type of gesture, the `GestureDetector` component is used to attach gestures to the underlying view based on the configuration object passed to it. The configuration objects are created using the `Gesture` object, here is a simple example:

```
const tapGesture = Gesture.Tap().onStart(() => {
  console.log('Tap!');
});
...
return (
  <GestureDetector gesture={tapGesture}>
    <View />
  </GestureDetector>
);
```

As you can see, there are no `onGestureEvent` and `onHandlerStateChange` callbacks, instead the state machine is handled under the hood and relevant callbacks are called for specific transitions or events:

- `onBegin` - called when the gesture transitions to the `BEGAN` state, which in most cases is when the gesture starts processing the touch stream - when the finger first touches the view
- `onStart` - called when the activation criteria for the gesture are met and it transitions from `BEGAN` to `ACTIVE` state
- `onUpdate` - replaces `onGestureEvent`, called every time the gesture sends a new event while it's in the `ACTIVE` state
- `onChange` - if defined, called just after `onUpdate`, the events passed to it are the same as the ones passed to `onUpdate` but they also contain `change` values which hold the change in value they represent since the last event (i.e. in case of the `Pan` gesture, the event will also contain `changeX` and `changeY` properties)
- `onEnd` - called when the gesture transitions from the `ACTIVE` state to either of `END`, `FAILED` or `CANCELLED` - you can tell whether the gesture finished due to user interaction or because of other reason (like getting cancelled by the system, or failure criteria) using the second value passed to the `onEnd` callback alongside the event
- `onFinalize` called when the gesture transitions into either of `END`, `FAILED` or `CANCELLED` state, if the gesture was `ACTIVE`, `onEnd` will be called first (similarly to `onEnd` you can determine the reason for finishing using the second argument)

The difference between `onEnd` and `onFinalize` is that the `onEnd` will be called only if the gesture was `ACTIVE`, while `onFinalize` will be called if the gesture has `BEGAN`. This means that you can use `onEnd` to clean up after `onStart`, and `onFinalize` to clean up after `onBegin` (or both `onBegin` and `onStart`).

#### Configuring the gestures

The new gesture objects are configured in the builder-like pattern. Instead of properties, each gesture provides methods that allow for its customization. In most cases the names of the methods are the same as the relevant props, or at least very similar. For example:

```
return (
  <TapGestureHandler
    numberOfTaps={2}
    maxDurationMs={500}
    maxDelayMs={500}
    maxDist={10}
    onHandlerStateChange={({ nativeEvent }) => {
      if (nativeEvent.state === State.ACTIVE) {
        console.log('Tap!');
      }
    }}>
    <View />
  </TapGestureHandler>
);
```

Would have the same effect as:

```
const tapGesture = Gesture.Tap()
  .numberOfTaps(2)
  .maxDuration(500)
  .maxDelay(500)
  .maxDistance(10)
  .onStart(() => {
    console.log('Tap!');
  });

return (
  <GestureDetector gesture={tapGesture}>
    <View />
  </GestureDetector>
);
```

You can check the modifiers available to specific gestures in the API Reference under Gestures.

#### Using multiple gestures on the same view

Using the gesture handler components, if you wanted to have multiple gestures on one view, you would have to stack them on top of each other and, in case you wanted to use animations, add an `Animated.View` after each handler, resulting in a deep component tree, for example:

```
return (
  <TapGestureHandler ... >
    <Animated.View>
      <PanGestureHandler ... >
        <Animated.View>
          <PinchGestureHandler ... >
            <YourView />
          </PinchGestureHandler>
        </Animated.View>
      </PanGestureHandler>
    </Animated.View>
  </TapGestureHandler>
);
```

With the `GestureDetector` you can use the Gesture Composition API to stack the gestures onto one view:

```
const tapGesture = Gesture.Tap();
const panGesture = Gesture.Pan();
const pinchGesture = Gesture.Pinch();

return (
  <GestureDetector gesture={Gesture.Race(tapGesture, panGesture, pinchGesture)}>
    <YourView />
  </GestureDetector>
);
```

Similarly, you can use `Gesture.Simultaneous` to replace stacked gesture handlers that should be able to recognize gestures simultaneously, and `Gesture.Exclusive` to replace stacked gesture handlers that require failure of others.

#### Replacing `waitFor` and `simultaneousHandlers`

If you want to make relations between the gestures attached to the same view, you should use the Gesture Composition API described above. However, if you want to make a relation between gestures attached to different views, or between gesture and an old gesture handler, you should use `simultaneousWithExternalGesture` instead of `simultaneousHandlers`, and `requireExternalGestureToFail` instead of `waitFor`. In case you need a ref object to pass to an old gesture handler, you can set it to the gesture using `.withRef(refObject)` modifier.

## Composed gestures

Composed gestures (`Race`, `Simultaneous`, `Exclusive`) provide a simple way of building relations between gestures. See Gesture Composition for more details.

### Reference

```
import { GestureDetector, Gesture } from 'react-native-gesture-handler';

function App() {
  const pan = Gesture.Pan();
  const longPress = Gesture.LongPress();

  const composed = Gesture.Race(pan, longPress);

  return (
    <GestureDetector gesture={composed}>
      <Animated.View />
    </GestureDetector>
  );
}
```

## Common handler properties

warning

The old API will be removed in the future version of Gesture Handler. Please migrate to gestures API instead. Check out our upgrading guide for more information.

This page covers the common set of properties all gesture handler components expose.

#### Units

All handler component properties and event attributes that represent onscreen dimensions are expressed in screen density independent units we refer to as "points". These are the units commonly used in React Native ecosystem (e.g. in the layout system). They do not map directly to physical pixels but instead to iOS's points and to dp units on Android.

### Properties

This section describes properties that can be used with all gesture handler components:

#### `enabled`

Accepts a boolean value. Indicates whether the given handler should be analyzing stream of touch events or not. When set to `false` we can be sure that the handler's state will **never** become `ACTIVE`. If the value gets updated while the handler already started recognizing a gesture, then the handler's state it will immediately change to `FAILED` or `CANCELLED` (depending on its current state). Default value is `true`.

#### `shouldCancelWhenOutside`

Accepts a boolean value. When `true` the handler will cancel or fail recognition (depending on its current state) whenever the finger leaves the area of the connected view. Default value of this property is different depending on the handler type. Most handlers' `shouldCancelWhenOutside` property defaults to `false` except for the `LongPressGestureHandler` and `TapGestureHandler` which default to `true`.

#### `cancelsTouchesInView` (**iOS only**)

Accepts a boolean value. When `true`, the handler will cancel touches for native UI components (`UIButton`, `UISwitch`, etc) it's attached to when it becomes `ACTIVE`. Default value is `true`.

#### `simultaneousHandlers`

Accepts a react ref object or an array of refs to other handler components (refs should be created using `React.createRef()`). When set, the handler will be allowed to activate even if one or more of the handlers provided by their refs are in an `ACTIVE` state. It will also prevent the provided handlers from cancelling the current handler when they activate. Read more in the cross handler interaction section.

#### `waitFor`

Accepts a react ref object or an array of refs to other handler components (refs should be created using `React.createRef()`). When set the handler will not activate as long as the handlers provided by their refs are in the `BEGAN` state. Read more in the cross handler interaction section.

#### `hitSlop`

This parameter enables control over what part of the connected view area can be used to begin recognizing the gesture. When a negative number is provided the bounds of the view will reduce the area by the given number of points in each of the sides evenly.

Instead you can pass an object to specify how each boundary side should be reduced by providing different number of points for `left`, `right`, `top` or `bottom` sides. You can alternatively provide `horizontal` or `vertical` instead of specifying directly `left`, `right` or `top` and `bottom`. Finally, the object can also take `width` and `height` attributes. When `width` is set it is only allow to specify one of the sides `right` or `left`. Similarly when `height` is provided only `top` or `bottom` can be set. Specifying `width` or `height` is useful if we only want the gesture to activate on the edge of the view. In which case for example we can set `left: 0` and `width: 20` which would make it possible for the gesture to be recognize when started no more than 20 points from the left edge.

**IMPORTANT:** Note that this parameter is primarily designed to reduce the area where gesture can activate. Hence it is only supported for all the values (except `width` and `height`) to be non positive (0 or lower). Although on Android it is supported for the values to also be positive and therefore allow to expand beyond view bounds but not further than the parent view bounds. To achieve this effect on both platforms you can use React Native's View hitSlop property.

#### `userSelect` (Web only)

This parameter allows to specify which `userSelect` property should be applied to underlying view. Possible values are `"none" | "auto" | "text"`. Default value is set to `"none"`.

#### `activeCursor` (Web only)

This parameter allows to specify which cursor should be used when gesture activates. Supports all CSS cursor values (e.g. `"grab"`, `"zoom-in"`). Default value is set to `"auto"`.

#### `onGestureEvent`

Takes a callback that is going to be triggered for each subsequent touch event while the handler is in an ACTIVE state. Event payload depends on the particular handler type. Common set of event data attributes is documented below and handler specific attributes are documented on the corresponding handler pages. E.g. event payload for `PinchGestureHandler` contains `scale` attribute that represents how the distance between fingers changed since when the gesture started.

Instead of a callback `Animated.event` object can be used. Also Animated events with `useNativeDriver` flag enabled **are fully supported**.

#### `onHandlerStateChange`

Takes a callback that is going to be triggered when state of the given handler changes.

The event payload contains the same payload as in case of `onGestureEvent` including handler specific event attributes some handlers may provide.

In addition `onHandlerStateChange` event payload contains `oldState` attribute which represents the state of the handler right before the change.

Instead of a callback `Animated.event` object can be used. Also Animated events with `useNativeDriver` flag enabled **are fully supported**.

### Event data

This section describes the attributes of event object being provided to `onGestureEvent` and `onHandlerStateChange` callbacks:

#### `state`

Current state of the handler. Expressed as one of the constants exported under `State` object by the library. Refer to the section about handler state to learn more about how to use it.

#### `numberOfPointers`

Represents the number of pointers (fingers) currently placed on the screen.

Version: 2.x

## Gestures

###

###

###

###

###

###

###

###

###

###

###

###

###

###

###

## Touch events

#### Touch event attributes:

#### `eventType`

Type of the current event - whether the finger was placed on the screen, moved, lifted or cancelled.

#### `changedTouches`

An array of objects where every object represents a single touch. Contains information only about the touches that were affected by the event i.e. those that were placed down, moved, lifted or cancelled.

#### `allTouches`

An array of objects where every object represents a single touch. Contains information about all active touches.

#### `numberOfTouches`

Number representing the count of currently active touches.

caution

Don't rely on the order of items in the `touches` as it may change during the gesture, instead use the `id` attribute to track individual touches across events.

#### PointerData attributes:

#### `id`

A number representing id of the touch. It may be used to track the touch between events as the id will not change while it is being tracked.

#### `x`

X coordinate of the current position of the touch relative to the view attached to the `GestureDetector`. Expressed in point units.

#### `y`

Y coordinate of the current position of the touch relative to the view attached to the `GestureDetector`. Expressed in point units.

#### `absoluteX`

X coordinate of the current position of the touch relative to the window. The value is expressed in point units. It is recommended to use it instead of `x` in cases when the original view can be transformed as an effect of the gesture.

#### `absoluteY`

Y coordinate of the current position of the touch relative to the window. The value is expressed in point units. It is recommended to use it instead of `y` in cases when the original view can be transformed as an effect of the gesture.

## Gesture state manager

`GestureStateManager` allows to manually control the state of the gestures. Please note that `react-native-reanimated` is required to use it, since it allows for synchronously executing methods in worklets.

### Methods

#### `begin()`

Transition the gesture to the `BEGAN` state. This method will have no effect if the gesture has already activated or finished.

#### `activate()`

Transition the gesture to the `ACTIVE` state. This method will have no effect if the handler is already active, or has finished. If the gesture is `exclusive` with another one, the activation will be delayed until the gesture with higher priority fails.

#### `end()`

Transition the gesture to the `END` state. This method will have no effect if the handler has already finished.

#### `fail()`

Transition the gesture to the `FAILED` state. This method will have no effect if the handler has already finished.

## Touch events

#### Touch event attributes:

#### `eventType`

Type of the current event - whether the finger was placed on the screen, moved, lifted or cancelled.

#### `changedTouches`

An array of objects where every object represents a single touch. Contains information only about the touches that were affected by the event i.e. those that were placed down, moved, lifted or cancelled.

#### `allTouches`

An array of objects where every object represents a single touch. Contains information about all active touches.

#### `numberOfTouches`

Number representing the count of currently active touches.

caution

Don't rely on the order of items in the `touches` as it may change during the gesture, instead use the `id` attribute to track individual touches across events.

#### PointerData attributes:

#### `id`

A number representing id of the touch. It may be used to track the touch between events as the id will not change while it is being tracked.

#### `x`

X coordinate of the current position of the touch relative to the view attached to the `GestureDetector`. Expressed in point units.

#### `y`

Y coordinate of the current position of the touch relative to the view attached to the `GestureDetector`. Expressed in point units.

#### `absoluteX`

X coordinate of the current position of the touch relative to the window. The value is expressed in point units. It is recommended to use it instead of `x` in cases when the original view can be transformed as an effect of the gesture.

#### `absoluteY`

Y coordinate of the current position of the touch relative to the window. The value is expressed in point units. It is recommended to use it instead of `y` in cases when the original view can be transformed as an effect of the gesture.

## Gesture state manager

`GestureStateManager` allows to manually control the state of the gestures. Please note that `react-native-reanimated` is required to use it, since it allows for synchronously executing methods in worklets.

### Methods

#### `begin()`

Transition the gesture to the `BEGAN` state. This method will have no effect if the gesture has already activated or finished.

#### `activate()`

Transition the gesture to the `ACTIVE` state. This method will have no effect if the handler is already active, or has finished. If the gesture is `exclusive` with another one, the activation will be delayed until the gesture with higher priority fails.

#### `end()`

Transition the gesture to the `END` state. This method will have no effect if the handler has already finished.

#### `fail()`

Transition the gesture to the `FAILED` state. This method will have no effect if the handler has already finished.

## GestureDetector

`GestureDetector` is the main component of the RNGH2. It is responsible for creating and updating native gesture handlers based on the config of provided gesture. The most significant difference between it and old gesture handlers is that the `GestureDetector` can recognize more than one gesture at the time thanks to gesture composition. Keep in mind that `GestureDetector` is not compatible with the Animated API, nor with Reanimated 1.

### Reference

```
import { Gesture, GestureDetector } from 'react-native-gesture-handler';

function App() {
  const tap = Gesture.Tap();
  return (
    <GestureDetector gesture={tap}>
      <Animated.View />
    </GestureDetector>
  );
}
```

### Properties

#### `gesture`

A gesture object containing the configuration and callbacks. Can be any of the base gestures (`Tap`, `Pan`, `LongPress`, `Fling`, `Pinch`, `Rotation`, `ForceTouch`) or any `ComposedGesture` (`Race`, `Simultaneous`, `Exclusive`).

info

GestureDetector will decide whether to use Reanimated to process provided gestures based on callbacks they have. If any of the callbacks is a worklet, tools provided by the Reanimated will be utilized bringing ability to handle gestures synchronously.

Starting with Reanimated 2.3.0 Gesture Handler will provide a StateManager in the touch events that allows for managing the state of the gesture.

#### `userSelect` (Web only)

This parameter allows to specify which `userSelect` property should be applied to underlying view. Possible values are `"none" | "auto" | "text"`. Default value is set to `"none"`.

#### `touchAction` (Web only)

This parameter allows to specify which `touchAction` property should be applied to underlying view. Supports all CSS `touch-action` values (e.g. `"none"`, `"pan-y"`). Default value is set to `"none"`.

#### `enableContextMenu(value: boolean)` (Web only)

Specifies whether context menu should be enabled after clicking on underlying view with right mouse button. Default value is set to `false`.

### Remarks

- Gesture Detector will use first native view in its subtree to recognize gestures, however if this view is used only to group its children it may get automatically collapsed. Consider this example:

  ```
  export default function Example() {
    const tap = Gesture.Tap().onStart(() => {
      console.log('tap');
    });

    return (
      <GestureDetector gesture={tap}>
        <FunctionalComponent>
          <View style={styles.box} />
        </FunctionalComponent>
      </GestureDetector>
    );
  }

  function FunctionalComponent(props) {
    return <View collapsable={false}>{props.children}</View>;
  }
  ```

  If we were to remove the collapsable prop from the View, the gesture would stop working because it would be attached to a view that is not present in the view hierarchy. Gesture Detector adds this prop automatically to its direct child but it's impossible to do automatically for more complex view trees.

- Using the same instance of a gesture across multiple Gesture Detectors is not possible. Have a look at the code below:

  ```
  export default function Example() {
    const pan = Gesture.Pan();

    return (
      <View>
        <GestureDetector gesture={pan}>
          <View>
            <GestureDetector gesture={pan}> {/* Don't do this! */}
              <View />
            </GestureDetector>
          </View>
        </GestureDetector>
      </View>
    );
  }
  ```

  This example will throw an error, becuse we try to use the same instance of `Pan` in two different Gesture Detectors.

##

## Gesture

`Gesture` is the object that allows you to create and compose gestures.

### Reference

```
import { GestureDetector, Gesture } from 'react-native-gesture-handler';

function App() {
  const tap = Gesture.Tap();

  return (
    <GestureDetector gesture={tap}>
      <Animated.View />
    </GestureDetector>
  );
}
```

#### Gesture.Tap()

Creates a new instance of `TapGesture` with its default config and no callbacks.

#### Gesture.Pan()

Creates a new instance of `PanGesture` with its default config and no callbacks.

#### Gesture.LongPress()

Creates a new instance of `LongPressGesture` with its default config and no callbacks.

#### Gesture.Fling()

Creates a new instance of `FlingGesture` with its default config and no callbacks.

#### Gesture.Pinch()

Creates a new instance of `PinchGesture` with its default config and no callbacks.

#### Gesture.Rotation()

Creates a new instance of `RotationGesture` with its default config and no callbacks.

#### Gesture.Hover()

Creates a new instance of `HoverGesture` with its default config and no callbacks.

#### Gesture.ForceTouch()

Creates a new instance of `ForceTouchGesture` with its default config and no callbacks.

#### Gesture.Manual()

Creates a new instance of `ManualGesture` with its default config and no callbacks.

#### Gesture.Native()

Creates a new instance of `NativeGesture` with its default config and no callbacks.

#### Gesture.Race(gesture1, gesture2, gesture3, ...): ComposedGesture

Creates a gesture composed of those provided as arguments. Only one of those can become active and there are no restrictions to the activation of the gesture. The first one to activate will cancel all the others.

#### Gesture.Simultaneous(gesture1, gesture2, gesture3, ...): ComposedGesture

Creates a gesture composed of those provided as arguments. All of them can become active without cancelling the others.

#### Gesture.Exclusive(gesture1, gesture2, gesture3, ...): ComposedGesture

Creates a gesture composed of those provided as arguments. Only one of them can become active, but the first one has a higher priority than the second one, the second one has a higher priority than the third one, and so on. When all gestures are in the `BEGAN` state and the activation criteria for the second one is met, instead of activating it will wait until the first one fails (and only then it will activate) or until the first one activates (and then the second one will get cancelled). It is useful when you want to compose gestures with similar activation criteria (e.g. single and double tap at the same component, without Exclusive the single tap would activate every time user taps thus cancelling the double tap).

### Remarks

- Consider wrapping your gesture configurations with `useMemo`, as it will reduce the amount of work Gesture Handler has to do under the hood when updating gestures. For example:

```
import React from 'react';

function App() {
  const gesture = React.useMemo(
    () =>
      Gesture.Tap().onStart(() => {
        console.log('Number of taps:', tapNumber + 1);
        setTapNumber((value) => value + 1);
      }),
    [tapNumber, setTapNumber]
  );
  // ...
}
```

## Drawer Layout

caution

This is a cross-platform replacement for React Native's DrawerLayoutAndroid component. It provides a compatible API but allows for the component to be used on both Android and iOS. Please refer to React Native docs for the detailed usage for standard parameters.

### Usage:

`DrawerLayout` component isn't exported by default from the `react-native-gesture-handler` package. To use it, import it in the following way:

```
import DrawerLayout from 'react-native-gesture-handler/DrawerLayout';
```

### Properties:

On top of the standard list of parameters DrawerLayout has an additional set of attributes to customize its behavior. Please refer to the list below:

#### `drawerType`

possible values are: `front`, `back` or `slide` (default is `front`). It specifies the way the drawer will be displayed. When set to `front` the drawer will slide in and out along with the gesture and will display on top of the content view. When `back` is used the drawer displays behind the content view and can be revealed with gesture of pulling the content view to the side. Finally `slide` option makes the drawer appear like it is attached to the side of the content view; when you pull both content view and drawer will follow the gesture.

Type `slide`:

Type `front`:

Type `back`:

#### `edgeWidth`

number, allows for defining how far from the edge of the content view the gesture should activate.

#### `hideStatusBar`

boolean, when set to `true` Drawer component will use StatusBar API to hide the OS status bar whenever the drawer is pulled or when its in an "open" state.

#### `statusBarAnimation`

possible values are: `slide`, `none` or `fade` (defaults to `slide`). Can be used when `hideStatusBar` is set to `true` and will select the animation used for hiding/showing the status bar. See StatusBar documentation for more details.

#### `overlayColor`

color (default to `"black"`) of a semi-transparent overlay to be displayed on top of the content view when drawer gets open. A solid color should be used as the opacity is added by the Drawer itself and the opacity of the overlay is animated (from 0% to 70%).

#### `renderNavigationView`

function. This attribute is present in the standard implementation already and is one of the required params. Gesture handler version of DrawerLayout make it possible for the function passed as `renderNavigationView` to take an Animated value as a parameter that indicates the progress of drawer opening/closing animation (progress value is 0 when closed and 1 when opened). This can be used by the drawer component to animated its children while the drawer is opening or closing.

#### `onDrawerClose`

function. This function is called when the drawer is closed.

#### `onDrawerOpen`

function. This function is called when the drawer is opened.

#### `onDrawerSlide`

function. This function is called as a drawer sliding open from touch events. The progress of the drawer opening/closing is passed back as 0 when closed and 1 when opened.

#### `onDrawerStateChanged`

function. This function is called when the status of the drawer changes. It takes two arguments:

- `newState: DrawerState` - state of the `Drawer`. It can be one of the following:

  - `Idle`
  - `Dragging`
  - `Settling`

- `drawerWillShow: boolean` - if `true`, `Drawer` is about to open.

#### `enableTrackpadTwoFingerGesture` (iOS only)

Enables two-finger gestures on supported devices, for example iPads with trackpads. If not enabled the gesture will require click + drag, with enableTrackpadTwoFingerGesture swiping with two fingers will also trigger the gesture.

#### `children`

component or function. Children is a component which is rendered by default and is wrapped by drawer. However, it could be also a render function which takes an Animated value as a parameter that indicates the progress of drawer opening/closing animation (progress value is 0 when closed and 1 when opened) is the same way like `renderNavigationView` prop.

#### `mouseButton(value: MouseButton)` (Web & Android only)

Allows users to choose which mouse button should handler respond to. The enum `MouseButton` consists of the following predefined fields:

- `LEFT`
- `RIGHT`
- `MIDDLE`
- `BUTTON_4`
- `BUTTON_5`
- `ALL`

Arguments can be combined using `|` operator, e.g. `mouseButton(MouseButton.LEFT | MouseButton.RIGHT)`. Default value is set to `MouseButton.LEFT`.

#### `enableContextMenu(value: boolean)` (Web only)

Specifies whether context menu should be enabled after clicking on underlying view with right mouse button. Default value is set to `false`.

### Methods

#### `openDrawer(options)`

`openDrawer` can take an optional `options` parameter which is an object, enabling further customization of the open animation.

`options` has two optional properties:

`velocity`: number, the initial velocity of the object attached to the spring. Default 0 (object is at rest). `speed`: number, controls speed of the animation. Default 12.

#### `closeDrawer(options)`

`closeDrawer` can take an optional `options` parameter which is an object, enabling further customization of the close animation.

`options` has two optional properties:

`velocity`: number, the initial velocity of the object attached to the spring. Default 0 (object is at rest). `speed`: number, controls speed of the animation. Default 12.

### Example:

See the drawer example from GestureHandler Example App or view it directly on your phone by visiting our expo demo.

```
class Drawerable extends Component {
  handleDrawerSlide = (status) => {
    // outputs a value between 0 and 1
    console.log(status);
  };

  renderDrawer = () => {
    return (
      <View>
        <Text>I am in the drawer!</Text>
      </View>
    );
  };

  render() {
    return (
      <View style={{ flex: 1 }}>
        <DrawerLayout
          drawerWidth={200}
          drawerPosition={DrawerLayout.positions.Right}
          drawerType="front"
          drawerBackgroundColor="#ddd"
          renderNavigationView={this.renderDrawer}
          onDrawerSlide={this.handleDrawerSlide}>
          <View>
            <Text>Hello, it's me</Text>
          </View>
        </DrawerLayout>
      </View>
    );
  }
}
```

##

## Manual gestures

RNGH2 finally brings one of the most requested features: manual gestures and touch events. To demonstrate how to make a manual gesture we will make a simple one that tracks all pointers on the screen.

Step 1

First, we need a way to store information about the pointer: whether it should be visible and its position.

```
interface Pointer {
  visible: boolean;
  x: number;
  y: number;
}
```

Step 2

We also need a component to mark where a pointer is. In order to accomplish that we will make a component that accepts two shared values: one holding information about the pointer using the interface we just created, the other holding a bool indicating whether the gesture has activated. In this example when the gesture is not active, the ball representing it will be blue and when it is active the ball will be red and slightly bigger.

```
import { StyleSheet } from 'react-native';
import Animated, {
  useAnimatedStyle,
  useSharedValue,
} from 'react-native-reanimated';

function PointerElement(props: {
  pointer: Animated.SharedValue<Pointer>,
  active: Animated.SharedValue<boolean>,
}) {
  const animatedStyle = useAnimatedStyle(() => ({
    transform: [
      { translateX: props.pointer.value.x },
      { translateY: props.pointer.value.y },
      {
        scale:
          (props.pointer.value.visible ? 1 : 0) *
          (props.active.value ? 1.3 : 1),
      },
    ],
    backgroundColor: props.active.value ? 'red' : 'blue',
  }));

  return <Animated.View style={[styles.pointer, animatedStyle]} />;
}

// ...

const styles = StyleSheet.create({
  pointer: {
    width: 60,
    height: 60,
    borderRadius: 30,
    backgroundColor: 'red',
    position: 'absolute',
    marginStart: -30,
    marginTop: -30,
  },
});
```

Step 3

Now we have to make a component that will handle the gesture and draw all the pointer indicators. We will store data about pointers in an array of size 12 as that is the maximum number of touches that RNGH will track, and render them inside an Animated.View.

```
import { Gesture, GestureDetector } from 'react-native-gesture-handler';

export default function Example() {
  const trackedPointers: Animated.SharedValue<Pointer>[] = [];
  const active = useSharedValue(false);

  for (let i = 0; i < 12; i++) {
    trackedPointers[i] =
      useSharedValue <
      Pointer >
      {
        visible: false,
        x: 0,
        y: 0,
      };
  }

  const gesture = Gesture.Manual();

  return (
    <GestureDetector gesture={gesture}>
      <Animated.View style={{ flex: 1 }}>
        {trackedPointers.map((pointer, index) => (
          <PointerElement pointer={pointer} active={active} key={index} />
        ))}
      </Animated.View>
    </GestureDetector>
  );
}
```

Step 4

We have our components set up and we can finally get to making the gesture! We will start with onTouchesDown where we need to set position of the pointers and make them visible. We can get this information from the touches property of the event. In this case we will also check how many pointers are on the screen and activate the gesture if there are at least two.

```
const gesture = Gesture.Manual().onTouchesDown((e, manager) => {
  for (const touch of e.changedTouches) {
    trackedPointers[touch.id].value = {
      visible: true,
      x: touch.x,
      y: touch.y,
    };
  }

  if (e.numberOfTouches >= 2) {
    manager.activate();
  }
});
```

Step 5

Next, we will handle pointer movement. In onTouchesMove we will simply update the position of moved pointers.

```
const gesture = Gesture.Manual()
    ...
    .onTouchesMove((e, _manager) => {
      for (const touch of e.changedTouches) {
        trackedPointers[touch.id].value = {
          visible: true,
          x: touch.x,
          y: touch.y,
        };
      }
    })
```

Step 6

We also need to handle lifting fingers from the screen, which corresponds to onTouchesUp. Here we will just hide the pointers that were lifted and end the gesture if there are no more pointers on the screen. Note that we are not handling onTouchesCancelled as in this very basic case we don't expect it to happen, however you should clear data about cancelled pointers (most of the time all active ones) when it is called.

```
const gesture = Gesture.Manual()
    ...
    .onTouchesUp((e, manager) => {
      for (const touch of e.changedTouches) {
        trackedPointers[touch.id].value = {
          visible: false,
          x: touch.x,
          y: touch.y,
        };
      }

      if (e.numberOfTouches === 0) {
        manager.end();
      }
    })
```

Step 7

Now that our pointers are being tracked correctly and we have the state management, we can handle activation and ending of the gesture. In our case, we will simply set the active shared value either to true or false.

```
const gesture = Gesture.Manual()
  ...
  .onStart(() => {
    active.value = true;
  })
  .onEnd(() => {
    active.value = false;
  });
```

And that's all! As you can see using manual gestures is really easy but as you can imagine, manual gestures are a powerful tool that makes it possible to accomplish things that were previously impossible with RNGH.

### Modifying existing gestures

While manual gestures open great possibilities we are aware that reimplementing pinch or rotation from scratch just because you need to activate in specific circumstances or require position of the fingers, would be a waste of time as those gestures are already available. Therefore, you can use touch events with every gesture to extract more detailed information about the gesture than what the basic events alone provide. We also added a `manualActivation` modifier on all continuous gestures, which prevents the gesture it is applied to from activating automatically, giving you full control over its behavior.

This functionality makes another highly requested feature possible: drag after long press. Simply set `manualActivation` to `true` on a `PanGesture` and use `StateManager` to fail the gesture if the user attempts to drag the component sooner than the duration of the long press.

## Pressable

info

This component is a drop-in replacement for the `Pressable` component.

`Pressable` is a component that can detect various stages of tap, press, and hover interactions on any of its children.

#### Usage:

To use `Pressable`, import it in the following way:

```
import { Pressable } from 'react-native-gesture-handler';
```

### Properties

#### `children`

either children or a render function that receives a boolean reflecting whether the component is currently pressed.

#### `style`

either view styles or a function that receives a boolean reflecting whether the component is currently pressed and returns view styles.

#### `onPress`

called after `onPressOut` when a single tap gesture is detected.

#### `onPressIn`

called before `onPress` when a touch is engaged.

#### `onPressOut`

called before `onPress` when a touch is released.

#### `onLongPress`

called immediately after pointer has been down for at least `delayLongPress` milliseconds (`500` ms by default).

After `onLongPress` has been called, `onPressOut` will be called as soon as the pointer is lifted and `onPress` will not be called at all.

#### `cancelable`

whether a press gesture can be interrupted by a parent gesture such as a scroll event. Defaults to `true`.

#### `onHoverIn` (Web only)

called when pointer is hovering over the element.

#### `onHoverOut` (Web only)

called when pointer stops hovering over the element.

#### `delayHoverIn` (Web only)

duration to wait after hover in before calling `onHoverIn`.

#### `delayHoverOut` (Web only)

duration to wait after hover out before calling `onHoverOut`.

#### `delayLongPress`

duration (in milliseconds) from `onPressIn` before `onLongPress` is called.

#### `disabled`

whether the `Pressable` behavior is disabled.

#### `hitSlop` (Android & iOS only)

additional distance outside of the view in which a press is detected and `onPressIn` is triggered.

Accepts values of type `number` or `Rect`

#### `pressRetentionOffset` (Android & iOS only)

additional distance outside of the view (or `hitSlop` if present) in which a touch is considered a press before `onPressOut` is triggered.

Accepts values of type `number` or `Rect`

#### `android_disableSound` (Android only)

if `true`, doesn't play system sound on touch.

#### `android_ripple` (Android only)

enables the Android ripple effect and configures its color, radius and other parameters.

Accepts values of type `RippleConfig`

#### `testOnly_pressed`

used only for documentation or testing (e.g. snapshot testing).

#### `unstable_pressDelay`

duration (in milliseconds) to wait after press down before calling `onPressIn`.

#### Example:

See the full pressable example from `GestureHandler` example app.

```
import { View, Text, StyleSheet } from 'react-native';
import { Pressable } from 'react-native-gesture-handler';

export default function Example() {
  return (
    <Pressable
      style={({ pressed }) => (pressed ? styles.highlight : styles.pressable)}
      hitSlop={20}
      pressRetentionOffset={20}>
      <View style={styles.textWrapper}>
        <Text style={styles.text}>Pressable!</Text>
      </View>
    </Pressable>
  );
}

const styles = StyleSheet.create({
  pressable: {
    width: 120,
    height: 120,
    backgroundColor: 'mediumpurple',
    borderWidth: StyleSheet.hairlineWidth,
  },
  highlight: {
    width: 120,
    height: 120,
    backgroundColor: 'red',
    borderWidth: StyleSheet.hairlineWidth,
  },
  textWrapper: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
  },
  text: {
    color: 'black',
  },
});
```

## Gesture composition & interactions

Composing gestures is much simpler in RNGH2, you don't need to create a ref for every gesture that depends on another one. Instead you can use `Race`, `Simultaneous` and `Exclusive` methods provided by the `Gesture` object.

### Race

Only one of the provided gestures can become active at the same time. The first gesture to become active will cancel the rest of the gestures. It accepts variable number of arguments. It is the equivalent to having more than one gesture handler without defining `simultaneousHandlers` and `waitFor` props.

For example, lets say that you have a component that you want to make draggable but you also want to show additional options on long press. Presumably you would not want the component to move after the long press activates. You can accomplish this using `Race`:

> Note: the `useSharedValue` and `useAnimatedStyle` are part of `react-native-reanimated`.

```
import { GestureDetector, Gesture } from 'react-native-gesture-handler';
import Animated, {
  useSharedValue,
  useAnimatedStyle,
  withTiming,
} from 'react-native-reanimated';

function App() {
  const offset = useSharedValue({ x: 0, y: 0 });
  const start = useSharedValue({ x: 0, y: 0 });
  const popupPosition = useSharedValue({ x: 0, y: 0 });
  const popupAlpha = useSharedValue(0);

  const animatedStyles = useAnimatedStyle(() => {
    return {
      transform: [
        { translateX: offset.value.x },
        { translateY: offset.value.y },
      ],
    };
  });

  const animatedPopupStyles = useAnimatedStyle(() => {
    return {
      transform: [
        { translateX: popupPosition.value.x },
        { translateY: popupPosition.value.y },
      ],
      opacity: popupAlpha.value,
    };
  });

  const dragGesture = Gesture.Pan()
    .onStart((_e) => {
      popupAlpha.value = withTiming(0);
    })
    .onUpdate((e) => {
      offset.value = {
        x: e.translationX + start.value.x,
        y: e.translationY + start.value.y,
      };
    })
    .onEnd(() => {
      start.value = {
        x: offset.value.x,
        y: offset.value.y,
      };
    });

  const longPressGesture = Gesture.LongPress().onStart((_event) => {
    popupPosition.value = { x: offset.value.x, y: offset.value.y };
    popupAlpha.value = withTiming(1);
  });

  const composed = Gesture.Race(dragGesture, longPressGesture);

  return (
    <Animated.View>
      <Popup style={animatedPopupStyles} />
      <GestureDetector gesture={composed}>
        <Component style={animatedStyles} />
      </GestureDetector>
    </Animated.View>
  );
}
```

### Simultaneous

All of the provided gestures can activate at the same time. Activation of one will not cancel the other. It is the equivalent to having some gesture handlers, each with `simultaneousHandlers` prop set to the other handlers.

For example, if you want to make a gallery app, you might want user to be able to zoom, rotate and pan around photos. You can do it with `Simultaneous`:

> Note: the `useSharedValue` and `useAnimatedStyle` are part of `react-native-reanimated`.

```
import { GestureDetector, Gesture } from 'react-native-gesture-handler';
import Animated, {
  useSharedValue,
  useAnimatedStyle,
} from 'react-native-reanimated';

function App() {
  const offset = useSharedValue({ x: 0, y: 0 });
  const start = useSharedValue({ x: 0, y: 0 });
  const scale = useSharedValue(1);
  const savedScale = useSharedValue(1);
  const rotation = useSharedValue(0);
  const savedRotation = useSharedValue(0);
  const animatedStyles = useAnimatedStyle(() => {
    return {
      transform: [
        { translateX: offset.value.x },
        { translateY: offset.value.y },
        { scale: scale.value },
        { rotateZ: `${rotation.value}rad` },
      ],
    };
  });

  const dragGesture = Gesture.Pan()
    .averageTouches(true)
    .onUpdate((e) => {
      offset.value = {
        x: e.translationX + start.value.x,
        y: e.translationY + start.value.y,
      };
    })
    .onEnd(() => {
      start.value = {
        x: offset.value.x,
        y: offset.value.y,
      };
    });

  const zoomGesture = Gesture.Pinch()
    .onUpdate((event) => {
      scale.value = savedScale.value * event.scale;
    })
    .onEnd(() => {
      savedScale.value = scale.value;
    });

  const rotateGesture = Gesture.Rotation()
    .onUpdate((event) => {
      rotation.value = savedRotation.value + event.rotation;
    })
    .onEnd(() => {
      savedRotation.value = rotation.value;
    });

  const composed = Gesture.Simultaneous(
    dragGesture,
    Gesture.Simultaneous(zoomGesture, rotateGesture)
  );

  return (
    <Animated.View>
      <GestureDetector gesture={composed}>
        <Photo style={animatedStyles} />
      </GestureDetector>
    </Animated.View>
  );
}
```

### Exclusive

Only one of the provided gestures can become active, with the first one having a higher priority than the second one (if both gestures are still possible, the second one will wait for the first one to fail before it activates), second one having a higher priority than the third one, and so on. It is equivalent to having some gesture handlers where the second one has the `waitFor` prop set to the first handler, third one has the `waitFor` prop set to the first and the second one, and so on.

For example, if you want to make a component that responds to single tap as well as to a double tap, you can accomplish that using `Exclusive`:

> Note: the `useSharedValue` and `useAnimatedStyle` are part of `react-native-reanimated`.

```
import { GestureDetector, Gesture } from 'react-native-gesture-handler';

function App() {
  const singleTap = Gesture.Tap().onEnd((_event, success) => {
    if (success) {
      console.log('single tap!');
    }
  });
  const doubleTap = Gesture.Tap()
    .numberOfTaps(2)
    .onEnd((_event, success) => {
      if (success) {
        console.log('double tap!');
      }
    });

  const taps = Gesture.Exclusive(doubleTap, singleTap);

  return (
    <GestureDetector gesture={taps}>
      <Component />
    </GestureDetector>
  );
}
```

### Cross-component interactions

You may have noticed that gesture composition described above requires you to mount all of the composed gestures under a single `GestureDetector`, effectively attaching them to the same underlying component. You can customize how gestures interact with each other across multiple components in a couple of ways:

### requireExternalGestureToFail

`requireExternalGestureToFail` allows to delay activation of the handler until all handlers passed as arguments to this method fail (or don't begin at all).

For example, you may want to have two nested components, both of them can be tapped by the user to trigger different actions: outer view requires one tap, but the inner one requires 2 taps. If you don't want the first tap on the inner view to activate the outer handler, you must make the outer gesture wait until the inner one fails:

```
import React from 'react';
import { View, StyleSheet } from 'react-native';
import {
  GestureDetector,
  Gesture,
  GestureHandlerRootView,
} from 'react-native-gesture-handler';

export default function Example() {
  const innerTap = Gesture.Tap()
    .numberOfTaps(2)
    .onStart(() => {
      console.log('inner tap');
    });

  const outerTap = Gesture.Tap()
    .onStart(() => {
      console.log('outer tap');
    })
    .requireExternalGestureToFail(innerTap);

  return (
    <GestureHandlerRootView style={styles.container}>
      <GestureDetector gesture={outerTap}>
        <View style={styles.outer}>
          <GestureDetector gesture={innerTap}>
            <View style={styles.inner} />
          </GestureDetector>
        </View>
      </GestureDetector>
    </GestureHandlerRootView>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    alignItems: 'center',
    justifyContent: 'center',
  },
  outer: {
    width: 250,
    height: 250,
    backgroundColor: 'lightblue',
  },
  inner: {
    width: 100,
    height: 100,
    backgroundColor: 'blue',
    alignSelf: 'center',
  },
});
```

### blocksExternalGesture

`blocksExternalGesture` works similarly to `requireExternalGestureToFail` but the direction of the relation is reversed - instead of being one-to-many relation, it's many-to-one. It's especially useful for making lists where the `ScrollView` component needs to wait for every gesture underneath it. All that's required to do is to pass a ref, for example:

```
import React, { useRef } from 'react';
import { StyleSheet } from 'react-native';
import {
  GestureDetector,
  Gesture,
  GestureHandlerRootView,
  ScrollView,
} from 'react-native-gesture-handler';
import Animated, {
  useSharedValue,
  useAnimatedStyle,
  withTiming,
} from 'react-native-reanimated';

const ITEMS = ['red', 'green', 'blue', 'yellow'];

function Item({ backgroundColor, scrollRef }) {
  const scale = useSharedValue(1);
  const zIndex = useSharedValue(1);

  const pinch = Gesture.Pinch()
    .blocksExternalGesture(scrollRef)
    .onBegin(() => {
      zIndex.value = 100;
    })
    .onChange((e) => {
      scale.value *= e.scaleChange;
    })
    .onFinalize(() => {
      scale.value = withTiming(1, undefined, (finished) => {
        if (finished) {
          zIndex.value = 1;
        }
      });
    });

  const animatedStyles = useAnimatedStyle(() => ({
    transform: [{ scale: scale.value }],
    zIndex: zIndex.value,
  }));

  return (
    <GestureDetector gesture={pinch}>
      <Animated.View
        style={[
          { backgroundColor: backgroundColor },
          styles.item,
          animatedStyles,
        ]}
      />
    </GestureDetector>
  );
}

export default function Example() {
  const scrollRef = useRef();

  return (
    <GestureHandlerRootView style={styles.container}>
      <ScrollView style={styles.container} ref={scrollRef}>
        {ITEMS.map((item) => (
          <Item backgroundColor={item} key={item} scrollRef={scrollRef} />
        ))}
      </ScrollView>
    </GestureHandlerRootView>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
  },
  item: {
    flex: 1,
    aspectRatio: 1,
  },
});
```

### simultaneousWithExternalGesture

`simultaneousWithExternalGesture` allows gestures across different components to be recognized simultaneously. For example, you may want to have two nested views, both with tap gesture attached. Both of them require one tap, but tapping the inner one should also activate the gesture attached to the outer view:

```
import React from 'react';
import { View, StyleSheet } from 'react-native';
import {
  GestureDetector,
  Gesture,
  GestureHandlerRootView,
} from 'react-native-gesture-handler';

export default function Example() {
  const innerTap = Gesture.Tap()
    .onStart(() => {
      console.log('inner tap');
    });

  const outerTap = Gesture.Tap()
    .onStart(() => {
      console.log('outer tap');
    })
    .simultaneousWithExternalGesture(innerTap);

  return (
    <GestureHandlerRootView style={styles.container}>
      <GestureDetector gesture={outerTap}>
        <View style={styles.outer}>
          <GestureDetector gesture={innerTap}>
            <View style={styles.inner} />
          </GestureDetector>
        </View>
      </GestureDetector>
    </GestureHandlerRootView>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    alignItems: 'center',
    justifyContent: 'center',
  },
  outer: {
    width: 250,
    height: 250,
    backgroundColor: 'lightblue',
  },
  inner: {
    width: 100,
    height: 100,
    backgroundColor: 'blue',
    alignSelf: 'center',
  },
});
```

## Reanimated Drawer Layout

Cross-platform replacement for the React Native's DrawerLayoutAndroid component.\
For detailed usage of standard parameters, please refer to the React Native docs.

#### Usage:

To use it, import it in the following way:

```
import ReanimatedDrawerLayout from 'react-native-gesture-handler/ReanimatedDrawerLayout';
```

### Properties:

#### `drawerType`

specifies the way the drawer will be displayed. Accepts values of the `DrawerPosition` enum. Defaults to `FRONT`.

- `FRONT` the drawer will be displayed above the content view.
- `BACK` the drawer will be displayed below the content view, revealed by sliding away the content view.
- `SLIDE` the drawer will appear attached to the content view, opening it slides both the drawer and the content view.

| `FRONT` | `BACK` | `SLIDE` |
| ------- | ------ | ------- |
|         |        |         |

#### `edgeWidth`

width of the invisible, draggable area on the edge of the content view, which can be dragged to open the drawer.

#### `hideStatusBar`

a boolean value. When set to `true`, drawer component will use StatusBar API to hide the OS status bar when the drawer is dragged or idle in the `open` position.

#### `statusBarAnimation`

a string with possible values: `slide`, `none` or `fade`. Defaults to `slide`. May be used in combination with `hideStatusBar` to select the animation used for hiding the status bar. See StatusBar API docs.

#### `overlayColor`

color of the background overlay on top of the content window when the drawer is `open`.\
This color's opacity animates from 0% to 100% as the drawer transitions from closed to open. Defaults to `rgba(0, 0, 0, 0.7)`.

#### `renderNavigationView`

a renderer function for the drawer component, provided with a `progress` parameter.

- `progress` - `SharedValue` that indicates the progress of drawer opening/closing animation.

  - equals `0` when the `drawer` is closed and `1` when the `drawer` is opened
  - can be used by the `drawer` component to animated its children while the `drawer` is opening or closing

#### `onDrawerClose`

a function which is called when the drawer has been closed.

#### `onDrawerOpen`

a function which is called when the drawer has been opened.

#### `onDrawerSlide`

a function which is called when drawer is moving or animating, provided with a `progress` parameter.

- `progress` - `SharedValue` that indicates the progress of drawer opening/closing animation.

  - equals `0` when the `drawer` is closed and `1` when the `drawer` is opened
  - can be used by the `drawer` component to animated its children while the `drawer` is opening or closing

#### `onDrawerStateChanged`

a function which is called when the status of the drawer changes. It takes two arguments:

- `newState` - interaction state of the drawer. It can be one of the following:

  - `DrawerState.IDLE`
  - `DrawerState.DRAGGING`
  - `DrawerState.SETTLING`

- `drawerWillShow` - `true` when `drawer` started animating to `open` position, `false` otherwise.

#### `enableTrackpadTwoFingerGesture` (iOS only)

enables two-finger gestures on supported devices, for example iPads with trackpads. If not enabled, the gesture will require click + drag, with `enableTrackpadTwoFingerGesture` swiping with two fingers will also trigger the gesture.

#### `children`

either a component that's rendered in the content view or a function. If `children` is a function, it is provided with a `progress` parameter.

- `progress` - `SharedValue` that indicates the progress of drawer opening/closing animation.

  - equals `0` when the `drawer` is closed and `1` when the `drawer` is opened
  - can be used by the `drawer` component to animated its children while the `drawer` is opening or closing

#### `mouseButton(value: MouseButton)` (Web & Android only)

allows users to choose which mouse button should handler respond to. The enum `MouseButton` consists of the following predefined fields:

- `LEFT`
- `RIGHT`
- `MIDDLE`
- `BUTTON_4`
- `BUTTON_5`
- `ALL`

Arguments can be combined using `|` operator, e.g. `mouseButton(MouseButton.LEFT | MouseButton.RIGHT)`. Defaults to `MouseButton.LEFT`.

#### `enableContextMenu(value: boolean)` (Web only)

specifies whether context menu should be enabled after clicking on underlying view with right mouse button. Defaults to `false`.

### Methods

#### `openDrawer(options)`

`openDrawer` accepts an optional `options` parameter, which is an object with the following optional properties:

- `initialVelocity` - the initial velocity of the object attached to the spring. Defaults to `0`.
- `animationSpeed` - controls speed of the animation. Defaults to `1`.

#### `closeDrawer(options)`

`closeDrawer` accepts an optional `options` parameter, which is an object with the following optional properties:

- `initialVelocity` - initial velocity of the object attached to the spring. Defaults to `0`.
- `animationSpeed` - controls speed of the animation. Defaults to `1`.

### Example:

See the reanimated drawer layout example from GestureHandler example app.

```
import React, { useRef } from 'react';
import { StyleSheet, Text, View } from 'react-native';
import { Gesture, GestureDetector } from 'react-native-gesture-handler';

import ReanimatedDrawerLayout, {
  DrawerType,
  DrawerPosition,
  DrawerLayoutMethods,
} from 'react-native-gesture-handler/ReanimatedDrawerLayout';

const DrawerPage = () => {
  return (
    <View style={styles.drawerContainer}>
      <Text>Lorem ipsum</Text>
    </View>
  );
};

export default function ReanimatedDrawerExample() {
  const drawerRef = useRef < DrawerLayoutMethods > null;
  const tapGesture = Gesture.Tap()
    .runOnJS(true)
    .onStart(() => drawerRef.current?.openDrawer());

  return (
    <ReanimatedDrawerLayout
      ref={drawerRef}
      renderNavigationView={() => <DrawerPage />}
      drawerPosition={DrawerPosition.LEFT}
      drawerType={DrawerType.FRONT}>
      <View style={styles.innerContainer}>
        <GestureDetector gesture={tapGesture}>
          <View style={styles.box}>
            <Text>Open drawer</Text>
          </View>
        </GestureDetector>
      </View>
    </ReanimatedDrawerLayout>
  );
}

const styles = StyleSheet.create({
  drawerContainer: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
    backgroundColor: 'pink',
  },
  innerContainer: {
    flex: 1,
    backgroundColor: 'white',
    alignItems: 'center',
    justifyContent: 'center',
    gap: 20,
  },
  box: {
    padding: 20,
    backgroundColor: 'pink',
  },
});
```

## Introduction

Gesture Handler provides a declarative API exposing the native platform's touch and gesture system to React Native. It's designed to be a replacement of React Native's built in touch system called Gesture Responder System. Using native touch handling allows to address the performance limitations of React Native's Gesture Responder System. It also provides more control over the platform's native components that can handle gestures on their own. If you want to learn more, we recommend this talk by Krzysztof Magiera in which he explains issues with the responder system.

The main benefits of using React Native Gesture Handler are:

- A way to use a platform's native touch handling system for recognizing gestures (like pinch, rotation, pan and a few others).
- The ability to define relations between gestures to ensure gestures, and possibly native components, will not conflict with each other.
- Mechanisms to use touchable components that run in native thread and follow platform default behavior; e.g. in the event they are in a scrollable component, turning into pressed state is slightly delayed to prevent it from highlighting when you fling.
- Close integration with `react-native-reanimated` to process touch events on the UI thread.
- Support for different input devices like touch screens, pens and mice.
- Ability to include any native component into the Gesture Handler's touch system, making it work alongside your gestures.

info

We recommended to use Reanimated to implement gesture-driven animations with Gesture Handler. Its more advanced features rely heavily on worklets and the UI runtime provided by Reanimated.

### Learning resources

#### Apps

Gesture Handler Example App – official gesture handler "showcase" app.

#### Talks and workshops

Declarative future of gestures and animations in React Native by Krzysztof Magiera - talk that explains motivation behind creating gesture handler library. It also presents react-native-reanimated and how and when it can be used with gesture handler.

React Native workshop with Expo team @ReactEurope 2018 by Brent Vatne – great workshop explaining gesture handler in details and presenting a few exercises that will help get you started.

Living in an async world of React Native by Krzysztof Magiera – talk which highlights some issue with the React Native's touch system Gesture Handler aims to address. Also the motivation for building this library is explained.

React Native Touch & Gesture by Krzysztof Magiera - talk explaining JS responder system limitations and points out some of the core features of Gesture Handler.

### Contributing

If you are interested in the project and want to contribute or support it in other ways don't hesitate to contact anyone from the team on Twitter or Bluesky (links below)!

All PRs are welcome, but talk to us before you start working on something big.

The easiest way to get started with contributing code is by:

- Reviewing the list of open issues and trying to solve the one that seem approachable to you.
- Updating the documentation whenever you see some information is unclear, missing or out of date.

Code is only one way how you can contribute. You may want to consider replying on issues if you know how to help.

### Community

We are very proud of the community that has been build around this package. We really appreciate all your help regardless of it is a pull request, issue report, helping others by commenting on existing issues or posting some demo or video tutorial on social media. If you've build something with this library you'd like to share, please contact us as we'd love to help share it with others.

#### Gesture Handler Team 🚀

Jakub Piasecki

Michał Bert

Ignacy Łątka

Krzysztof Magiera

#### Sponsors

We really appreciate our sponsors! Thanks to them we can develop our library and make the react-native world a better place. Special thanks for:

## Troubleshooting

### Troubleshooting

Thanks for giving this library a try! We are sorry that you might have encountered issues though. Here is how you can seek help:

1. Search over the issues on Github. There is a chance someone had this problem in the past and it has been resolved!
2. When sure your problem hasn't been reported or was reported but the proposed solution doesn't work for you please follow our issue reporting guidelines.
3. You can try seeking help on Expo Developers Discord where we often hang out.
4. If you feel like reading the source code I highly recommend it, as this is by far the best resource and gives you the most up to date insights into how the library works and what might be causing the bug.
5. If you managed to find the solution consider contributing a fix or update our documentation to make this information easier to find for the others in the future.

### Reporting issues

This library is maintained by a very small team. Please be mindful of that when reporting issue and when it happens that we can't get back to you as soon as you might expect. We would love to fix all the problems as soon as possible, but often our time is constraint with other issues/features or projects. To make it easier for us to understand your issue and to be able to approach it sooner you can help by:

- Making sure the issue description is complete. Please include all the details about your environment (library version, RN version, device OS etc).
- It is the best to provide an example app that reproduces the issue you are having. Put it up on gist, snack or create a repo on Github – it doesn't matter as long as we can easily pull it in, run and see the issue.
- Explain how you run your repro app and what steps to take to reproduce the issue.
- Isolate your issue from other dependencies you might be using and make the repro app as minimal as possible.
- If you have spent some time figuring out the root cause of the problem you can leave a note about your findings so far.
- **Do not comment on closed issues**. It is very unlikely that we are going to notice your comment in such a case. If the issue has been closed, but the proposed solution doesn't work for you, please open a new one providing all the information necessary and linking to the solution you have tried.

### It's not a bug, it's a feature

- Changing `enabled` prop during a gesture has no effect, only when a gesture starts (that is a finger touches the screen) the `enabled` prop is taken into consideration to decide whether to extract (or not) the gesture and provide it with stream of events to analyze.
- `Native` gesture may not conform to the standard state flow due to platform specific workarounds to incorporate native views into RNGH.
- Keep in mind that `Touchables` from RNGH are rendering two additional views that may need to be styled separately to achieve desired effect (`style` and `containerStyle` props).
- In order for the gesture composition to work, all composed gestures must be attached to the same `GestureHandlerRootView`.

#### Multiple instances of Gesture Handler were detected

This error usually happens when in your project there exists more than one instance of Gesture Handler. It can occur when some of your dependencies have installed Gesture Handler inside their own `node_modules` instead of using it as a peer dependency. In this case two different versions of Gesture Handler JS module try to install the same Native Module. You can resolve this problem manually by modifying your `package.json` file.

You can check which libraries are using Gesture Handler, for example, with the command:

```
npm ls react-native-gesture-handler
yarn why react-native-gesture-handler
```

If you use `yarn` you should add `resolution` property.

```
"resolutions": {
  "react-native-gesture-handler": <Gesture Handler version>
}
```

If you use `npm` you should add `overrides` property.

```
"overrides": {
  "react-native-gesture-handler": <Gesture Handler version>
}
```

After that you need to run your package manager again

```
yarn
```

or

```
npm install
```

#### Automatic workletization of gesture callbacks

Reanimated's Babel plugin is setup in a way that automatically marks callbacks passed to gestures in the configuration chain as worklets. This means that as long as all your callbacks are defined in a single chain, you don't need to add a `'worklet';` directive at the beginning of the functions. Here is an example that will be automatically workletized:

```
const gesture = Gesture.Tap().onBegin(() => {
  console.log(_WORKLET);
});
```

And here are some examples that won't:

```
const gesture = Gesture.Tap();
gesture.onBegin(() => {
  console.log(_WORKLET);
});
```

```
const callback = () => {
  console.log(_WORKLET);
};
const gesture = Gesture.Tap().onBegin(callback);
```

```
const callback = () => {
  console.log(_WORKLET);
};
const gesture = Gesture.Tap();
gesture.onBegin(callback);
```

In the above cases, you should add a `"worklet";` directive at the beginning of the callbacks, like so:

```
const callback = () => {
  "worklet";
  console.log(_WORKLET);
};
const gesture = Gesture.Tap().onBegin(callback);
```

```
const callback = () => {
  "worklet";
  console.log(_WORKLET);
};
const gesture = Gesture.Tap();
gesture.onBegin(callback);
```

## Tap gesture

A discrete gesture that recognizes one or many taps.

Tap gestures detect one or more fingers briefly touching the screen. The fingers involved in these gestures must not move significantly from their initial touch positions. The required number of taps and allowed distance from initial position may be configured. For example, you might configure tap gesture recognizers to detect single taps, double taps, or triple taps.

In order for a gesture to activate, specified gesture requirements such as minPointers, numberOfTaps, maxDist, maxDuration, and maxDelayMs (explained below) must be met. Immediately after the gesture activates, it will end.

`Tap Gesture`

### Example

```
import { View, StyleSheet } from 'react-native';
import { Gesture, GestureDetector } from 'react-native-gesture-handler';

export default function App() {
  const singleTap = Gesture.Tap()
    .maxDuration(250)
    .onStart(() => {
      console.log('Single tap!');
    });

  const doubleTap = Gesture.Tap()
    .maxDuration(250)
    .numberOfTaps(2)
    .onStart(() => {
      console.log('Double tap!');
    });

  return (
    <GestureDetector gesture={Gesture.Exclusive(doubleTap, singleTap)}>
      <View style={styles.box} />
    </GestureDetector>
  );
}

const styles = StyleSheet.create({
  box: {
    height: 120,
    width: 120,
    backgroundColor: '#b58df1',
    borderRadius: 20,
    marginBottom: 30,
  },
});
```

### Config

#### Properties specific to `TapGesture`:

#### `minPointers(value: number)`

Minimum number of pointers (fingers) required to be placed before the gesture activates. Should be a positive integer. The default value is 1.

#### `maxDuration(value: number)`

Maximum time, expressed in milliseconds, that defines how fast a finger must be released after a touch. The default value is 500.

#### `maxDelay(value: number)`

Maximum time, expressed in milliseconds, that can pass before the next tap — if many taps are required. The default value is 500.

#### `numberOfTaps(value: number)`

Number of tap gestures required to activate the gesture. The default value is 1.

#### `maxDeltaX(value: number)`

Maximum distance, expressed in points, that defines how far the finger is allowed to travel along the X axis during a tap gesture. If the finger travels further than the defined distance along the X axis and the gesture hasn't yet activated, it will fail to recognize the gesture.

#### `maxDeltaY(value: number)`

Maximum distance, expressed in points, that defines how far the finger is allowed to travel along the Y axis during a tap gesture. If the finger travels further than the defined distance along the Y axis and the gesture hasn't yet activated, it will fail to recognize the gesture.

#### `maxDistance(value: number)`

Maximum distance, expressed in points, that defines how far the finger is allowed to travel during a tap gesture. If the finger travels further than the defined distance and the gesture hasn't yet activated, it will fail to recognize the gesture.

#### `mouseButton(value: MouseButton)` (Web & Android only)

Allows users to choose which mouse button should handler respond to. The enum `MouseButton` consists of the following predefined fields:

- `LEFT`
- `RIGHT`
- `MIDDLE`
- `BUTTON_4`
- `BUTTON_5`
- `ALL`

Arguments can be combined using `|` operator, e.g. `mouseButton(MouseButton.LEFT | MouseButton.RIGHT)`. Default value is set to `MouseButton.LEFT`.

#### Properties common to all gestures:

#### `enabled(value: boolean)`

Indicates whether the given handler should be analyzing stream of touch events or not. When set to `false` we can be sure that the handler's state will **never** become `ACTIVE`. If the value gets updated while the handler already started recognizing a gesture, then the handler's state it will immediately change to `FAILED` or `CANCELLED` (depending on its current state). Default value is `true`.

#### `shouldCancelWhenOutside(value: boolean)`

When `true` the handler will cancel or fail recognition (depending on its current state) whenever the finger leaves the area of the connected view. Default value of this property is different depending on the handler type. Most handlers' `shouldCancelWhenOutside` property defaults to `false` except for the `LongPressGesture` and `TapGesture` which default to `true`.

#### `hitSlop(settings)`

This parameter enables control over what part of the connected view area can be used to begin recognizing the gesture. When a negative number is provided the bounds of the view will reduce the area by the given number of points in each of the sides evenly.

Instead you can pass an object to specify how each boundary side should be reduced by providing different number of points for `left`, `right`, `top` or `bottom` sides. You can alternatively provide `horizontal` or `vertical` instead of specifying directly `left`, `right` or `top` and `bottom`. Finally, the object can also take `width` and `height` attributes. When `width` is set it is only allow to specify one of the sides `right` or `left`. Similarly when `height` is provided only `top` or `bottom` can be set. Specifying `width` or `height` is useful if we only want the gesture to activate on the edge of the view. In which case for example we can set `left: 0` and `width: 20` which would make it possible for the gesture to be recognize when started no more than 20 points from the left edge.

**IMPORTANT:** Note that this parameter is primarily designed to reduce the area where gesture can activate. Hence it is only supported for all the values (except `width` and `height`) to be non positive (0 or lower). Although on Android it is supported for the values to also be positive and therefore allow to expand beyond view bounds but not further than the parent view bounds. To achieve this effect on both platforms you can use React Native's View hitSlop property.

#### `withRef(ref)`

Sets a ref to the gesture object, allowing for interoperability with the old API.

#### `withTestId(testID)`

Sets a `testID` property for gesture object, allowing for querying for it in tests.

#### `cancelsTouchesInView(value)` (**iOS only**)

Accepts a boolean value. When `true`, the gesture will cancel touches for native UI components (`UIButton`, `UISwitch`, etc) it's attached to when it becomes `ACTIVE`. Default value is `true`.

#### `runOnJS(value: boolean)`

When `react-native-reanimated` is installed, the callbacks passed to the gestures are automatically workletized and run on the UI thread when called. This option allows for changing this behavior: when `true`, all the callbacks will be run on the JS thread instead of the UI thread, regardless of whether they are worklets or not. Defaults to `false`.

#### `simultaneousWithExternalGesture(otherGesture1, otherGesture2, ...)`

Adds a gesture that should be recognized simultaneously with this one.

**IMPORTANT:** Note that this method only marks the relation between gestures, without composing them. `GestureDetector` will not recognize the `otherGestures` and it needs to be added to another detector in order to be recognized.

#### `requireExternalGestureToFail(otherGesture1, otherGesture2, ...)`

Adds a relation requiring another gesture to fail, before this one can activate.

#### `blocksExternalGesture(otherGesture1, otherGesture2, ...)`

Adds a relation that makes other gestures wait with activation until this gesture fails (or doesn't start at all).

**IMPORTANT:** Note that this method only marks the relation between gestures, without composing them.`GestureDetector` will not recognize the `otherGestures` and it needs to be added to another detector in order to be recognized.

#### `activeCursor(value)` (Web only)

This parameter allows to specify which cursor should be used when gesture activates. Supports all CSS cursor values (e.g. `"grab"`, `"zoom-in"`). Default value is set to `"auto"`.

### Callbacks

#### Callbacks common to all gestures:

#### `onBegin(callback)`

Set the callback that is being called when given gesture handler starts receiving touches. At the moment of this callback the handler is not yet in an active state and we don't know yet if it will recognize the gesture at all.

#### `onStart(callback)`

Set the callback that is being called when the gesture is recognized by the handler and it transitions to the active state.

#### `onEnd(callback)`

Set the callback that is being called when the gesture that was recognized by the handler finishes. It will be called only if the handler was previously in the active state.

#### `onFinalize(callback)`

Set the callback that is being called when the handler finalizes handling gesture - the gesture was recognized and has finished or it failed to recognize.

#### `onTouchesDown(callback)`

Set the `onTouchesDown` callback which is called every time a finger is placed on the screen.

#### `onTouchesMove(callback)`

Set the `onTouchesMove` callback which is called every time a finger is moved on the screen.

#### `onTouchesUp(callback)`

Set the `onTouchesUp` callback which is called every time a finger is lifted from the screen.

#### `onTouchesCancelled(callback)`

Set the `onTouchesCancelled` callback which is called every time a finger stops being tracked, for example when the gesture finishes.

### Event data

#### Event attributes specific to `TapGesture`:

#### `x`

X coordinate, expressed in points, of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the view attached to the `GestureDetector`.

#### `y`

Y coordinate, expressed in points, of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the view attached to the `GestureDetector`.

#### `absoluteX`

X coordinate, expressed in points, of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the window. It is recommended to use `absoluteX` instead of `x` in cases when the view attached to the `GestureDetector` can be transformed as an effect of the gesture.

#### `absoluteY`

Y coordinate, expressed in points, of the current position of the pointer (finger or a leading pointer when there are multiple fingers placed) relative to the window. It is recommended to use `absoluteY` instead of `y` in cases when the view attached to the `GestureDetector` can be transformed as an effect of the gesture.

#### Event attributes common to all gestures:

#### `state`

Current state of the handler. Expressed as one of the constants exported under `State` object by the library.

#### `numberOfPointers`

Represents the number of pointers (fingers) currently placed on the screen.

#### `pointerType`

Indicates the type of pointer device in use. This value is represented by the `PointerType` enum, which includes the following fields:

- `TOUCH` - represents finger
- `STYLUS` - represents stylus or digital pen
- `MOUSE` - represents computer mouse
- `KEY` - represents keyboard
- `OTHER` - represents unknown device type that is not relevant

## Reanimated Swipeable

info

This component is a drop-in replacement for the `Swipeable` component, rewritten using `Reanimated`.

Reanimated `Swipeable` allows for implementing swipeable rows or similar interaction. It renders its children within a panable container allows for horizontal swiping left and right. While swiping one of two "action" containers can be shown depends on whether user swipes left or right (containers can be rendered by `renderLeftActions` or `renderRightActions` props).

#### Usage:

To use it, import it in the following way:

```
import Swipeable from 'react-native-gesture-handler/ReanimatedSwipeable';
```

### Properties

#### `friction`

a number that specifies how much the visual interaction will be delayed compared to the gesture distance. e.g. value of `1` will indicate that the swipeable panel should exactly follow the gesture, `2` means it is going to be two times "slower".

#### `leftThreshold`

distance from the left edge at which released panel will animate to the open state (or the open panel will animate into the closed state). By default it's a half of the panel's width.

#### `rightThreshold`

distance from the right edge at which released panel will animate to the open state (or the open panel will animate into the closed state). By default it's a half of the panel's width.

#### `dragOffsetFromLeftEdge`

distance that the panel must be dragged from the left edge to be considered a swipe. The default value is `10`.

#### `dragOffsetFromRightEdge`

distance that the panel must be dragged from the right edge to be considered a swipe. The default value is `10`.

#### `overshootLeft`

a boolean value indicating if the swipeable panel can be pulled further than the left actions panel's width. It is set to `true` by default as long as the left panel render function is present.

#### `overshootRight`

a boolean value indicating if the swipeable panel can be pulled further than the right actions panel's width. It is set to `true` by default as long as the right panel render function is present.

#### `overshootFriction`

a number that specifies how much the visual interaction will be delayed compared to the gesture distance at overshoot. Default value is `1`, it mean no friction, for a native feel, try `8` or above.

#### `onSwipeableOpen`

a function that is called when `swipeable` is opened (either right or left). Receives swipe direction as an argument.

#### `onSwipeableClose`

a function that is called when `swipeable` is closed. Receives swipe direction as an argument.

#### `onSwipeableWillOpen`

a function that is called when `swipeable` starts animating on open (either right or left). Receives swipe direction as an argument.

#### `onSwipeableWillClose`

a function that is called when `swipeable` starts animating on close. Receives swipe direction as an argument.

#### `onSwipeableOpenStartDrag`

a function that is called when a user starts to drag the `swipable` to open. Receives swipe direction as an argument.

#### `onSwipeableCloseStartDrag`

a function that is called when a user starts to drag the `swipable` to close. Receives swipe direction as an argument.

#### `renderLeftActions`

a function that returns a component which will be rendered under the swipeable after swiping it to the right. The function receives the following arguments:

- `progress` - a `SharedValue` representing swiping progress relative to the width of the returned element.

  - Equals `0` when `swipeable` is closed, `1` when `swipeable` is opened.
  - When the element overshoots it's opened position the value tends towards `Infinity`.

- `translation` - a horizontal offset of the `swipeable` relative to its closed position.

- `swipeableMethods` - provides an object exposing the methods listed here.

This function must return a `ReactNode`.

To support `rtl` flexbox layouts use `flexDirection` styling.

#### `renderRightActions`

a function that returns a component which will be rendered under the swipeable after swiping it to the left. The function receives the following arguments:

- `progress` - a `SharedValue` representing swiping progress relative to the width of the returned element.

  - Equals `0` when `swipeable` is closed, `1` when `swipeable` is opened.
  - When the element overshoots it's opened position the value tends towards `Infinity`.

- `translation` - a horizontal offset of the `swipeable` relative to its closed position.

- `swipeableMethods` - provides an object exposing the methods listed here.

This function must return a `ReactNode`.

To support `rtl` flexbox layouts use `flexDirection` styling.

#### `containerStyle`

style object for the container (`Animated.View`), for example to override `overflow: 'hidden'`.

#### `childrenContainerStyle`

style object for the children container (`Animated.View`), for example to apply `flex: 1`.

#### `simultaneousWithExternalGesture`

A gesture configuration to be recognized simultaneously with the swipeable gesture. This is useful for allowing other gestures to work simultaneously with swipeable gesture handler.

For example, to enable a pan gesture alongside the swipeable gesture:

```
const panGesture = Gesture.Pan();

<GestureDetector gesture={panGesture}>
  <ReanimatedSwipeable simultaneousWithExternalGesture={panGesture} />
</GestureDetector>
```

More details can be found in the gesture composition documentation.

#### `enableTrackpadTwoFingerGesture` (iOS only)

Enables two-finger gestures on supported devices, for example iPads with trackpads. If not enabled the gesture will require click + drag, with `enableTrackpadTwoFingerGesture` swiping with two fingers will also trigger the gesture.

#### `mouseButton(value: MouseButton)` (Web & Android only)

Allows users to choose which mouse button should handler respond to. The enum `MouseButton` consists of the following predefined fields:

- `LEFT`
- `RIGHT`
- `MIDDLE`
- `BUTTON_4`
- `BUTTON_5`
- `ALL`

Arguments can be combined using `|` operator, e.g. `mouseButton(MouseButton.LEFT | MouseButton.RIGHT)`. Default value is set to `MouseButton.LEFT`.

#### `enableContextMenu(value: boolean)` (Web only)

Specifies whether context menu should be enabled after clicking on underlying view with right mouse button. Default value is set to `false`.

### Methods

Using reference to `Swipeable` it's possible to trigger some actions on it

#### `close`

a method that closes component.

#### `openLeft`

a method that opens component on left side.

#### `openRight`

a method that opens component on right side.

#### `reset`

a method that resets the swiping states of this `Swipeable` component.

Unlike method `close`, this method does not trigger any animation.

#### Example:

For a more in-depth presentation of differences between the new and the legacy implementations, see swipeable example from GestureHandler Example App.

```
import React from 'react';
import { Text, StyleSheet } from 'react-native';

import { GestureHandlerRootView } from 'react-native-gesture-handler';
import ReanimatedSwipeable from 'react-native-gesture-handler/ReanimatedSwipeable';
import Reanimated, {
  SharedValue,
  useAnimatedStyle,
} from 'react-native-reanimated';

function RightAction(prog: SharedValue<number>, drag: SharedValue<number>) {
  const styleAnimation = useAnimatedStyle(() => {
    console.log('showRightProgress:', prog.value);
    console.log('appliedTranslation:', drag.value);

    return {
      transform: [{ translateX: drag.value + 50 }],
    };
  });

  return (
    <Reanimated.View style={styleAnimation}>
      <Text style={styles.rightAction}>Text</Text>
    </Reanimated.View>
  );
}

export default function Example() {
  return (
    <GestureHandlerRootView>
      <ReanimatedSwipeable
        containerStyle={styles.swipeable}
        friction={2}
        enableTrackpadTwoFingerGesture
        rightThreshold={40}
        renderRightActions={RightAction}>
        <Text>Swipe me!</Text>
      </ReanimatedSwipeable>
    </GestureHandlerRootView>
  );
}

const styles = StyleSheet.create({
  rightAction: { width: 50, height: 50, backgroundColor: 'purple' },
  separator: {
    width: '100%',
    borderTopWidth: 1,
  },
  swipeable: {
    height: 50,
    backgroundColor: 'papayawhip',
    alignItems: 'center',
  },
});
```

## Swipeable

caution

This component allows for implementing swipeable rows or similar interaction. It renders its children within a panable container allows for horizontal swiping left and right. While swiping one of two "action" containers can be shown depends on whether user swipes left or right (containers can be rendered by `renderLeftActions` or `renderRightActions` props).

#### Usage:

Similarly to the `DrawerLayout`, `Swipeable` component isn't exported by default from the `react-native-gesture-handler` package. To use it, import it in the following way:

```
import Swipeable from 'react-native-gesture-handler/Swipeable';
```

### Properties

#### `friction`

A number that specifies how much the visual interaction will be delayed compared to the gesture distance. e.g. value of `1` will indicate that the swipeable panel should exactly follow the gesture, `2` means it is going to be two times "slower".

#### `leftThreshold`

Distance from the left edge at which released panel will animate to the open state (or the open panel will animate into the closed state). By default it's a half of the panel's width.

#### `rightThreshold`

Distance from the right edge at which released panel will animate to the open state (or the open panel will animate into the closed state). By default it's a half of the panel's width.

#### `dragOffsetFromLeftEdge`

Distance that the panel must be dragged from the left edge to be considered a swipe. The default value is `10`.

#### `dragOffsetFromRightEdge`

Distance that the panel must be dragged from the right edge to be considered a swipe. The default value is `10`.

#### `overshootLeft`

A boolean value indicating if the swipeable panel can be pulled further than the left actions panel's width. It is set to `true` by default as long as the left panel render method is present.

#### `overshootRight`

A boolean value indicating if the swipeable panel can be pulled further than the right actions panel's width. It is set to `true` by default as long as the right panel render method is present.

#### `overshootFriction`

A number that specifies how much the visual interaction will be delayed compared to the gesture distance at overshoot. Default value is `1`, it mean no friction, for a native feel, try `8` or above.

#### `onSwipeableLeftOpen`

caution

This callback is deprecated and will be removed in the next version. Please use `onSwipeableOpen(direction)`

Method that is called when left action panel gets open.

#### `onSwipeableRightOpen`

caution

This callback is deprecated and will be removed in the next version. Please use `onSwipeableOpen(direction)`

Method that is called when right action panel gets open.

#### `onSwipeableOpen`

Method that is called when action panel gets open (either right or left). Takes swipe direction as an argument.

#### `onSwipeableClose`

Method that is called when action panel is closed. Takes swipe direction as an argument.

#### `onSwipeableLeftWillOpen`

caution

This callback is deprecated and will be removed in the next version. Please use `onSwipeableWillOpen(direction)`

Method that is called when left action panel starts animating on open.

#### `onSwipeableRightWillOpen`

caution

This callback is deprecated and will be removed in the next version. Please use `onSwipeableWillOpen(direction)`

Method that is called when right action panel starts animating on open.

#### `onSwipeableWillOpen`

Method that is called when action panel starts animating on open (either right or left). Takes swipe direction as an argument.

#### `onSwipeableWillClose`

Method that is called when action panel starts animating on close. Takes swipe direction as an argument.

#### `renderLeftActions`

Method that is expected to return an action panel that is going to be revealed from the left side when user swipes right. This map describes the values to use as inputRange for extra interpolation: AnimatedValue: \[startValue, endValue]

progressAnimatedValue: `[0, 1]` dragAnimatedValue: `[0, +]`

To support `rtl` flexbox layouts use `flexDirection` styling.

#### `renderRightActions`

Method that is expected to return an action panel that is going to be revealed from the right side when user swipes left. This map describes the values to use as inputRange for extra interpolation: AnimatedValue: \[startValue, endValue]

progressAnimatedValue: `[0, 1]` dragAnimatedValue: `[0, -]`

To support `rtl` flexbox layouts use `flexDirection` styling.

#### `containerStyle`

Style object for the container (Animated.View), for example to override `overflow: 'hidden'`.

#### `childrenContainerStyle`

Style object for the children container (Animated.View), for example to apply `flex: 1`.

#### `enableTrackpadTwoFingerGesture` (iOS only)

Enables two-finger gestures on supported devices, for example iPads with trackpads. If not enabled the gesture will require click + drag, with enableTrackpadTwoFingerGesture swiping with two fingers will also trigger the gesture.

#### `mouseButton(value: MouseButton)` (Web & Android only)

Allows users to choose which mouse button should handler respond to. The enum `MouseButton` consists of the following predefined fields:

- `LEFT`
- `RIGHT`
- `MIDDLE`
- `BUTTON_4`
- `BUTTON_5`
- `ALL`

Arguments can be combined using `|` operator, e.g. `mouseButton(MouseButton.LEFT | MouseButton.RIGHT)`. Default value is set to `MouseButton.LEFT`.

#### `enableContextMenu(value: boolean)` (Web only)

Specifies whether context menu should be enabled after clicking on underlying view with right mouse button. Default value is set to `false`.

### Methods

Using reference to `Swipeable` it's possible to trigger some actions on it

#### `close`

Method that closes component.

#### `openLeft`

Method that opens component on left side.

#### `openRight`

Method that opens component on right side.

#### `reset`

Method that resets the swiping states of this `Swipeable` component.

Unlike method `close`, this method does not trigger any animation.

#### Example:

See the swipeable example from GestureHandler Example App or view it directly on your phone by visiting our expo demo.

```
import React, { Component } from 'react';
import { Animated, StyleSheet, View } from 'react-native';
import { RectButton } from 'react-native-gesture-handler';
import Swipeable from 'react-native-gesture-handler/Swipeable';

class AppleStyleSwipeableRow extends Component {
  renderLeftActions = (progress, dragX) => {
    const trans = dragX.interpolate({
      inputRange: [0, 50, 100, 101],
      outputRange: [-20, 0, 0, 1],
    });
    return (
      <RectButton style={styles.leftAction} onPress={this.close}>
        <Animated.Text
          style={[
            styles.actionText,
            {
              transform: [{ translateX: trans }],
            },
          ]}>
          Archive
        </Animated.Text>
      </RectButton>
    );
  };
  render() {
    return (
      <Swipeable renderLeftActions={this.renderLeftActions}>
        <Text>"hello"</Text>
      </Swipeable>
    );
  }
}
```

## Touchables

warning

Touchables will be removed in the future version of Gesture Handler. Use Pressable instead.

Gesture Handler library provides an implementation of RN's touchable components that are based on native buttons and does not rely on JS responder system utilized by RN. Our touchable implementation follows the same API and aims to be a drop-in replacement for touchables available in React Native.

React Native's touchables API can be found here:

-
-
-
-

All major touchable properties (except from `pressRetentionOffset`) have been adopted and should behave in a similar way as with RN's touchables.

The motivation for using RNGH touchables as a replacement for these imported from React Native is to follow built-in native behavior more closely by utilizing platform native touch system instead of relying on the JS responder system. These touchables and their feedback behavior are deeply integrated with native gesture ecosystem and could be connected with other native components (e.g. `ScrollView`) and Gesture Handlers easily and in a more predictable way, which follows native apps' behavior.

Our intention was to make switch for these touchables as simple as possible. In order to use RNGH's touchables the only thing you need to do is to change library from which you import touchable components. need only to change imports of touchables.

info

Gesture Handler's TouchableOpacity uses native driver for animations by default. If this causes problems for you, you can set `useNativeAnimations` prop to false.

#### Example:

```
import {
  TouchableNativeFeedback,
  TouchableHighlight,
  TouchableOpacity,
  TouchableWithoutFeedback,
} from 'react-native';
```

has to be replaced with:

```
import {
  TouchableNativeFeedback,
  TouchableHighlight,
  TouchableOpacity,
  TouchableWithoutFeedback,
} from 'react-native-gesture-handler';
```

For a comparison of both touchable implementations see our touchables example

##

## How does it work?

#### Units

All handler component properties and event attributes that represent onscreen dimensions are expressed in screen density independent units we refer to as "points". These are the units commonly used in React Native ecosystem (e.g. in the layout system). They do not map directly to physical pixels but instead to iOS's points and to dp units on Android.

### iOS

All gestures are implemented using UIGestureRecognizers, some of them have been slightly modified to allow for more customization and to conform to the state flow of RNGH. When you assign a gesture configuration to the `GestureDetector`, it creates all the required recognizers and assigns them to the child view of the detector. From this point most of the heavy lifting is handled by the UIKit (with our help to correctly implement interactions between gestures).

### Android

Unfortunately, Android doesn't provide an easy way of handling gestures hence most of them were implemented from scratch, including a system for managing how the gestures should interact with each other. Here's a quick overview of how it works: When you wrap a component with `GestureHandlerRootView` it allows for the RNGH to intercept all touch events on that component and process them, deciding whether they should be handled by one of the gesture handlers or passed to the underlying view. Gesture handlers are created when you assign a gesture configuration to the `GestureDetector`, it initializes all of the necessary handlers natively. Every `GestureHandlerRootView` also has a specific handler to decide whether to pass the touch events or to consume them. It can never activate, only begin, end or be cancelled. When this handler is in the `UNDETERMINED` state it means that there is no touch in progress, however when the touch starts it transitions to the `BEGAN` state. As long as it stays in that state, no touch event is consumed, but as soon as it gets cancelled (meaning that some handler has activated) all incoming touch events get consumed, preventing underlying view from receiving them.

When a pointer touches the screen the view tree is traversed in order to extract all handlers attached to the views below the finger (including the one attached to the `GestureHandlerRootView`) and all extracted handlers transition to the `BEGAN` state, signalling that the gesture may have began. The touch events continue to be delivered to all extracted handlers until one of them recognizes the gesture and tries to activate. At this point the orchestrator checks whether this gesture should wait for any other of the extracted gestures to fail. If it does, it's put to the waiting list, if it doesn't, it gets activated and all other gestures (that are not simultaneous with it) get cancelled. When a gesture handlers transitions to a finished state (the gesture recognized by it stops, it fails or gets cancelled) the orchestrator check the waiting handlers. Every one of them that waited for the gesture that just failed tries to activate again (and again the orchestrator checks if it should wait for any of the extracted gestures...).
